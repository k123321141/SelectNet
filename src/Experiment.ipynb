{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^((?!.*((w_prine)|(w_value)).*).)*$\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optimi\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics\n",
    "import torchvision\n",
    "from utils.Training_utils import *\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.CustomDataset import CustomDataset\n",
    "from utils.SimpleDNN import SimpleDNN\n",
    "from utils.SimpleCNN import SimpleCNN\n",
    "from SelectNet import *\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dengue data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4894, 63) (4894, 1)\n",
      "[2942.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 43440/180000 [55:10<2:51:29, 13.27it/s, acc :      0.840, val_acc :      0.833, loss:      0.354,                              val_loss:     0.4748, w_loss :      0.001, entropy :      3.697,                              regularizer :      0.054                      Cancer with Metastasis:  0.00,                            Hyperthyroidism:  0.00,                             Mental Illness:  0.00,                            Hyperlipidaemia:  0.00,                                   exam_WBC: 55.44,                              merged_height: 79.23,                                    exam_NA:159.32,                                       Temp:270.19]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "data = np.load('/home/k123/git/ncku_project/src/medical/data.npz')\n",
    "iid1 = [0, 1, 9, 10, 11, 24]\n",
    "iid2 = [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 24]\n",
    "iid3 = [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "\n",
    "iid = iid1\n",
    "\n",
    "\n",
    "X = data['x'][:, iid]\n",
    "X = data['x']\n",
    "v_mask = data['missing_mask']\n",
    "Y = data['y']\n",
    "X = X[v_mask, :].astype(np.float32)\n",
    "Y = Y[v_mask, :].astype(np.float32)\n",
    "\n",
    "print X.shape, Y.shape\n",
    "print sum(Y)\n",
    "            \n",
    "\n",
    "batch_size = 256\n",
    "N = len(Y)\n",
    "x_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda x:torch.from_numpy(x)),\n",
    "    transforms.Lambda(lambda x:x.float()),\n",
    "    transforms.Lambda(lambda x:x.cuda()),\n",
    "])\n",
    "y_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda y:torch.from_numpy(y)),\n",
    "    transforms.Lambda(lambda y:y.type(torch.float).flatten()),\n",
    "    transforms.Lambda(lambda y:y.cuda()),\n",
    "])\n",
    "            \n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y,\n",
    "                                                                         x_transforms=x_transforms,\n",
    "                                                                         y_transforms=y_transforms,\n",
    "                                                                        ), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.dnn = SimpleDNN(in_dim, 16, 1, 3, F.relu)\n",
    "        self.kernel_weights = self.dnn.kernel_weights\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dnn(x)\n",
    "        return x\n",
    "def dengue_noise_fn(x):\n",
    "    noise_distribution = torch.distributions.Uniform(0.5, 1)\n",
    "    x[:, 0] += noise_distribution.sample(x.shape)[:, 0].cuda()\n",
    "    return x\n",
    "simple_model = Net(X.shape[-1])\n",
    "model = SelectNet(X.shape[-1], simple_model, simple_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "# beta = 0\n",
    "gamma = 0\n",
    "epochs = 10000\n",
    "iters = 1\n",
    "src_loss_criterion = nn.BCEWithLogitsLoss()\n",
    "feature_names = data['feature_names']\n",
    "train(model, opt, src_loss_criterion, train_dataloader, \n",
    "      val_dataloader, alpha, beta, gamma, \n",
    "      epochs, noise_fn=dengue_noise_fn, \n",
    "      metric_fn=calc_accracy_sigmoid, log_name='Dengue', \n",
    "      feature_names=feature_names, \n",
    "      log_period=10, K=4\n",
    "     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Temp', 0.2378159)\n",
      "(u'exam_NA', 0.09374473)\n",
      "(u'merged_height', 0.075081654)\n",
      "(u'exam_WBC', 0.068373166)\n",
      "(u'exam_Hb', 0.0621576)\n",
      "(u'exam_CRP', 0.046066813)\n",
      "(u'SBP', 0.044948414)\n",
      "(u'sex', 0.039721448)\n",
      "(u'exam_PT', 0.034997687)\n",
      "(u'Pulse', 0.033641547)\n",
      "(u'age', 0.03350617)\n",
      "(u'exam_APTT', 0.03278675)\n",
      "(u'merged_weight', 0.02721474)\n",
      "(u'exam_Plt', 0.025029268)\n",
      "(u'bmi', 0.024489818)\n",
      "(u'exam_GLU', 0.023236427)\n",
      "(u'MAP', 0.021679584)\n",
      "(u'Breath', 0.021462012)\n",
      "(u'DBP', 0.020698708)\n",
      "(u'exam_AST', 0.014917306)\n",
      "(u'exam_ALT', 0.00986625)\n",
      "(u'exam_CREA', 0.008563927)\n",
      "[u'Temp', u'exam_NA', u'merged_height', u'exam_WBC', u'exam_Hb', u'exam_CRP', u'SBP', u'sex', u'exam_PT', u'Pulse', u'age', u'exam_APTT', u'merged_weight', u'exam_Plt', u'bmi', u'exam_GLU', u'MAP', u'Breath', u'DBP', u'exam_AST', u'exam_ALT', u'exam_CREA']\n",
      "[0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24]\n"
     ]
    }
   ],
   "source": [
    "w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "sorted_ratio = sorted([(data['feature_names'][i],x) for i,x in enumerate(w_ratio)], key=lambda x:x[1], reverse=True)\n",
    "for x in sorted_ratio[:22]:\n",
    "    print x\n",
    "names = [x[0] for x in sorted_ratio[:22]]\n",
    "print names\n",
    "idx =[data['feature_names'].tolist().index(n) for n in names]\n",
    "print sorted(idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesized XOR data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ab387f337240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;31m# X = torch.from_numpy(np.hstack([x1, x2, y1, y2, y3, iid, iid2]).astype(np.float32))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# X = torch.from_numpy(np.hstack([x1, x2, y1, y2, y3, iid, iid2]).astype(np.float32))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_xor(N):\n",
    "    X = []\n",
    "    Y = []\n",
    "    offset = 10\n",
    "    std = 2\n",
    "    for i in range(N):\n",
    "        idx = np.random.randint(0, 4)\n",
    "        if idx == 0:\n",
    "            s = np.random.normal([offset, offset], std)\n",
    "            y = 1\n",
    "        elif idx == 1:\n",
    "            s = np.random.normal([2*offset, offset], std)\n",
    "            y = 0\n",
    "        elif idx == 2:\n",
    "            s = np.random.normal([offset, 2*offset], std)\n",
    "            y = 0\n",
    "        elif idx == 3:\n",
    "            s = np.random.normal([2*offset, 2*offset], std)\n",
    "            y = 1\n",
    "        X.append(s)\n",
    "        Y.append(y)\n",
    "    return np.asarray(X), np.array(Y).reshape([-1, 1])\n",
    "        \n",
    "\n",
    "N = 1500\n",
    "X, Y = generate_xor(N)\n",
    "\n",
    "print X.shape\n",
    "display_N = 300\n",
    "neg_idx, pos_idx = np.where(Y == 0)[0][:display_N], np.where(Y == 1)[0][:display_N]\n",
    "fig = plt.figure()\n",
    "# ax = fig.gca(projection='3d')\n",
    "ax = fig.gca()\n",
    "ax.scatter(X[neg_idx,0], X[neg_idx, 1], label='negative')\n",
    "ax.scatter(X[pos_idx,0], X[pos_idx, 1], label='positive')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "X = torch.from_numpy(np.hstack([h, w, iid, iid2]).astype(np.float32))\n",
    "# X = torch.from_numpy(np.hstack([x1, x2, y1, y2, y3, iid, iid2]).astype(np.float32))\n",
    "# X = torch.from_numpy(np.hstack([x1, x2, y1, y2, y3, iid, iid2]).astype(np.float32))\n",
    "\n",
    "# X = torch.from_numpy(x1.astype(np.float32))\n",
    "# X = torch.from_numpy(np.hstack([x1, iid]).astype(np.float32))\n",
    "# X, norm = sklearn.preprocessing.normalize(X, axis=0, return_norm=True)\n",
    "# X = X.astype(np.float32)\n",
    "# print norm.shape\n",
    "Y = torch.from_numpy(bmi.astype(np.float32))\n",
    "# Y = torch.from_numpy(y4.astype(np.float32))\n",
    "# Y = torch.from_numpy((bmi > 25).astype(np.float32))\n",
    "print X.shape, Y.shape\n",
    "batch_size = 128\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "DNN_model = SimpleDNN(X.shape[-1], 16, 1, 2, F.relu)\n",
    "model = SelectNet(X.shape[-1], DNN_model, DNN_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "gamma = 0\n",
    "epochs = 1000\n",
    "iters = 1\n",
    "noise_std = 25\n",
    "noise_col_idx = [2, 3]\n",
    "writer = SummaryWriter('./AE_logs/XOR-a%f,b%f,g%f' % (alpha, beta, gamma))\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_masked_noise(x, noise_std, noise_col_idx)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_masked_noise(val_x, noise_std, noise_col_idx)\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "#             mask\n",
    "#             x = mask_column(x, mask_idx)\n",
    "#             val_x = mask_column(val_x, mask_idx)\n",
    "# \n",
    "            model.train()\n",
    "            out = model(x)\n",
    "            reg_loss, w_loss, entropy_loss = model.calc_reg_loss(F.mse_loss)\n",
    "            mse_loss = F.mse_loss(out, y)\n",
    "            loss = alpha*reg_loss + beta*w_loss + gamma*entropy_loss + mse_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "            \n",
    "                out = model(val_x)\n",
    "                val_mse_loss = F.mse_loss(out, val_y)\n",
    "#                 noised\n",
    "                noised_mse = F.mse_loss(model(noised_x), y)\n",
    "                val_noised_mse = F.mse_loss(model(val_noised_x), val_y)\n",
    "                \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            w_prine = torch.sigmoid(model.w).cpu().detach().numpy().flatten()\n",
    "            w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "#             buf = ','.join(['%d:%.2f' % (i+1,x) for i,x in enumerate(buf)])\n",
    "            buf = ','.join(['%2.3f, ' % (x) for i,x in enumerate(w_ratio)])\n",
    "            pbar.set_postfix_str('loss: %.3f, val_loss: %.4f, w_loss : %.3f, entropy : %.3f, regularizer : %.3f                     %s' %\n",
    "                                 (mse_loss.item(), val_mse_loss.item(), \n",
    "                                  w_loss.item(), entropy_loss.item(),\n",
    "                                  reg_loss.item(), buf))\n",
    "#             if mse_loss.item() < 100:\n",
    "            if epoch > 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/mse_loss', {'train': mse_loss.item(),\n",
    "                                                     'validation': val_mse_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_mse_loss', {'train': noised_mse.item(),\n",
    "                                                     'validation': val_noised_mse.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_loss', {'train': w_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/entropy', {'train': entropy_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w\\'', {'w%d' % (i+1) : v  for i, v in enumerate(w_prine)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_ratio', {'w%d' % (i+1) : v  for i, v in enumerate(w_ratio)},\n",
    "                                                     iters)\n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(Y == 0)[0][:200].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 55748/3910000 [6:54:21<492:37:00,  2.17it/s, acc :      0.719, val_acc :      0.703, loss:      0.835,                              val_loss:     0.8734, w_loss :      0.002, entropy :     10.192,                              regularizer :      0.053                                  pixel_1181:  0.17,                                    pixel_1:  0.23,                                  pixel_820:  0.26,                                   pixel_20:  0.26,                                  pixel_668:  1.11,                                  pixel_708:  1.12,                                  pixel_710:  1.12,                                  pixel_589:  1.12]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 60046/3910000 [7:27:24<421:51:44,  2.54it/s, acc :      0.727, val_acc :      0.789, loss:      0.807,                              val_loss:     0.6310, w_loss :      0.002, entropy :     10.193,                              regularizer :      0.056                                  pixel_1181:  0.17,                                    pixel_1:  0.23,                                  pixel_820:  0.27,                                   pixel_20:  0.27,                                  pixel_650:  1.10,                                  pixel_610:  1.11,                                  pixel_630:  1.11,                                  pixel_750:  1.12]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 64154/3910000 [7:55:17<490:17:24,  2.18it/s, acc :      0.719, val_acc :      0.766, loss:      0.693,                              val_loss:     0.6761, w_loss :      0.002, entropy :     10.194,                              regularizer :      0.060                                  pixel_1181:  0.18,                                    pixel_1:  0.23,                                  pixel_440:  0.29,                                   pixel_20:  0.29,                                  pixel_628:  1.10,                                  pixel_402:  1.10,                                  pixel_710:  1.11,                                  pixel_768:  1.13]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 68452/3910000 [8:24:42<567:42:20,  1.88it/s, acc :      0.773, val_acc :      0.719, loss:      0.736,                              val_loss:     0.8059, w_loss :      0.002, entropy :     10.196,                              regularizer :      0.063                                  pixel_1181:  0.21,                                    pixel_1:  0.24,                                   pixel_20:  0.27,                                  pixel_820:  0.29,                                  pixel_168:  1.11,                                  pixel_768:  1.11,                                  pixel_208:  1.13,                                  pixel_402:  1.18]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 72499/3910000 [8:52:10<425:15:54,  2.51it/s, acc :      0.773, val_acc :      0.781, loss:      0.725,                              val_loss:     0.6410, w_loss :      0.002, entropy :     10.197,                              regularizer :      0.066                                  pixel_1181:  0.23,                                    pixel_1:  0.26,                                   pixel_20:  0.26,                                  pixel_820:  0.29,                                  pixel_768:  1.10,                                  pixel_187:  1.10,                                  pixel_229:  1.11,                                  pixel_402:  1.17]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 76812/3910000 [9:21:29<433:01:06,  2.46it/s, acc :      0.750, val_acc :      0.727, loss:      0.664,                              val_loss:     0.8412, w_loss :      0.001, entropy :     10.198,                              regularizer :      0.070                                     pixel_1:  0.25,                                 pixel_1181:  0.26,                                   pixel_20:  0.28,                                  pixel_820:  0.30,                                  pixel_629:  1.08,                                  pixel_668:  1.09,                                  pixel_768:  1.11,                                  pixel_402:  1.19]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 80972/3910000 [9:49:47<422:09:23,  2.52it/s, acc :      0.797, val_acc :      0.789, loss:      0.624,                              val_loss:     0.7104, w_loss :      0.001, entropy :     10.199,                              regularizer :      0.073                                     pixel_1:  0.27,                                 pixel_1181:  0.27,                                   pixel_20:  0.27,                                  pixel_820:  0.30,                                  pixel_250:  1.10,                                  pixel_768:  1.11,                                  pixel_769:  1.11,                                  pixel_402:  1.19]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 85309/3910000 [10:19:20<433:13:51,  2.45it/s, acc :      0.766, val_acc :      0.773, loss:      0.784,                              val_loss:     0.6804, w_loss :      0.001, entropy :     10.199,                              regularizer :      0.076                                  pixel_1181:  0.28,                                    pixel_1:  0.28,                                  pixel_440:  0.30,                                  pixel_861:  0.31,                                  pixel_708:  1.08,                                  pixel_188:  1.09,                                  pixel_768:  1.12,                                  pixel_402:  1.17]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 89657/3910000 [10:49:02<457:04:21,  2.32it/s, acc :      0.773, val_acc :      0.734, loss:      0.756,                              val_loss:     0.6703, w_loss :      0.001, entropy :     10.200,                              regularizer :      0.079                                  pixel_1181:  0.28,                                    pixel_1:  0.29,                                  pixel_440:  0.30,                                  pixel_861:  0.31,                                  pixel_608:  1.08,                                  pixel_768:  1.10,                                  pixel_567:  1.10,                                  pixel_402:  1.11]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 93741/3910000 [11:16:47<423:07:18,  2.51it/s, acc :      0.758, val_acc :      0.719, loss:      0.615,                              val_loss:     0.7511, w_loss :      0.001, entropy :     10.200,                              regularizer :      0.082                                  pixel_1181:  0.27,                                    pixel_1:  0.27,                                  pixel_440:  0.30,                                  pixel_861:  0.32,                                  pixel_766:  1.09,                                  pixel_193:  1.09,                                  pixel_768:  1.11,                                  pixel_402:  1.12]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 97998/3910000 [11:45:47<429:23:16,  2.47it/s, acc :      0.812, val_acc :      0.727, loss:      0.576,                              val_loss:     0.7518, w_loss :      0.001, entropy :     10.201,                              regularizer :      0.085                                  pixel_1181:  0.26,                                    pixel_1:  0.27,                                   pixel_20:  0.30,                                  pixel_440:  0.31,                                  pixel_767:  1.08,                                  pixel_766:  1.08,                                  pixel_768:  1.09,                                  pixel_402:  1.09]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 102259/3910000 [12:14:47<423:26:45,  2.50it/s, acc :      0.797, val_acc :      0.719, loss:      0.583,                              val_loss:     0.8685, w_loss :      0.001, entropy :     10.201,                              regularizer :      0.088                                  pixel_1181:  0.25,                                    pixel_1:  0.26,                                   pixel_20:  0.31,                                  pixel_861:  0.31,                                  pixel_629:  1.08,                                   pixel_90:  1.08,                                  pixel_768:  1.08,                                  pixel_589:  1.10]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 106594/3910000 [12:44:18<422:54:21,  2.50it/s, acc :      0.711, val_acc :      0.750, loss:      0.715,                              val_loss:     0.5966, w_loss :      0.001, entropy :     10.202,                              regularizer :      0.091                                  pixel_1181:  0.27,                                    pixel_1:  0.27,                                   pixel_20:  0.30,                                  pixel_440:  0.32,                                  pixel_588:  1.09,                                  pixel_209:  1.09,                                  pixel_402:  1.10,                                  pixel_768:  1.12]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 110914/3910000 [13:13:43<412:10:31,  2.56it/s, acc :      0.781, val_acc :      0.773, loss:      0.644,                              val_loss:     0.6802, w_loss :      0.001, entropy :     10.203,                              regularizer :      0.093                                     pixel_1:  0.27,                                 pixel_1181:  0.28,                                   pixel_20:  0.31,                                  pixel_440:  0.32,                                  pixel_764:  1.09,                                  pixel_208:  1.09,                                  pixel_402:  1.09,                                  pixel_768:  1.13]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 115210/3910000 [13:42:48<429:31:41,  2.45it/s, acc :      0.836, val_acc :      0.742, loss:      0.571,                              val_loss:     0.7505, w_loss :      0.001, entropy :     10.203,                              regularizer :      0.096                                     pixel_1:  0.28,                                 pixel_1181:  0.28,                                  pixel_861:  0.32,                                   pixel_20:  0.32,                                  pixel_766:  1.07,                                  pixel_191:  1.07,                                  pixel_402:  1.08,                                  pixel_768:  1.08]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 119526/3910000 [14:12:12<414:22:16,  2.54it/s, acc :      0.844, val_acc :      0.805, loss:      0.584,                              val_loss:     0.6699, w_loss :      0.001, entropy :     10.203,                              regularizer :      0.099                                     pixel_1:  0.27,                                 pixel_1181:  0.29,                                   pixel_20:  0.30,                                  pixel_861:  0.33,                                  pixel_188:  1.07,                                  pixel_767:  1.07,                                  pixel_768:  1.08,                                  pixel_402:  1.09]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 123814/3910000 [14:41:17<431:44:52,  2.44it/s, acc :      0.805, val_acc :      0.742, loss:      0.561,                              val_loss:     0.7971, w_loss :      0.001, entropy :     10.203,                              regularizer :      0.102                                     pixel_1:  0.26,                                 pixel_1181:  0.28,                                   pixel_20:  0.30,                                  pixel_861:  0.34,                                  pixel_769:  1.09,                                  pixel_631:  1.09,                                  pixel_402:  1.09,                                  pixel_768:  1.11]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 127779/3910000 [15:08:16<422:29:07,  2.49it/s, acc :      0.719, val_acc :      0.703, loss:      0.764,                              val_loss:     0.8058, w_loss :      0.001, entropy :     10.203,                              regularizer :      0.104                                     pixel_1:  0.28,                                   pixel_20:  0.29,                                 pixel_1181:  0.30,                                  pixel_861:  0.33,                                  pixel_349:  1.07,                                  pixel_208:  1.07,                                  pixel_769:  1.10,                                  pixel_768:  1.14]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 132100/3910000 [15:37:48<413:59:56,  2.53it/s, acc :      0.750, val_acc :      0.750, loss:      0.721,                              val_loss:     0.6314, w_loss :      0.001, entropy :     10.204,                              regularizer :      0.107                                     pixel_1:  0.25,                                   pixel_20:  0.28,                                 pixel_1181:  0.30,                                  pixel_861:  0.32,                                  pixel_209:  1.07,                                  pixel_230:  1.08,                                  pixel_768:  1.09,                                  pixel_769:  1.12]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 136425/3910000 [16:07:27<411:19:58,  2.55it/s, acc :      0.789, val_acc :      0.789, loss:      0.664,                              val_loss:     0.6673, w_loss :      0.001, entropy :     10.204,                              regularizer :      0.109                                     pixel_1:  0.24,                                   pixel_20:  0.29,                                 pixel_1181:  0.31,                                  pixel_801:  0.32,                                  pixel_128:  1.07,                                  pixel_768:  1.08,                                  pixel_402:  1.08,                                  pixel_769:  1.08]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  4%|▎         | 140399/3910000 [16:34:38<413:17:03,  2.53it/s, acc :      0.766, val_acc :      0.750, loss:      0.630,                              val_loss:     0.7574, w_loss :      0.001, entropy :     10.204,                              regularizer :      0.111                                     pixel_1:  0.24,                                   pixel_20:  0.26,                                  pixel_801:  0.31,                                 pixel_1181:  0.31,                                  pixel_766:  1.08,                                  pixel_690:  1.08,                                  pixel_770:  1.10,                                  pixel_169:  1.10]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "final_size = 20\n",
    "final_in_dim = final_size*final_size*3\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn = SimpleCNN(3, 16, 3)\n",
    "        self.kernel_weights = self.cnn.kernel_weights\n",
    "        self.linear = nn.Linear(4*64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = x.view(batch, 3, final_size, final_size)\n",
    "        x = self.cnn(x)\n",
    "        out = self.linear(x.view(batch, -1))\n",
    "        return out\n",
    "def cifar_noise_fn(x):\n",
    "    return x\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "x_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([final_size, final_size]),\n",
    "#     transforms.Grayscale(),\n",
    "    transforms.RandomCrop(20, padding=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    transforms.Lambda(lambda x:x.float().flatten()),\n",
    "    transforms.Lambda(lambda x:x.cuda()),\n",
    "])\n",
    "y_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda y:torch.from_numpy(y).type(torch.long).flatten()),\n",
    "    transforms.Lambda(lambda y:y.cuda()),\n",
    "])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=None)\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=None)\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(trainset.train_data, np.array(trainset.train_labels).reshape([-1, 1]),\n",
    "                             x_transforms=x_transforms,\n",
    "                             y_transforms=y_transforms,\n",
    "                             )\n",
    "val_dataset = CustomDataset(testset.test_data, np.array(testset.test_labels).reshape([-1, 1]),\n",
    "                            x_transforms=x_transforms,\n",
    "                            y_transforms=y_transforms,\n",
    "                           )\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "G = generator(train_dataset)\n",
    "# DNN_model = SimpleDNN(X.shape[-1], 128, 10, 3, F.relu)\n",
    "# model = SelectNet(X.shape[-1], DNN_model, DNN_model.kernel_weights).cuda()\n",
    "simple_model = Net()\n",
    "model = SelectNet(final_in_dim, simple_model, simple_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "# beta = 0\n",
    "gamma = 0\n",
    "epochs = 10000\n",
    "iters = 1\n",
    "src_loss_criterion = nn.CrossEntropyLoss()\n",
    "feature_names = ['pixel_%d' % (i+1) for i in range(final_in_dim)]\n",
    "train(model, opt, src_loss_criterion, train_dataloader, \n",
    "      val_dataloader, alpha, beta, gamma, \n",
    "      epochs, noise_fn=cifar_noise_fn, \n",
    "      metric_fn=calc_accracy_softmax, log_name='Cifar-10', \n",
    "      feature_names=feature_names,\n",
    "      log_period=50, K=4\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(trainset.train_labels).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3363/2350000 [04:30<50:26:18, 12.92it/s, acc : 0.996, val_acc : 0.977, loss: 0.017, val_loss: 0.0630, w_loss : 0.982, entropy : 6.644, regularizer : 0.011 w37:10.00,w54:10.00,w26:10.00,w64:10.00,w34:10.00,w57:10.00,w58:10.00,w36:10.00,w75:10.00,w66:10.00]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  9%|▉         | 220736/2350000 [4:54:00<47:09:08, 12.54it/s, acc : 0.996, val_acc : 0.988, loss: 0.046, val_loss: 0.0790, w_loss : 0.000, entropy : 5.803, regularizer : 0.020 w91:0.00,w99:0.00,w10:0.00,w90:0.00,w1:0.00,w54:22.19,w55:22.34,w77:22.56,w38:23.80,w86:24.67] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 13%|█▎        | 301233/2350000 [6:41:07<45:51:46, 12.41it/s, acc : 1.000, val_acc : 0.988, loss: 0.000, val_loss: 0.0890, w_loss : 0.000, entropy : 5.812, regularizer : 0.020 w91:0.00,w99:0.00,w10:0.00,w1:0.00,w90:0.00,w15:22.10,w77:22.15,w58:22.48,w38:23.87,w86:23.98]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 16%|█▋        | 382465/2350000 [8:29:19<43:13:12, 12.65it/s, acc : 1.000, val_acc : 0.996, loss: 0.000, val_loss: 0.0086, w_loss : 0.000, entropy : 5.825, regularizer : 0.018 w91:0.00,w99:0.00,w10:0.00,w1:0.00,w81:0.00,w68:22.01,w77:22.23,w24:22.39,w86:23.00,w38:23.56]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 23%|██▎       | 544789/2350000 [12:05:33<40:09:59, 12.48it/s, acc : 1.000, val_acc : 0.988, loss: 0.000, val_loss: 0.0903, w_loss : 0.000, entropy : 5.851, regularizer : 0.016 w91:0.00,w99:0.00,w1:0.00,w10:0.00,w80:0.00,w16:22.30,w77:22.41,w78:22.50,w68:23.26,w38:23.65] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 24%|██▍       | 563799/2350000 [12:30:50<39:43:51, 12.49it/s, acc : 1.000, val_acc : 0.977, loss: 0.000, val_loss: 0.1622, w_loss : 0.000, entropy : 5.854, regularizer : 0.017 w91:0.00,w1:0.00,w99:0.00,w10:0.00,w80:0.00,w86:22.21,w16:22.62,w77:22.90,w68:23.19,w38:24.11]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aad0e3c580f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mtrain_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mreg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_reg_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0msrc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_loss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/miniconda2/envs/python-conda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/git/SelectNet/src/SelectNet.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_lay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownstream_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/miniconda2/envs/python-conda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/git/SelectNet/src/SelectNet.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# ratio = self.calc_ratio()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from utils.SimpleCNN import SimpleCNN\n",
    "import sklearn.metrics\n",
    "def calc_accracy(y, out):\n",
    "    label = y.flatten().cpu().detach().numpy().astype(np.int)\n",
    "    pred = torch.argmax(out, dim=-1).cpu().detach().numpy().astype(np.int)\n",
    "    return sklearn.metrics.accuracy_score(label, pred)\n",
    "\n",
    "def add_noise_on_pixel(x, pixel_mask, distribution):\n",
    "    noise = distribution.sample(x.size())\n",
    "    batch = x.shape[0]\n",
    "    ret = x.clone()\n",
    "    ret += pixel_mask.repeat(batch, 1).type(torch.FloatTensor)*noise\n",
    "    return ret\n",
    "            \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn = SimpleCNN(1, 16, 2)\n",
    "        self.kernel_weights = self.cnn.kernel_weights\n",
    "        self.linear = nn.Linear(4*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = x.view(batch, 1, 10, 10)\n",
    "        x = self.cnn(x)\n",
    "        out = self.linear(x.view(batch, -1))\n",
    "        return out\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize([10,10]),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                           transforms.Lambda(lambda x:x.flatten()),\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.Resize([10,10]),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                           transforms.Lambda(lambda x:x.flatten()),\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "X = np.zeros([50000, 100])\n",
    "\n",
    "# DNN_model = SimpleDNN(X.shape[-1], 128, 10, 3, F.relu)\n",
    "# model = SelectNet(X.shape[-1], DNN_model, DNN_model.kernel_weights).cuda()\n",
    "simple_model = Net()\n",
    "model = SelectNet(X.shape[-1], simple_model, simple_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "# beta = 0\n",
    "gamma = 0\n",
    "epochs = 10000\n",
    "iters = 1\n",
    "noise_distribution = torch.distributions.Uniform(0.5, 1)\n",
    "noise_pixel_mask = torch.tensor([[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 1, 1]], dtype=torch.uint8)\n",
    "writer = SummaryWriter('./logs/noised_cnn_mnist-a%f,b%f,g%f' % (alpha, beta, gamma))\n",
    "src_loss_criterion = nn.CrossEntropyLoss()\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "#         mask_idx = np.random.randint(0, X.shape[-1])\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_noise_on_pixel(x, noise_pixel_mask, noise_distribution)\n",
    "            x, y = x.cuda(), y.type(torch.long).flatten().cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_noise_on_pixel(val_x, noise_pixel_mask, noise_distribution)\n",
    "            val_x, val_y = val_x.cuda(), val_y.type(torch.long).flatten().cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "# \n",
    "            model.train()\n",
    "            train_out = model(x)\n",
    "            reg_loss, w_loss, entropy_loss = model.calc_reg_loss(F.mse_loss)\n",
    "            src_loss = src_loss_criterion(train_out, y)\n",
    "            loss = alpha*reg_loss + beta*w_loss + gamma*entropy_loss + src_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "            \n",
    "#                 val_out = torch.softmax(model(val_x), dim=-1)\n",
    "                val_out = model(val_x)\n",
    "                val_src_loss = src_loss_criterion(val_out, val_y)\n",
    "                \n",
    "                \n",
    "#                 noised\n",
    "                noised_train_out = model(noised_x)\n",
    "                noised_val_out = model(val_noised_x)\n",
    "                noised_src = src_loss_criterion(noised_train_out, y)\n",
    "                val_noised_src = src_loss_criterion(noised_val_out, val_y)\n",
    "#                 acc\n",
    "                train_acc = calc_accracy(y, train_out)\n",
    "                val_acc = calc_accracy(val_y, val_out)\n",
    "                noised_train_acc = calc_accracy(y, noised_train_out)\n",
    "                noised_val_acc = calc_accracy(val_y, noised_val_out)\n",
    "                \n",
    "            \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            w_prine = torch.sigmoid(model.w).cpu().detach().numpy().flatten()\n",
    "            w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "            sorted_ratio = sorted([(i+1,x) for i,x in enumerate(w_ratio)], key=lambda x:x[1])\n",
    "            buf = sorted_ratio[:5] + sorted_ratio[-5:]\n",
    "            buf = ','.join(['w%d:%.2f' % (i,x*1000) for i,x in buf])\n",
    "            pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, loss: %.3f, val_loss: %.4f, w_loss : %.3f, entropy : %.3f, regularizer : %.3f %s' %\n",
    "                                 (\n",
    "                                     train_acc.item(), val_acc.item(),\n",
    "                                     src_loss.item(), val_src_loss.item(), \n",
    "                                     w_loss.item(), entropy_loss.item(),\n",
    "                                     reg_loss.item(), buf))\n",
    "            if epoch >= 0 and iters % 10 == 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/cross-entropy', {'train': src_loss.item(),\n",
    "                                                     'validation': val_src_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_loss', {'train': noised_src.item(),\n",
    "                                                     'validation': val_noised_src.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/accuracy', {'train': train_acc.item(),\n",
    "                                                     'validation': val_acc.item(),\n",
    "                                                     'noised_train': noised_train_acc.item(),\n",
    "                                                     'noised_validation': noised_val_acc.item(),\n",
    "                                                    },\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_loss', {'train': w_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/entropy', {'train': entropy_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_prine', {'w%d' % (i+1) : v  for i, v in enumerate(w_prine)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_ratio', {'w%d' % (i+1) : v  for i, v in enumerate(w_ratio)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_z', {'nothing':0 },\n",
    "                                                     iters)\n",
    "            \n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# torch.save(model, './models/mnist_10x10.hdf5')\n",
    "# print val_x.shape\n",
    "# print sorted_ratio\n",
    "# print ['%.5f' % w for w in sorted_ratio]\n",
    "s = 0\n",
    "for i, (_, w) in enumerate(reversed(sorted_ratio)):\n",
    "    s += w\n",
    "#     print '%3d, %.7f, %.7f' % (i, s, w)\n",
    "# print ['%d, %.7f' % w[1] for w in sorted_ratio]\n",
    "# print w_ratio\n",
    "# plt.plot(np.ones([100,]), w_ratio, 'r.')\n",
    "ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "plt.hist(ratio, bins=np.linspace(0, 0.1, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 1, 1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 1, 1]], dtype=torch.uint8)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 1, 1, 1]], dtype=torch.uint8)\n",
      "torch.Size([1, 100])\n",
      "0.9859765625\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.001\n",
    "def get_torch_mask(model, threshold):\n",
    "    ratio = model.select_lay.calc_ratio()\n",
    "    pixel_mask =  ratio*model.select_lay.in_dim < threshold\n",
    "    return pixel_mask.cpu().detach()\n",
    "    \n",
    "def add_noise_on_pixel(x, pixel_mask):\n",
    "    uniform = torch.distributions.Uniform(0.5, 1)\n",
    "    noise = uniform.sample(x.size())\n",
    "    batch = x.shape[0]\n",
    "    ret = x.clone()\n",
    "    ret += pixel_mask.repeat(batch, 1).type(torch.FloatTensor)*noise\n",
    "    return ret\n",
    "\n",
    "def test_accuracy_with_noise(model, val_G, mask, iters=100):\n",
    "    mean_acc = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for it in xrange(iters):\n",
    "            x, y = next(val_G)\n",
    "            x, y = x, y.type(torch.long).flatten().cuda()\n",
    "            x = add_noise_on_pixel(x, pixel_mask).cuda()\n",
    "            out = model(x)\n",
    "            acc = calc_accracy(y, out)\n",
    "            mean_acc.append(acc)\n",
    "    return np.mean(mean_acc)\n",
    "            \n",
    "    \n",
    "pixel_mask = get_torch_mask(model, threshold)\n",
    "print pixel_mask\n",
    "print pixel_mask.shape\n",
    "pixel_idx = [i for i in range(pixel_mask.shape[-1]) if pixel_mask[0, i] == 1]\n",
    "# print np.[pixel_idx]\n",
    "print test_accuracy_with_noise(model, val_G, pixel_mask, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 100]) torch.Size([256])\n",
      "(10, 10, 3) 0.0 1.0\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fed3ec03290>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_noise(img, pixel_mask):\n",
    "    assert len(img.shape) == 3 and img.shape[-1] == 3\n",
    "    mask = pixel_mask.reshape(10, 10)\n",
    "    mask = np.swapaxes(mask, 0, 1)\n",
    "    \n",
    "    ret = img.copy()\n",
    "    np.putmask(ret[:,:,0], mask, 1)\n",
    "    np.putmask(ret[:,:,1], mask, 0)\n",
    "    np.putmask(ret[:,:,2], mask, 0)\n",
    "    return ret\n",
    "\n",
    "def denormalize(x):\n",
    "    return x*0.3081 + 0.1307\n",
    "    \n",
    "for x, y in val_dataloader:\n",
    "    print x.shape, y.shape\n",
    "    break\n",
    "x = x[0:1,:]\n",
    "x = denormalize(x)\n",
    "m = x.numpy()\n",
    "m = np.repeat(m, 3, axis=0)\n",
    "# m = add_noise_on_pixel(m, pixel_idx)\n",
    "m = m.reshape([3, 10, 10])\n",
    "m = np.swapaxes(m, 0, 2)\n",
    "m = np.swapaxes(m, 0, 1)\n",
    "m = visualize_noise(m, pixel_mask)\n",
    "\n",
    "print m.shape, np.min(m), np.max(m)\n",
    "print y[0]\n",
    "plt.imshow(m, cmap=None, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 100]) torch.Size([256])\n",
      "(10, 10, 3) 0.0 1.0\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe03aed5c90>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "def visualize_noise(img, pixel_mask):\n",
    "    assert len(img.shape) == 3 and img.shape[-1] == 3\n",
    "    mask = pixel_mask.reshape(10, 10)\n",
    "    mask = np.swapaxes(mask, 0, 1)\n",
    "    \n",
    "    ret = img.copy()\n",
    "    np.putmask(ret[:,:,0], mask, 1)\n",
    "    np.putmask(ret[:,:,1], mask, 0)\n",
    "    np.putmask(ret[:,:,2], mask, 0)\n",
    "    return ret\n",
    "\n",
    "def denormalize(x):\n",
    "    return x*0.3081 + 0.1307\n",
    "    \n",
    "for x, y in val_dataloader:\n",
    "    print x.shape, y.shape\n",
    "    break\n",
    "x = x[0:1,:]\n",
    "x = denormalize(x)\n",
    "m = x.numpy()\n",
    "m = np.repeat(m, 3, axis=0)\n",
    "# m = add_noise_on_pixel(m, pixel_idx)\n",
    "m = m.reshape([3, 10, 10])\n",
    "m = np.swapaxes(m, 0, 2)\n",
    "m = np.swapaxes(m, 0, 1)\n",
    "m = visualize_noise(m, pixel_mask)\n",
    "\n",
    "print m.shape, np.min(m), np.max(m)\n",
    "print y[0]\n",
    "plt.imshow(m, cmap=None, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist model visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import sklearn.metrics\n",
    "\n",
    "def calc_accracy(y, out):\n",
    "    label = y.flatten().cpu().detach().numpy().astype(np.int)\n",
    "    pred = torch.argmax(out, dim=-1).cpu().detach().numpy().astype(np.int)\n",
    "    return sklearn.metrics.accuracy_score(label, pred)\n",
    "            \n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float32)\n",
    "Y = iris.target.reshape([-1, 1]).astype(np.float32)\n",
    "# print iris.data.shape\n",
    "N = len(Y)\n",
    "batch_size = 8\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "\n",
    "DNN_model = SimpleDNN(X.shape[-1], 16, 3, 2, F.relu)\n",
    "model = SelectNet(X.shape[-1], DNN_model, DNN_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "gamma = 0\n",
    "epochs = 10000\n",
    "iters = 1\n",
    "noise_std = 25\n",
    "noise_col_idx = []\n",
    "writer = SummaryWriter('./AE_logs/Iris-a%f,b%f,g%f' % (alpha, beta, gamma))\n",
    "src_loss_criterion = nn.CrossEntropyLoss()\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "#         mask_idx = np.random.randint(0, X.shape[-1])\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_masked_noise(x, noise_std, noise_col_idx)\n",
    "            x, y = x.cuda(), y.type(torch.long).flatten().cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_masked_noise(val_x, noise_std, noise_col_idx)\n",
    "            val_x, val_y = val_x.cuda(), val_y.type(torch.long).flatten().cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "#             mask\n",
    "#             x = mask_column(x, mask_idx)\n",
    "#             val_x = mask_column(val_x, mask_idx)\n",
    "# \n",
    "            model.train()\n",
    "#             train_out = torch.softmax(model(x), dim=-1)\n",
    "            train_out = model(x)\n",
    "            reg_loss, w_loss, entropy_loss = model.calc_reg_loss(F.mse_loss)\n",
    "            src_loss = src_loss_criterion(train_out, y)\n",
    "            loss = alpha*reg_loss + beta*w_loss + gamma*entropy_loss + src_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "            \n",
    "#                 val_out = torch.softmax(model(val_x), dim=-1)\n",
    "                val_out = model(val_x)\n",
    "                val_src_loss = src_loss_criterion(val_out, val_y)\n",
    "                \n",
    "                \n",
    "#                 noised\n",
    "                noised_train_out = model(noised_x)\n",
    "                noised_val_out = model(val_noised_x)\n",
    "                noised_src = src_loss_criterion(noised_train_out, y)\n",
    "                val_noised_src = src_loss_criterion(noised_val_out, val_y)\n",
    "#                 acc\n",
    "                train_acc = calc_accracy(y, train_out)\n",
    "                val_acc = calc_accracy(val_y, val_out)\n",
    "                noised_train_acc = calc_accracy(y, noised_train_out)\n",
    "                noised_val_acc = calc_accracy(val_y, noised_val_out)\n",
    "                \n",
    "            \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            w_prine = torch.sigmoid(model.w).cpu().detach().numpy().flatten()\n",
    "            w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "#             buf = ','.join(['%d:%.2f' % (i+1,x) for i,x in enumerate(buf)])\n",
    "            buf = ','.join(['%2.3f, ' % (x) for i,x in enumerate(w_ratio)])\n",
    "            pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, loss: %.3f, val_loss: %.4f, w_loss : %.3f, entropy : %.3f, regularizer : %.3f                     %s' %\n",
    "                                 (\n",
    "                                     train_acc.item(), val_acc.item(),\n",
    "                                     src_loss.item(), val_src_loss.item(), \n",
    "                                     w_loss.item(), entropy_loss.item(),\n",
    "                                     reg_loss.item(), buf))\n",
    "            if epoch > 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/cross-entropy', {'train': src_loss.item(),\n",
    "                                                     'validation': val_src_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_loss', {'train': noised_src.item(),\n",
    "                                                     'validation': val_noised_src.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/accuracy', {'train': train_acc.item(),\n",
    "                                                     'validation': val_acc.item(),\n",
    "                                                     'noised_train': noised_train_acc.item(),\n",
    "                                                     'noised_validation': noised_val_acc.item(),\n",
    "                                                    },\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_loss', {'train': w_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/entropy', {'train': entropy_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_prine', {'w%d' % (i+1) : v  for i, v in enumerate(w_prine)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_ratio', {'w%d' % (i+1) : v  for i, v in enumerate(w_ratio)},\n",
    "                                                     iters)\n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/930 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1], [2], [3], [4], [0, 1], [0, 2], [0, 3], [0, 4], [1, 2], [1, 3], [1, 4], [2, 3], [2, 4], [3, 4], [0, 1, 2], [0, 1, 3], [0, 1, 4], [0, 2, 3], [0, 2, 4], [0, 3, 4], [1, 2, 3], [1, 2, 4], [1, 3, 4], [2, 3, 4], [0, 1, 2, 3], [0, 1, 2, 4], [0, 1, 3, 4], [0, 2, 3, 4], [1, 2, 3, 4], [0, 1, 2, 3, 4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 930/930 [28:41<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------+--------------------------------------------------------------------------------------------------------------+\n",
      "| Rank |  Accuracy over 30   |                                                using features                                                |\n",
      "+------+---------------------+--------------------------------------------------------------------------------------------------------------+\n",
      "|  1   |  0.9603174605066814 |        [0, 1, 2, 3, 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']        |\n",
      "|  2   |  0.9561904764743079 |             [1, 2, 3, 4, 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'sw * pw']             |\n",
      "|  3   |  0.9523809526080176 |                        [1, 2, 4, 'sepal width (cm)', 'petal length (cm)', 'sw * pw']                         |\n",
      "|  4   |  0.9507936510207161 | [0, 1, 2, 3, 4, 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'sw * pw'] |\n",
      "|  5   |  0.9507936509639497 |                                    [1, 4, 'sepal width (cm)', 'sw * pw']                                     |\n",
      "|  6   |  0.9457142859981172 |                   [0, 2, 3, 'sepal length (cm)', 'petal length (cm)', 'petal width (cm)']                    |\n",
      "|  7   |  0.9453968256617349 |                                           [3, 'petal width (cm)']                                            |\n",
      "|  8   |  0.9415873018522111 |            [0, 1, 2, 4, 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'sw * pw']             |\n",
      "|  9   |  0.9409523812172904 |                         [1, 3, 4, 'sepal width (cm)', 'petal width (cm)', 'sw * pw']                         |\n",
      "|  10  |  0.9358730162893022 |                                [1, 3, 'sepal width (cm)', 'petal width (cm)']                                |\n",
      "|  11  |  0.9295238097508748 |                    [0, 1, 3, 'sepal length (cm)', 'sepal width (cm)', 'petal width (cm)']                    |\n",
      "|  12  |  0.9269841274193354 |                                    [3, 4, 'petal width (cm)', 'sw * pw']                                     |\n",
      "|  13  |  0.9260317462777334 |                   [0, 1, 2, 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)']                    |\n",
      "|  14  |  0.9234920637380509 |                        [0, 1, 4, 'sepal length (cm)', 'sepal width (cm)', 'sw * pw']                         |\n",
      "|  15  |  0.9219047621223662 |                    [1, 2, 3, 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']                    |\n",
      "|  16  |  0.9212698417428941 |                               [0, 3, 'sepal length (cm)', 'petal width (cm)']                                |\n",
      "|  17  |  0.9212698416672056 |                               [0, 2, 'sepal length (cm)', 'petal length (cm)']                               |\n",
      "|  18  |  0.9161904763986194 |             [0, 1, 3, 4, 'sepal length (cm)', 'sepal width (cm)', 'petal width (cm)', 'sw * pw']             |\n",
      "|  19  |  0.9158730163271466 |                                           [2, 'petal length (cm)']                                           |\n",
      "|  20  |  0.914285714579007  |                               [2, 3, 'petal length (cm)', 'petal width (cm)']                                |\n",
      "|  21  |  0.9111111116220081 |            [0, 2, 3, 4, 'sepal length (cm)', 'petal length (cm)', 'petal width (cm)', 'sw * pw']             |\n",
      "|  22  |  0.8996825400042157 |                        [0, 2, 4, 'sepal length (cm)', 'petal length (cm)', 'sw * pw']                        |\n",
      "|  23  |  0.8879365086744703 |                               [1, 2, 'sepal width (cm)', 'petal length (cm)']                                |\n",
      "|  24  |  0.8815873021928092 |                        [0, 3, 4, 'sepal length (cm)', 'petal width (cm)', 'sw * pw']                         |\n",
      "|  25  |  0.8793650800462754 |                                    [0, 4, 'sepal length (cm)', 'sw * pw']                                    |\n",
      "|  26  |   0.86444444521079  |                                                [4, 'sw * pw']                                                |\n",
      "|  27  |  0.8476190485840752 |                                    [2, 4, 'petal length (cm)', 'sw * pw']                                    |\n",
      "|  28  |  0.8434920641921816 |                        [2, 3, 4, 'petal length (cm)', 'petal width (cm)', 'sw * pw']                         |\n",
      "|  29  |  0.6422222236224585 |                               [0, 1, 'sepal length (cm)', 'sepal width (cm)']                                |\n",
      "|  30  | 0.31555555601441665 |                                           [1, 'sepal width (cm)']                                            |\n",
      "|  31  | 0.30222222282536454 |                                           [0, 'sepal length (cm)']                                           |\n",
      "+------+---------------------+--------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from itertools import combinations\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float32)\n",
    "buf = (X[:,1] * X[:,3]).reshape([-1, 1])\n",
    "X = np.concatenate([X, buf], axis=1)\n",
    "Y = iris.target.reshape([-1, 1]).astype(np.float32)\n",
    "buf = X[:]\n",
    "def init_sess():\n",
    "    K.clear_session()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                        # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "def train_model(X, Y, iters, pbar):\n",
    "    input_dim = X.shape[-1]\n",
    "    arr = []\n",
    "    cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        \n",
    "    for i in range(iters):\n",
    "        init_sess()\n",
    "        X_train,X_test,y_train,y_test=train_test_split(X,Y,train_size=0.3)\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64,input_shape=(input_dim,), activation='relu'))\n",
    "#         model.add(Dropout(0.2))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "#         model.add(Dropout(0.2))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "        model.fit(X_train,y_train, epochs=500,batch_size=5,\n",
    "                  verbose=0, validation_data=[X_test, y_test],\n",
    "                  callbacks=[cb]\n",
    "                 )\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        arr.append(accuracy)\n",
    "        pbar.update(1)\n",
    "    return np.mean(arr)\n",
    "idx_set = []\n",
    "feature_names = iris.feature_names + ['sw * pw']\n",
    "for i in range(len(feature_names)):\n",
    "    for idxs in combinations(np.arange(len(feature_names)), i+1):\n",
    "        idx_set.append(list(idxs))\n",
    "print idx_set\n",
    "# print X.shape\n",
    "iters = 30\n",
    "acc_arr = []\n",
    "with tqdm(total=len(idx_set)*iters) as pbar:\n",
    "    for idx in idx_set:\n",
    "        acc = train_model(X[:, idx], Y, iters, pbar)\n",
    "        acc_arr.append([idx, acc])\n",
    "acc_arr = sorted(acc_arr, key=lambda x: x[1], reverse=True)\n",
    "T = PrettyTable()\n",
    "T.field_names = [\"Rank\", \"Accuracy over %d \" % iters, \"using features\"]\n",
    "for i, (idx, acc) in enumerate(acc_arr):\n",
    "    row = [i+1, acc, idx + [feature_names[x] for x in idx]]\n",
    "    T.add_row(row)\n",
    "print T    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------------------------------------------------------------------------------------------+\n",
      "| Rank | Accuracy over 30  |                                      using features                                      |\n",
      "+------+-------------------+------------------------------------------------------------------------------------------+\n",
      "|  1   |       0.960       |        [0, 1, 2, 3, 'sepal length', 'sepal width', 'petal length', 'petal width']        |\n",
      "|  2   |       0.956       |          [1, 2, 3, 4, 'sepal width', 'petal length', 'petal width', 'sw * pw']           |\n",
      "|  3   |       0.952       |                   [1, 2, 4, 'sepal width', 'petal length', 'sw * pw']                    |\n",
      "|  4   |       0.951       | [0, 1, 2, 3, 4, 'sepal length', 'sepal width', 'petal length', 'petal width', 'sw * pw'] |\n",
      "|  5   |       0.951       |                             [1, 4, 'sepal width', 'sw * pw']                             |\n",
      "|  6   |       0.946       |                 [0, 2, 3, 'sepal length', 'petal length', 'petal width']                 |\n",
      "|  7   |       0.945       |                                    [3, 'petal width']                                    |\n",
      "|  8   |       0.942       |          [0, 1, 2, 4, 'sepal length', 'sepal width', 'petal length', 'sw * pw']          |\n",
      "|  9   |       0.941       |                    [1, 3, 4, 'sepal width', 'petal width', 'sw * pw']                    |\n",
      "|  10  |       0.936       |                           [1, 3, 'sepal width', 'petal width']                           |\n",
      "|  11  |       0.930       |                 [0, 1, 3, 'sepal length', 'sepal width', 'petal width']                  |\n",
      "|  12  |       0.927       |                             [3, 4, 'petal width', 'sw * pw']                             |\n",
      "|  13  |       0.926       |                 [0, 1, 2, 'sepal length', 'sepal width', 'petal length']                 |\n",
      "|  14  |       0.923       |                   [0, 1, 4, 'sepal length', 'sepal width', 'sw * pw']                    |\n",
      "|  15  |       0.922       |                 [1, 2, 3, 'sepal width', 'petal length', 'petal width']                  |\n",
      "|  16  |       0.921       |                          [0, 3, 'sepal length', 'petal width']                           |\n",
      "|  17  |       0.921       |                          [0, 2, 'sepal length', 'petal length']                          |\n",
      "|  18  |       0.916       |          [0, 1, 3, 4, 'sepal length', 'sepal width', 'petal width', 'sw * pw']           |\n",
      "|  19  |       0.916       |                                   [2, 'petal length']                                    |\n",
      "|  20  |       0.914       |                          [2, 3, 'petal length', 'petal width']                           |\n",
      "|  21  |       0.911       |          [0, 2, 3, 4, 'sepal length', 'petal length', 'petal width', 'sw * pw']          |\n",
      "|  22  |       0.900       |                   [0, 2, 4, 'sepal length', 'petal length', 'sw * pw']                   |\n",
      "|  23  |       0.888       |                          [1, 2, 'sepal width', 'petal length']                           |\n",
      "|  24  |       0.882       |                   [0, 3, 4, 'sepal length', 'petal width', 'sw * pw']                    |\n",
      "|  25  |       0.879       |                            [0, 4, 'sepal length', 'sw * pw']                             |\n",
      "|  26  |       0.864       |                                      [4, 'sw * pw']                                      |\n",
      "|  27  |       0.848       |                            [2, 4, 'petal length', 'sw * pw']                             |\n",
      "|  28  |       0.843       |                   [2, 3, 4, 'petal length', 'petal width', 'sw * pw']                    |\n",
      "|  29  |       0.642       |                          [0, 1, 'sepal length', 'sepal width']                           |\n",
      "|  30  |       0.316       |                                    [1, 'sepal width']                                    |\n",
      "|  31  |       0.302       |                                   [0, 'sepal length']                                    |\n",
      "+------+-------------------+------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "T = PrettyTable()\n",
    "T.field_names = [\"Rank\", \"Accuracy over %d \" % iters, \"using features\"]\n",
    "for i, (idx, acc) in enumerate(acc_arr):\n",
    "    acc = '%.3f' % acc\n",
    "    row = [i+1, acc, idx + [feature_names[x].replace(' (cm)','') for x in idx]]\n",
    "    T.add_row(row)\n",
    "print T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "(0, 1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "print '%s' % ([iris.feature_names[x] for x in idxs ])\n",
    "print idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = nn.Conv2d(1, 16, 3, padding=1)\n",
    "print cnn.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_noise(model, val_G, label, iters=100):\n",
    "    x_ax = np.linspace(1, 30, 100)\n",
    "    src_arr = []\n",
    "    noised_arr = []\n",
    "    for std in x_ax:\n",
    "        src_mse_loss = 0\n",
    "        noised_mse_loss = 0\n",
    "        normal = torch.distributions.Normal(0, std)\n",
    "        for i in range(iters):\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "            N = val_x.shape[0]\n",
    "            noise = torch.cat([torch.zeros_like(val_x)[:,:-2], normal.sample([N,2]).cuda()], dim=1)\n",
    "            out1,_ = model(val_x)\n",
    "            out2,_ = model(val_x + noise)\n",
    "            src_mse_loss += F.mse_loss(out1, val_y)\n",
    "            noised_mse_loss += F.mse_loss(out2, val_y)\n",
    "        src_mse_loss /= iters\n",
    "        noised_mse_loss /= iters\n",
    "        src_arr.append(src_mse_loss.item())\n",
    "        noised_arr.append(noised_mse_loss.item())\n",
    "    \n",
    "#     plt.plot(x_ax, src_arr, label=label + ' mse')\n",
    "    plt.plot(x_ax, noised_arr, label=label + ' mse with noise')\n",
    "# eval_noise(att_model, val_G, 'selection', 10)\n",
    "eval_noise(model, val_G, 'src', 10 )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print X.shape, Y.shape\n",
    "print Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float32)\n",
    "Y = iris.target.reshape([-1, 1]).astype(np.float32)\n",
    "# print iris.data.shape\n",
    "N = len(Y)\n",
    "batch_size = 32\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "model = Attention_Autoendecoder(X.shape[-1]).cuda()\n",
    "# opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "opt = optim.Adam(model.parameters())\n",
    "alpha = 100\n",
    "beta = 0\n",
    "epochs = 1000\n",
    "iters = 1\n",
    "noise_std = 5\n",
    "noise_col_idx = [2, 3]\n",
    "writer = SummaryWriter('./AE_logs/Iris-a%f,b%f' % (alpha, beta))\n",
    "reg_l2_coe = 0.1\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        mask_idx = np.random.randint(0, X.shape[-1])\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_masked_noise(x, noise_std, noise_col_idx)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_masked_noise(val_x, noise_std, noise_col_idx)\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "#             mask\n",
    "#             x = mask_column(x, mask_idx)\n",
    "#             val_x = mask_column(val_x, mask_idx)\n",
    "# \n",
    "            model.train()\n",
    "            out, att_w = model(x)\n",
    "            w_ = torch.softmax(att_w, dim=-1)\n",
    "            mse_loss = F.mse_loss(out, y)\n",
    "            att_loss = alpha*(F.l1_loss(att_w, torch.zeros_like(att_w)) + beta*entropy_loss(w_))\n",
    "            reg_loss = reg_l2_coe * regularizer(model.kernel_weights, F.mse_loss)\n",
    "            loss = att_loss + mse_loss + reg_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                out, _ = model(val_x)\n",
    "                val_mse_loss = F.mse_loss(out, val_y)\n",
    "                val_loss = att_loss + val_mse_loss + reg_loss\n",
    "#                 noised\n",
    "                noised_mse = F.mse_loss(model(noised_x)[0], y)\n",
    "                val_noised_mse = F.mse_loss(model(val_noised_x)[0], val_y)\n",
    "                \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            att_w_arr = att_w.cpu().detach().numpy().flatten()\n",
    "            ratio_w = (att_w / torch.sum(att_w)).cpu().detach().numpy().flatten()\n",
    "#             buf = ','.join(['%d:%.2f' % (i+1,x) for i,x in enumerate(buf)])\n",
    "            buf = ','.join(['%2.3f, ' % (x) for i,x in enumerate(ratio_w)])\n",
    "            buf += 'l1 %.3f, entropy %.3f' % (F.l1_loss(att_w, torch.zeros_like(att_w)).item(), entropy_loss(w_).item())\n",
    "            pbar.set_postfix_str('loss: %.3f, val_loss: %.4f, att_loss : %.3f, regularizer : %.3f                     %s' %\n",
    "                                 (mse_loss.item(), val_mse_loss.item(), \n",
    "                                  att_loss.item(),\n",
    "                                  reg_loss.item(), buf))\n",
    "#             if mse_loss.item() < 100:\n",
    "            if epoch > 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item(),\n",
    "                                                     'validation': val_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/mse_loss', {'train': mse_loss.item(),\n",
    "                                                     'validation': val_mse_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_mse_loss', {'train': noised_mse.item(),\n",
    "                                                     'validation': val_noised_mse.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/att_loss', {'train': att_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/att_w', {'w%d' % (i+1) : v  for i, v in enumerate(att_w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/ratio_att_w', {'w%d' % (i+1) : v  for i, v in enumerate(ratio_w)},\n",
    "                                                     iters)\n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n",
    "print att_w[0,: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_mse_loss = 0\n",
    "noised_mse_loss = 0\n",
    "normal = torch.distributions.Normal(0, 20)\n",
    "\n",
    "for i in range(100):\n",
    "    val_x, val_y = next(val_G)\n",
    "    val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "    N = val_x.shape[0]\n",
    "    noise = torch.cat([torch.zeros_like(val_x)[:,:-2], normal.sample([N,2]).cuda()], dim=1)\n",
    "    out1,_ = model(val_x)\n",
    "    out2,_ = model(val_x + noise)\n",
    "    src_mse_loss += F.mse_loss(out1, val_y)\n",
    "    noised_mse_loss += F.mse_loss(out2, val_y)\n",
    "    \n",
    "print src_mse_loss\n",
    "print noised_mse_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(torch.FloatTensor([1,0,0]), dim=0)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "input_x = np.hstack([h, w, iid, iid2])\n",
    "print input_x.shape\n",
    "m = Sequential()\n",
    "m.add(Dense(32, activation='selu'))\n",
    "m.add(Dense(32, activation='selu'))\n",
    "m.add(Dense(1, activation='linear'))\n",
    "m.compile(loss='mse', optimizer='adam')\n",
    "m.fit(input_x, bmi, epochs=100, batch_size=128, validation_split=0.1)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x1.shape\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(x1.flatten(), y1.flatten(), y2.flatten(), label='curve')\n",
    "ax.legend()\n",
    "print X.shape\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "theta = np.linspace(-4 * np.pi, 4 * np.pi, 100)\n",
    "z = np.linspace(-2, 2, 100)\n",
    "r = z**2 + 1\n",
    "x = r * np.sin(theta)\n",
    "y = r * np.cos(theta)\n",
    "ax.plot(x, y, z, label='parametric curve')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.14 (conda)",
   "language": "python",
   "name": "python-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
