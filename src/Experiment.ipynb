{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^((?!.*((w_prine)|(w_value)).*).)*$\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optimi\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics\n",
    "import torchvision\n",
    "from utils.Training_utils import *\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.CustomDataset import CustomDataset\n",
    "from utils.SimpleDNN import SimpleDNN\n",
    "from SelectNet import *\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dengue data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4894, 63) (4894, 1)\n",
      "[2942.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 43440/180000 [55:10<2:51:29, 13.27it/s, acc :      0.840, val_acc :      0.833, loss:      0.354,                              val_loss:     0.4748, w_loss :      0.001, entropy :      3.697,                              regularizer :      0.054                      Cancer with Metastasis:  0.00,                            Hyperthyroidism:  0.00,                             Mental Illness:  0.00,                            Hyperlipidaemia:  0.00,                                   exam_WBC: 55.44,                              merged_height: 79.23,                                    exam_NA:159.32,                                       Temp:270.19]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "data = np.load('/home/k123/git/ncku_project/src/medical/data.npz')\n",
    "iid1 = [0, 1, 9, 10, 11, 24]\n",
    "iid2 = [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 24]\n",
    "iid3 = [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "\n",
    "iid = iid1\n",
    "\n",
    "\n",
    "X = data['x'][:, iid]\n",
    "X = data['x']\n",
    "v_mask = data['missing_mask']\n",
    "Y = data['y']\n",
    "X = X[v_mask, :].astype(np.float32)\n",
    "Y = Y[v_mask, :].astype(np.float32)\n",
    "\n",
    "print X.shape, Y.shape\n",
    "print sum(Y)\n",
    "            \n",
    "\n",
    "batch_size = 256\n",
    "N = len(Y)\n",
    "x_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda x:torch.from_numpy(x)),\n",
    "    transforms.Lambda(lambda x:x.float()),\n",
    "    transforms.Lambda(lambda x:x.cuda()),\n",
    "])\n",
    "y_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda y:torch.from_numpy(y)),\n",
    "    transforms.Lambda(lambda y:y.type(torch.float).flatten()),\n",
    "    transforms.Lambda(lambda y:y.cuda()),\n",
    "])\n",
    "            \n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y,\n",
    "                                                                         x_transforms=x_transforms,\n",
    "                                                                         y_transforms=y_transforms,\n",
    "                                                                        ), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.dnn = SimpleDNN(in_dim, 16, 1, 3, F.relu)\n",
    "        self.kernel_weights = self.dnn.kernel_weights\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dnn(x)\n",
    "        return x\n",
    "def dengue_noise_fn(x):\n",
    "    noise_distribution = torch.distributions.Uniform(0.5, 1)\n",
    "    x[:, 0] += noise_distribution.sample(x.shape)[:, 0].cuda()\n",
    "    return x\n",
    "simple_model = Net(X.shape[-1])\n",
    "model = SelectNet(X.shape[-1], simple_model, simple_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "# beta = 0\n",
    "gamma = 0\n",
    "epochs = 10000\n",
    "iters = 1\n",
    "src_loss_criterion = nn.BCEWithLogitsLoss()\n",
    "feature_names = data['feature_names']\n",
    "train(model, opt, src_loss_criterion, train_dataloader, \n",
    "      val_dataloader, alpha, beta, gamma, \n",
    "      epochs, noise_fn=dengue_noise_fn, \n",
    "      metric_fn=calc_accracy_sigmoid, log_name='Dengue', \n",
    "      feature_names=feature_names, K=4\n",
    "     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Temp', 0.2378159)\n",
      "(u'exam_NA', 0.09374473)\n",
      "(u'merged_height', 0.075081654)\n",
      "(u'exam_WBC', 0.068373166)\n",
      "(u'exam_Hb', 0.0621576)\n",
      "(u'exam_CRP', 0.046066813)\n",
      "(u'SBP', 0.044948414)\n",
      "(u'sex', 0.039721448)\n",
      "(u'exam_PT', 0.034997687)\n",
      "(u'Pulse', 0.033641547)\n",
      "(u'age', 0.03350617)\n",
      "(u'exam_APTT', 0.03278675)\n",
      "(u'merged_weight', 0.02721474)\n",
      "(u'exam_Plt', 0.025029268)\n",
      "(u'bmi', 0.024489818)\n",
      "(u'exam_GLU', 0.023236427)\n",
      "(u'MAP', 0.021679584)\n",
      "(u'Breath', 0.021462012)\n",
      "(u'DBP', 0.020698708)\n",
      "(u'exam_AST', 0.014917306)\n",
      "(u'exam_ALT', 0.00986625)\n",
      "(u'exam_CREA', 0.008563927)\n",
      "[u'Temp', u'exam_NA', u'merged_height', u'exam_WBC', u'exam_Hb', u'exam_CRP', u'SBP', u'sex', u'exam_PT', u'Pulse', u'age', u'exam_APTT', u'merged_weight', u'exam_Plt', u'bmi', u'exam_GLU', u'MAP', u'Breath', u'DBP', u'exam_AST', u'exam_ALT', u'exam_CREA']\n",
      "[0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24]\n"
     ]
    }
   ],
   "source": [
    "w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "sorted_ratio = sorted([(data['feature_names'][i],x) for i,x in enumerate(w_ratio)], key=lambda x:x[1], reverse=True)\n",
    "for x in sorted_ratio[:22]:\n",
    "    print x\n",
    "names = [x[0] for x in sorted_ratio[:22]]\n",
    "print names\n",
    "idx =[data['feature_names'].tolist().index(n) for n in names]\n",
    "print sorted(idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesized XOR data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJztvXucVNW17/sbXV0NBZpuWtm50oCwc91oeDWbjnIu2dk+dsC37Qt87asnRuLVfKLEzRZzjLYec8RgIMdo9BAlxoiEjkD7DniRfT1xi0ljN00Q+BiVV0OUAE0QCru6e9w/Vq3uVavmXGuuR1Wtqprfz8dPd69aa65ZRTnmXGP8xhjEzNBoNBpN+VBR6AloNBqNJr9ow6/RaDRlhjb8Go1GU2Zow6/RaDRlhjb8Go1GU2Zow6/RaDRlhjb8Go1GU2Zow6/RaDRlhjb8Go1GU2ZUFnoCIk4++WQeM2ZMoaeh0Wg0RcPGjRv/yszDVc6NpOEfM2YMWltbCz0NjUajKRqIaKfqudrVo9FoNGWGNvwajUZTZmjDr9FoNGWGq+EnolFEtJ6IPiCiLUR0R/p4ExF1ElF7+r8LJdefT0TbiejPRDQ/7Deg0Wg0Gm+oBHd7ANzFzO8T0YkANhLRm+nXFjPzo7ILiSgG4AkA3wSwB8AfiehlZv4g6MQ1Go1G4w/XHT8z72Pm99O/HwGwFUCd4vhnAvgzM3/MzN0AfgPgMr+T1Wg0Gk1wPPn4iWgMgCkA3ksf+i4RdRDRUiIaJrikDsBuy997oL5oaDQajSYHKBt+IjoBwEoAdzLz3wA8CeArAOoB7APwkyATIaI5RNRKRK379+8PMpRGo9FoHFAy/EQUh2H0lzHzKgBg5k+ZuZeZ+wD8AoZbx04ngFGWv0emj2XBzEuYuYGZG4YPV0o+02g0GnU6moHFE4CmGuNnR3OhZ1QwVFQ9BOAZAFuZeZHl+CmW0y4H8CfB5X8EcBoRjSWiKgDXAHg52JQ1Go3GIx3NwCvfAw7vBsDGz1e+V7bGX2XHPx3AvwI41ybd/DERbSaiDgDnAJgLAEQ0goheBwBm7gHwXQBrYASFm5l5Sy7eiEaj0UhZ9yCQSmYeSyWN42WIq5yTmX8PgAQvvS45fy+ACy1/vy47txhoaevEwjXbsbcriRE1CcybOQ6NU3R8WqMpKg7v8Xa8xIlkkbao0NLWiXtWbUYy1QsA6OxK4p5VmwEgb8ZfLzwaTQhUj0y7eQTHyxBdssGBhWu29xt9k2SqFwvXbM/L/c2Fp7MrCcbAwtPSJoyPazQaGefdB8QTmcfiCeN4GaINvwN7u5KejodNoRcejaZkmDQLuOQxoHoUADJ+XvKYcbwM0a4eB0bUJNApMPIjahKCs8On0AuPRlNSTJpVtobejt7xOzBv5jgk4rGMY4l4DPNmjsvL/WULTL4WHo1GU5pow+9A45Q6PHzFRNTVJEAA6moSePiKiXkLrhZ64dEUITpJSaOAdvW40DilrmAqGvO+flQ9Wg1UhphJSqZe3UxSArSLQ5MBMXOh55BFQ0MD6567/rHLUAHjSSGfTysan3Q0G0lFh/cYUsPz7lM32osnSCSLo4C5osR6TSlBRBuZuUHlXL3jL0Gc1EBOhl8/JRSYoDt2naSkUUT7+EsQP2ognTMQAYKWFZAlI6kkKenYQFmhDX8J4kcNpHMGIkDQHbvfJCVdwKzs0Ia/BPGjBtI5AxEgyI4d8J+klK8CZvqpIjJoH38J0jilDq07D2L5e7vRy4wYEa6c6qxOKnSymgbGztzq4we8lxXwk6SUj9iAl/hFkAC3Rglt+EuQe1s2Y9mGXTD1Wr3MWLnR8NWv37ZfGLydN3OcUAmkcwbyiGnc8m30nAqYhWWEnZ4qrONpSWpe0HLOIkJFddPS1om5K9oh+lclIOt4TSKOpkvHo3FKnVb15IMo7mbtxhYwnjQmXwdseiH7uJ8aN03VDq8dHvhdS1J9o+WcJYhqieiFa7YLjT6QbfQBoCuZyhhHG/ocEtXdrOxJQ3WXbkW2sFEM4N7s8ykzFqUlqflBpfXiKCJaT0QfENEWIrojfXwhEW0jog4iWk1ENZLrd6Q7dbUTkd7G+0RVdeMnGKvVO3kiyl2gJs0ydtRNXcbPSbO8G2EndZDI6APZx4MGuDVKqOz4ewDcxczvE9GJADYS0ZsA3gRwDzP3ENEjAO4BcLdkjHOY+a/hTLlw2F0h55w+XOozDxtV1Y0sSOt3/Ki6f7zOKxLvo9h2s16blzgtbNWj5C4cK2EEuDWuuO74mXkfM7+f/v0IjN65dcy8Nt1TFwA2ACjpJVmU4PT8hl15S3hS1eaLpJwEYPpXarOOu42vmtTV0taJ6Qvewtj5r2H6grdynvTlNdksMslpxbabPe8+IFaVeSxWJTfCTgubao6BrpufFzzp+IloDIApAN6zvfQtAG9ILmMAa4loIxHNcRh7DhG1ElHr/v37vUwrL4hcLXZy6TJR1eaLKoounl2PZbf8Fzx8xUQMrRIb/3NOH551TMW9VAij6jXZLDLJacXWBWrXBqC3O/OYkxjEaWFzM+hWjf8bdwPdR0N5CxoxysFdIjoBwEoAdzLz3yzH/xsMd9AyyaVfZ+ZOIvo7AG8S0TZmftt+EjMvAbAEMFQ9Ht5DXlD1necq4clLpU5ZkLZxSh0WrtmOo93Zc1y/LXuxVXEv+a0LFASvyWaRSU4rlFzTDx3NQOvS7ON9KXlw181NI8sxsAe9kwcHXotKALzEUDL8RBSHYfSXMfMqy/GbAFwM4DyW6EKZuTP98zMiWg3gTABZhj/qqPrOc5nwFIbqxskI2v3g1Yk4upKprHOt77EQRtVrslmkktOKpQvUugch1oFB7tKRLWxAWqYpWexEsQErbkoir0RRUptnVFQ9BOAZAFuZeZHl+PkA/h3Apcx8THLt0HRAGEQ0FMAMAEUpxhW5WuwUKuHJi49dZuyqE/Esl83R7h7EKyjjPPt7DNIlzG9swGtJCt3QxgdOAWenmIRdHQS41wFSCW6HFQDXdYkAqPn4pwP4VwDnpiWZ7UR0IYDHAZwIw33TTkRPAQARjSCi19PXfhnA74loE4A/AHiNmX8X/tvIPSLf+Q3TRhesO5eJVx+7zAgSIctlk+plnDC40vE9+jWqQWID5r/FsCHx/mODKuVf5UJ3UssiqjVrrPMi2edJ3mISKhJWleB2WAHwKEtq84irq4eZfw9DGGLndcExMPNeABemf/8YwOQgEywkIgngO/PPzen4VmOkIkGU+djnNrcDQNb5sljB3BXtwjl2HUuh7b4Z0vfgt0tYkNhAS1snml7ekuGGsieiieYZBRlqpGrWWMdPDAO+OGL48AGJ7p6Ahm95m4OKhFUUG7ASZgC82CS1OUJn7kpQzZS1G6FhQ+K4/5LxSsbLaXzR63NXtKN150E81DixfxyZL50ZmPfipqz5mn+LFhBVP7jqgui0cPmNDYi6i5nkOqgcCrmuWWM35gCQPJS9cDgFVK1QDOA+fwtPR7Px5CBaRKw7+IzYwO70NX3GsUQtcMEj4S14XnMTShRdllmCqpRx3m83Zew8Dx1LYd6Lm1xdFm7ji15nAMs27MoY28mXnuplZcniOacPz3qsE7lsvGj7nc7zGxtwk9VGvoy06o7Tj0vC7r9OHkwbdIEv2y2gasJ9mdm8qphzERl9mX7flLuaRh8AekL+9yw2SW2O0IZfgqqUMdWXrXxQMbiy8Tu7kpi+4C2pgojT9zVx86V3diVdg6ctbZ1YubEzQ8NBgLCUs6om3u08v7EBN8Me+TLSqklcol0p4OySUFXHuI3jNC9VZHOhmDwhKx/+d50gBkC7eqSoSACdjJCKgZIZ986upLCSpmjsxil1eOCVLTh0LFt2aWLdcZtYXTDHunuETxd+tf0q5/mNDTh9bjlT6oTpa1cpSdDRDHEtVTgbYi/qmMQwuXtHNi8vyObCvfLPLl/+92KR1OYQveOXoLIjddpduu08580ch3hMFDM3cMpgs499/yXjs2SXIpKpXjzwypYsF4xs0RAZb1UXjcp5jVPq8M78c/HJgovwzvxzlXzzMlntsCHx3Ch1wpb/qew4pRp6F0WNqjqmo9kI5NqpiBk+da87Yasa6JGxxn9O3+BHxoo/v2IraVHEaMMvQUUCOG/mOKHBjcfIdefZOKUOQ6vcH7hU/O6NU+qw8OrJqEnE4cahYynX0hMmIuOt6qKR1QwyXVlWt5OKnt88Z+6KdgyOV6AmEe//d/np7Hq03TcjN0HdXLgfRJUwrUh3uOxsiEX+ayvmDn7dgwPqHSuDqoG7P/Hm05fGFRxIHhQvntr/njd0I5aA+FX1AMDY+a857uyHDYmDGb7GdooTqBCvICy82lDi2t0xomOiOZmqHpHryvy7JhHH0e4epHoHXk3EYxmLrEjJYz8nZzTVQLr7burKzT2DNCNRUfWE+Z5kc1WlelS22qjMs2r94qURizb8BcTJOMdjBDAygsdejJ3MWA6qrBCWYRDdf/bXRmHlxs7ABtfPIlRXk+iXiMqut56TMwrREUrWEUvkevFjKN2MtVVC2T/+7oFmKlZjLV1EPOC3q5cmAy+GX7t6CojMX12TiGNoVWWWYshLRUmZq6rp0vFCF4ydVC/j+Q27PFW1FLlsWto6A/cHcFJA5ZxCuB9UlSd+4w9uLqHkQaDlNuDV71vGx4A08/Bu43U3X74qqSSw+tboZTKXMHrHX2BkSU4yNxAB+GTBRcrjqNzTqwEVzUH0hCF6alFl2JA4hlRVYm9XEhVE6BV8TwnA4tn1uXf3RNX9EIpLKICbJlfEqoCqE8SJZxop2tVTAnhxbwT1gXt1xYjmEDSmYMXLgmGfSyQ6beULJzdL9Si1hSoMV02u0a4gJbSrJ0LkowJl0EYjKpVH3eYQJGM2XkEYNmRApSNyc8mw3leULfz71T/HsUdOL003glTmSO7uH1OCGXWjDxiuoDdkXV01ftAJXDlEtd6PiMYpdWjdeRDL39uNXmbEiISZtOa4IlTq3pi74+pEHMd7eoUNlqyKnMFx8V7Bi8uoJhHH0EGV0l352PmvKY1j3tfEvgBeWvF7PEhPY0gy3UWq1Jp6CIubCRK/7LWARMHjvOOUoiggedCYdyn8u0UAvePPIUF24mYZBdO33cuMlRs7hTVxZKlbFUTKfWi7kilUVlBWXkK8glBpSTQ7dCzVX3PH+jRzrLtH6ctEGJCnLp5dL0zcUi27YH/6sC90/17ZjCFkax0YxRK8Xso0W89d9yAw+brMILBK8xTVOj0yErXZvXi9UD0KuGJJdqN1N6L271bEaMOfQ4J0p/JSE0e2b+pllta4F40vqr9/wuDKDI29OY+5K9px54r2/oXj0LEU+iAmRsbCYd3jdXYlceeKdtQ/sDZrfm7Jb7KEuqzsYfqreIAoleD1oswRnbvpBWPnbyZdyYyp1S3k9/1XjwKaDhtJXpc94d1wxxPAFb8YSA477z6INWUSRPP2u2iWmtvPIyoduEYR0Xoi+oCIthDRHenjtUT0JhF9mP45THL9jelzPiSiG8N+A1EmSHeqoDVxTESLhZPEsutYKqOMQpeknIMXz7DpqhJdY9bRtxr/xil1GU1WrNTVJKQlHuyxir18snhCUSoB4CUzWOVcFfmpn/dvH8PMPnYy/olacQkI0wCvmgNP3yT7vIMummXYectEZcffA+AuZv4qgGkAbieirwKYD2AdM58GYF367wyIqBbA/QDOgtFr937ZAlGKBGn5F7QmjhVRAFT1vmFVuxTJMU3MGkJW7r8kO9/A7bOz5y48XXUDemKDM0+KWgkAL4XJVM5VyQFw0vFTBdBws7Ezt44x+TpjgbHuljuage6j4nHMJDB7CQi7AZZiexIQ/bu9cXe4i2YZodKBax+AfenfjxDRVgB1AC4DcHb6tF8B+A8A9tD7TABvMvNBACCiNwGcD2B5CHOPPH4rUALGoiGSaIpq4sxd0a5c1M2pnr1sfFnjkzA5dCyFlrbO/s/G72eX2WTmIqBjfDQ1+CZeGoOonutUfdLU76eSEAZYKwcBo6dljiFqCtNyG0AE9NpiKCZmPR5zPiYq8YV4wlhoPlwr/3fraJbXBPK7aJYRnlQ9RDQGwBQA7wH4cnpRAIC/wOiva6cOgPWbuid9rGxwa/kn053bDV91Io5Ubx/uTPvWAaCCgOvOGu1o9N0CoFZEun/zb3urw1xw54p2LFyzPeMzCKzBj3oJXpky5zRBu8vTZgCtS5FhrGVPMKKkM8B2L8E3R9QNTGSsRUXeVMZyNLSkvjg77dSDLJplgnJwl4hOALASwJ3M/Dfra2xkgQUSBBPRHCJqJaLW/fuz68CXIm5dqsyyxYtn1+Nodw+OdmfuuvsYeH7DLgytEmvwTQnowjXb+/MIahx85zIj2zilDkMHhaP8dase7aXpek7JVyBw0ixjd5vh2mAjaGu9Z0ezccxe6m7ydeqlHESuERF2AxlkV2y/NiHx9CZqDZeQWT3U7XN3mpNoIfRaeqPEA8FKhp+I4jCM/jJmXpU+/CkRnZJ+/RQAnwku7QRgjf6MTB/LgpmXMHMDMzcMHz5cdf5FjRfljl1ZY+VYd6/QH37tWUaRNevC8vnxnqw+APangpa2TtQ/sBZj5r+GMfNfw5QH17pq9MkyZE0ijulfqRWWlF40q961fLSX5LOckO9A4IdrIdXemwhdJJy+1obMn+1WLtmEbGYhyK7YrP+/eALQVC2fwxdHbLWBXD532ZwSteKnBS+dt8ogEKyi6iEAzwDYysyLLC+9DMBU6dwI4CXB5WsAzCCiYemg7oz0MQ3CU+4wICzItn7b/mzJZh9jaFWltM+ArI+wG9efNRo7FlyEHQsuQtOl4/H+rsPSVo6iQnF2Cto7N2gg0GroHqg1fvrZvVqPhxEEVoX7MufqVtRNRjxhuKeshd5k9KWAjc+qf+6yHfwFj8jv4dYHwaQMAsEqz+/TAfwrgM1E1J4+9gMACwA0E9HNAHYCmAUARNQA4FZm/jYzHySi/w7gj+nrHjQDvRq19o5O55nEiIT+8Lkr2oXnH06m0H6/wIcMeR9hN9Zv259Rf98OA1j+3m40nFoLwMgAdgoYF7R3bpBAoD0Qaq1oKcsaVvE/q5xj+vXDKMOw6hZjLKu/3YwZOI1vrxHkJVlM1JgdEH/u9jmFGbgvg0Cwiqrn95BnWZwnOL8VwLctfy8FsNTvBEsZL8qdeS9ukrp7rj1LrKVWXVis+N1pm755J2Pey4x5v90EEBxdVznrnatKkECgk6ETBTuBdND2mezzrQFet169fsowJGqd3T/2xcqct6wqaKI2uyroqjnq85Eh+9xzFbgvg0CwztzNM9YyBwvXbMeVU+sy3C72YKwpcVx41WRpEPe1jn3CYKhbHoGogFyQnbaK5DPVx0KjHyOSZuTmnSA1+N12haLXRX56+3E3H7XXMgzVowyNfaLW+TyRi+O8+8QlG5JdRo1+a0BUFsz1wuHd+Q2wlkELSF2WOY+4lU92e92t9DEBuH7aaDzUODHjniK5qOnLt7p14hWEM8cOwzsf5d8bJ+szUDD81uB3624lqpUfRitEp/LK8YS8m5fSk4JgHo+MdQ8WxxMAKoCUJMnLK0HKM3v994xqDwYHdD3+iOJkuOtqEjjW3SMMpJo159169JrcYDP+IuofWCvU5RNBWKFzSLwCDMpZIpfXNoqRrbvvZEhlhiuM9o5OY5i+dqdkqDfulhty4WJVrTavsPHT8tJLK8siRtfjzzOqNfed/OedXUmpesa8TtUNs/w9965KsmQs2T4gmerLUg65Ea+gLOmoCK8+fbf8h4KS4ZKB0acWcJYPhuFacBrDTc0yaRZQNVQyMInnQc6qrJzhJ8BaBiodr+h6/AHxUnPfT5tD8zpAvXyCU10cv4xIJ3hZ35Ob62nh1ZONnxKlj8mgSm/7D6f8h0js+r0GHcNQqAQdQ2pQWTyGTIFjJ1FraPRVMn1V8BNgLQOVjlf0jj8gXmrue+l0ZWLdDTdOqcOVU90Nm0qhW1n1S7c5WJk3c5z0XnWWhWLezHH9pZlFiCp0OiFbRPLSfD1XqGrMg4zhlI0qM6jSMs8qJZnJ0NUPOlFp+q74DbBK31vpqHS8og1/QLzU3LdWj1QhRpSVXKXixhkiUf9Yuf+S8Y5uGBWVTeOUOlw/bbQwQ9eqHLpn1WbXpxAv2bqyRcRpcSkrRAa+oxl46fbMbNRVtwwkl502w5u7SSmpK/20kDzkcp793y39t6yss1fKQKXjFe3qCYhXrby5CxYpeOz0MWcYfRUDCgBHu3v7d8+yAKj5805JklcfMz5ZcFF/EHXuinZhELXh1Fq8umlff8xg2JA47r9kfEaROdWAsGoOgewzyIWLKxJ4UZiIKmm+8j2jDIOskqbZ0MWtIqaVDNeSZDNiPhVIdfHpQG2uFTS5TPYqUrThD4hqEpYdq2GUuShUyykL5/XiJoDRL9cUxR4ap9RJ7z+iJuEavxAtXsdTmX24vCSEqQav6ySLreqTVFEhM+SA2HDJAplupJKG0XdSzLz6fWDjL42SDiaJWqN+/6YX5Mllbsln+aigGvUqrXlGu3oCYm/+YXWNuKl9zOqbP51d79p0xGtGbaqXs0oviNwpTklebvELlfiGzJg7uYfckMVKjn7REw1lT5h4VaSEWUnTyqvfN7KLOXNhR/Ig0Pbr7N6/VreMlwJp+aLEq2+6oXf8ISCqk3Nvy2Ys27Aro8esTO2j0nRE5lIStNJwxFxAWto6M2rsm/r9Osu9ZbV+zDFU4huyJ6Irp9Zh/bb9vnT45nkPvLIlQwJrBomt5xSMsNwXUkWKzL0icauofFOcgp0bn5W/1tsNbFltZALLiNKO2+tTVAmid/w5oKWtM8PomzgFMM3dv2o/WcAwoItn13tycZguHHsFTmYgHqMMA+zW/rFaUl65giijp4DoieihxomO79eNxil1GFKVvW8peElnILyyvh3N2SWS+yHxeLJAZsO3gAoHJVesymijKNsBu8k3kweBH40IvnPOx05c6/r1jj8XLFyzXbq32tuVdCyjYN2F2wOl1oqWNYk4mi4deM2+q47HKMPHD2S6cEQVOFO9nKGFF+3W4zHC0S96MGb+a9L338ucsfP20knLS0auF0VVXnEyLKo7SnPxkBpcFo/nFMgcPW3guFlDJ3nI+P2LIwOZu4d3GwqgN+4eeF2F1FGjJaN1Hl7I105c6/q14c8FToanOhEXBkxbdx7Eij/szjDIh46lMO/FTWjdeRArN3ZmGOAvegZ8rTJXkeiYkwvHPnf7uDVD4vj8eI9SC0Y/CVVekuEAf9VH80IYhkWl6JpsPJlbRXZ88YTscg293QPHVBu4AEailpcFzkoYC6YKZVB90w1t+HOAkz+eKLuKZTLVi+Xv7RbKEVO9LHzNblhlu2ovBtN8zX69Ocb0BW8pNWUx8brz9pqR61dRlXPCMCwqi0RYhirsna7f8fK1E3dTGZUB2sefA0T+eLNyZpfEcDpp0GWv+XVpzJs5DnFB81vTxy/D6/287ry9um6cFFUFJYyEITejHqahCnun63e8fGXYRlFllGdcd/xEtBTAxQA+Y+YJ6WMrAJgWogZAFzPXC67dAeAIgF4APaqV44odJ5XO+m37hbvtGJHUwMteUzGsTj5zp3iCCC+1hvzsvGXjM4ynDZG/30v8IG+EkTAk2pWayhyz4mZYhkp4LxcqYkCfIP5QEfe/IAXdiXtRUkVJZVQAXMsyE9E3AHwO4DnT8Nte/wmAw8ycFRJPG/4GZv6rl0mVallmQF6T/8qpdVk+fsDYhc/+2qgsH7+1Tr/Xe/ndFYvGM0WCw4bEwWy0dfRbJtktmznI3CODk3Gyv3baDPVM2tDu7V4SBBQDLn/K+N1azjlRa9TmydUc3a4rg9LLToRej5+IxgB41W74043YdwE4l5k/FFy3A9rwZ+FH1eOn/ryseqbX2vcqcw9rLMC9mmddwPsWDCfjBBhKGmtZhVgVcNkT4TQMUTWMbo1kompMw+hpUOTk0/B/A8Ai2c2I6BMAh2BsCv8XMy9xuMccAHMAYPTo0VN37typMn+NBbshlRnPQna7sjZkt6cUWXf0bk1n3Hb/kWzU4mScuo+K1TOJWnlilJddrqphFDaSyZGLKUyCdjErwo5bdrwY/qCqnmsBLHd4/evM3ElEfwfgTSLaxsxvi05MLwpLAGPHH3BeJYOqARNJIWW5moWSO9rnKEtwa5xS5xpPcFL7eJWF5g1H1YqsA46DlNKL/FFVMVOsBc2CKKnKMJPXt6qHiCoBXAFghewcZu5M//wMwGoAZ/q9XznipdOUSArJCFYTJ2xUCs2ZCh6V3gUytY+XHgl5JWzVihf5o5d7q/QGiFqtmyBKqjLM5A0i5/wXANuYWfjtI6KhRHSi+TuAGQDKw9kWEl4MmGx3zEAk5I4tbZ1KiiDzaUSld4HsySWyGb1OxilRK75GdhzwZszDrEkfVkkK+5hBFpIgEs0yzORVkXMuB3A2gJOJaA+A+5n5GQDXwObmIaIRAJ5m5gsBfBnAaiP+i0oALzDz78KdfmnjxYDJJJ8xIt+B3LAwn1zcsD+NOPUucHpyiWxGr5sbpeW2zBaFFXFDJSPDi/wxTBeO2w7Z6z3CcrX4lWiWYSavq+Fn5mslx28SHNsL4ML07x8DmBxwfmWNFwNWqOYkKjEIJxePGYdwUuqoVC+1EtmMXsC5nALgzWh6vSYs7bpTxVA/BjxfpRpklGEmr5KqJ9+UupxTFS86/FxIN/3MD8guIOek0Pnp7HrfclW3uUVO1VMqyBRCFBMXlXOTVAZV5ISBVvVoooKXnW4hdrmynby9Lr7sycVsyJ4LFU4kM3pLBdkOWZb56+Yrj4KrpcwyeXWtnojjVqffel6+69Y4BUutQWinLl+APIh954p2YecyTYGRBVLNHrt23Ay4boaed/SOv4TI9y7XTWtvLgxuTy5OC0hkNPilQJjuDNkO2Y+vPEjguQRcNIVAG36Nb0TuJSvWILTTohQkWUujSD6SlIIYcD+uljJMvAoL7erR+MZ0Lw0bkt3SL4zm6VYKrsEvdvKVpDRplmHsq0c0+SMJAAAgAElEQVQaxn/dg7lL7irDxKuw0Dt+TSCsWnu/KhqrK0i1QYzGI05JSmG6S/K5Cy/DxKuw0IZfEwpB4wt+k7U0isiUM4lh4RrqfGryo6AGKlJKxtXT0taJ6Qvewtj5r2kliIRi+Iwi21Wr2JEpZ4Bw3SX53IVrNZBvSmLHH9lqjDYKmVRULJ8RoDX4OUEWeF01R3y+X0Odz114sVYSjQAlYfi9NukuBIU2vMXwGWlyjEg5I+u65ddQy1pGnjbD33hulFniVViUhKsnstUYLRS6VLCfz6gYXEOagITtLpk0C5h8HTILgjOw6QV1dU/USj6XICVh+GWKjygpQQq9OHn9jLz0AtAUMUHKGcv4cC2yau+oxg1yUfJZk0VJGH63kgBRoNCLk9fPqNBPKJo8otJ4xQtBArxam58XSsLwF4MSpNCLk9fPqNBPKJoiJkinMa3NzwsqjViWArgYwGdms3UiagJwC4D96dN+wMyvC649H8D/BBCD0aBlQUjzziLqShCvNeVzNQfV+0W2mYnGG4WoZROkvn1imLjPsNbmh4qKqudZAI8DeM52fDEzPyq7iIhiAJ4A8E0AewD8kYheZuYPfM616In64mQl0s1MNFkIpcKxdwpTy8avzLKjGfjiSPbxWJXW5oeMSgeut4lojI+xzwTw53QnLhDRbwBcBqBsDX+kse0MG8+7D7hium5mUgTIpMIzTrgPQwrV2cqPzHLdg5mtJ02qTtCSzZAJouP/LhH93wBaAdzFzIdsr9cBsAqE9wA4K8D9NCZhP75L6qs0XvIYGufr/+GijiwQPzj5F/EFCv7ygiQbyuaVtJsWTVD8BnefBPAVAPUA9gH4SdCJENEcImolotb9+/e7X1Cu5ELuppUURY00EN93kvgCF395waS8QYLCGk/4MvzM/Ckz9zJzH4BfwHDr2OkEYG3JMzJ9TDbmEmZuYOaG4cOH+5lWeZALI62VFEWNLOD+dNUNvpKzCibl1bV38oYvw09Ep1j+vByAqJPyHwGcRkRjiagKwDUAXvZzP42FXBhpvdMqamRS4fqL5vhKziqYlDcXyWQaISpyzuUAzgZwMhHtAXA/gLOJqB5Get4OAN9JnzsChmzzQmbuIaLvAlgDQ865lJm35ORdlBO5KIIVRH6nKTgyqTAATH/9ZOztesQ4dvY4NE5y99MXVMqra+/kBWJm97PyTENDA7e2thZ6GtHEHogFDCMddGeke5eWFLK+BiqJjUGu1RQOItrIzA0q55ZE5m5ZkavHYTNt/4olxt+r5sgLZAUtoqWLcOWcIH76YsiE1wSjJMoylwXWHXliWPhjVo80SuduesE54Sdoaz3dIDsvhOWnZwB/OXwcd65ox8I123UuR4mgXT3FgMi9Y8WPq8dtTCsUA7jPWBy6j0pS6kcZTwxuLJ4giVEoXq9RYvqCt4R++rqaBN6Zf67jtSJXj4l2+UQX7eopNUQSTit+5JxuY1rhXvTnDIiMPqCuKvKqStJuIV8EKQoochOZ6AqtpYF29RQDKkbVq5wzbI2+k6rI6lKiivRConC9dgv5JkhRQDd3kK7QWvxow18MyCSc9nPCHlMVJ+mn3XiLjL7seqdkNW34XfFbFFAm57S+rilutKunGBBlNFqJJ4zArBeXiNuYgOHbd4NizvEFmUuJYnBVJemM4oIgchOZ6AqtpYHe8RcD9jK3pqoneUhdjSMb8427s/32ZrAYcA8Ac5/z7ltmpLnP6PjkRC6S1TSuWN1EnV1JxIjQy4w6XaG1ZNCqnlIgqFJGJOv8cK1tkZEEdd3uEWRuuUpWizgFqYypKXq8qHr0jr8UCOoSsabJ241t8qBhbBtuznyqANTKOgQpB+G3oUdE8GPAZbX1ATheK7tX0EVEL0Klid7xFyP2HXpQbb113NW3SlQ3owyjq2KEnZ4gRH8XkTFXxW/ZAz/6e9m9rpxah5UbO6VzcDPqUSndoBcfNfSOv5QRSRxjVUBFPLN7kdcia+a4IqMPGEZapYCWaH6bXhhwz7hJNN0WjSJZJJxKJjgZLT8Zt7J7LX9vN3ptGzurDt/tycLvewgTv09AGme04S82RCqZ3m4gUQtUDfVvIN0SuqwBVSfjLNLpWyWYbv0E7ItC6zMD5xWRjt9vyQQ/lTFlY9qNvvV8FaNesPLMFqKw+JQi2vAXEj8VMZ3a0939if+5OMUDKuIDctHDuwEQjCouyDbOTk8MTvc5vEctm7hIdPx+Sxv7aXIvu5epxrFTQSTV6VuNutN7yJf7JQqLTymidfyFQtRCcdUcoKnaWYefi6YpHc3GTl0G9wFtv7aoc3zEhcz5Oc0/aNkHP+SoJITfkgl+KmPK7nXtWaOEenzZkwCQuTDJxj3n9OF5a80oWyh1ElkwtOEvFMLdrWUXLeuje9oM8Xiy4264+fYB47Xebn/jAwDIeE+LJxjzlLXXU128wtLx56J/cZp8ljaW3euhxokZx2NEjuOIFqbB8Yqsv1/r2Je31oxBag5p5LiqeohoKYCLAXzGzBPSxxYCuARAN4CPAPxXZs7KxiGiHQCOAOgF0KMacS4LVU9TDVx3ziJVTtjVLWXjBYVi6cXE4hYCDCM/+TpxwFalYmiYOv4IVgrNpZJm7PzXpN84e3KWU4VOGQTgkwUX9f8tcgcB3usHaVWPGmGrep4F8DiA5yzH3gRwT7q94iMA7gFwt+T6c5j5ryqTKStUauWIXBphlzHIRfkD07hvfFYc6P1wrdiwirKJ40OBykEDWcphqnoiWBIil8FMp1iAGfAFjCcIpwqdTuObiNQ4817cBDCQ6uP+YyoKHb81hzRyXF09zPw2gIO2Y2uZuSf95wYAOofeKyq1ckQujbB9/CrXVcQNyaj8BENVZNbemXydIeF0C/TK6LEYp9RR4+8rlhiLRZhB3Qg2mc9lMFNWg6eXOctX7/V+dveLaOFI9XK/0TfRZZ4LQxg+/m8BeEPyGgNYS0QbiWhOCPeKPqrBwowWioDxoGxBpsMXLRhBGqOLxquIZxryxp8Dlz1hmaudPkNK2tRlGOcP17qoc1j+2bjJPcMk7M8yBHIZzLTHAkQuf9MQu92vJhF3jF94WTis597bshlfued1jJn/Gr5yz+u4t2Wz8jgadQLJOYnovwHoAbBMcsrXmbmTiP4OwJtEtC39BCEaaw6AOQAwevToINMqHF7rx9tLJahIO8MuY+BlvEmz5LEJ6y5eqX+A5LPJp/slgiUh/Mg5vWC6TVraOnHninbhOXu7klg8u96xC1fTpeMd3S9upZ3t5wKG0X9+w67+473M/X8/1DhRaSyNGkolG4hoDIBXzeBu+thNAL4D4DxmPqYwRhOAz5n5Ubdziza4G8FgYeiovEcvAWPrdW4lI0rlM3QhzGCmbCxZaQhgoDyEea2fCp1egsPDhsRx/yXjcVfzJqHUNEaEjx6+UO0NlzE5L9lAROcD+HcA/ywz+kQ0FEAFMx9J/z4DQA6e1yNEBIOFyqg+cagUXROdI8P8bJxkpQV2v+SbsIKZTuUOnFwx55w+HGf88A0kU30AgAoCrj1rlPKu21wwkqleaRKZlUPHUrhn1WbpeW7Xa7zjaviJaDmAswGcTER7ANwPQ8UzCIb7BgA2MPOtRDQCwNPMfCGALwNYnX69EsALzPy7nLyLqFBM9eOthj4xDPjiyECtHzOZbNcG4OJFmdepuEdE58gKyZn+/u6j8oYtZm+AxRMi45IpBpwUQjJXzNCqGF7YsAt9lmN9DGWXi32x6WW2C3qFeFUQBaXcJaKuhp+ZrxUcfkZwDMy8F8CF6d8/BjA50OyKjSAliHNFv4HfPaCtT9RmGnqZQW5dCoyelmlgvcQi7NfJngKc3EKcNkG6965nnBRCIh9+Ih5DPFaBoxAb4eXv7XY1/KLFhpGVzREKVuNdMyQOZuBwMuVqyHXhN12rJ1wKHSwUFU+z1tA33SiypipZMLDqFmNMc/F66faBLN7Du42/Aff3mPHZeEgYqx7pr/eunzpIEaOlrRNNL29BV9JYoE1fuKpxku3qGYaBvnJqHdZv25+x650rCfgCai4X2WLDMGIHe7uSAAGioUhyvE6gMLIb70PHBirTuhlyXfhNG/7wUSldnAtEiqLWpQhln2XusKkiu3RDb7eRcKXyns3PRiVrGRh4WlolUQLLYide1VURpKWtE/N+uylD937oWMpIgoLaznTezHFZY5h0diWxcmNnlgzTDOaKcCv5AMgXG2s/gfoH1vYvZlYSlRVgkJKiyS3BzMmQ68JvulZP6eBU+ycMUknDDy9C+QkijUrMw9qE3WuiVT5zAXLEwjXbhQY71cveEp4cbLUoeWrezHFSo3DtWbI8DoOWtk4c/aIn67jdeB8WGH1jPn3K9Y1UjLRsAdOF3/SOvzToaM5NvZ1c4ar6oUzpptfYSTGrq9I4GTbVnenCNduR6nVe/O1jmUb2nlUd/aoeABgSr0DDqbXScWTyTat7yvTJy2Y0oiahrGhSyROg9Lzs4+U6V6IY0IbfJNc+4VyNb7o1pIQZVpOMlZAbBCHm+5Zq9keKz1f9/IpJXSXBybCp7kxVFgjRWAPGf8A4Hkv1ZfjN7aqYY909QtfLkKrK/vOddP3xGHkyvCLjbceMZdgNv7XDmFb1lDO59gnncnyn5iVmsbRWoQjLG+ZY7z+X2eKxIg5c8Ij38cz3rbqT9xI7iaK6yiPnnD48I4vVJFYhNpAieaLbrpgAqbF1CoAC2W0bZZiLj2vRN497E7vxll0uW/zCLvxWbPJQ7eMH1H3Cfpt2ePE5e72Hk4unMmHIMaU1dtyDdcZpaS39xYuMuj3Vo5BRxydIuYj+ekWU6dcX4asOksK4EWT9tv3C4ycOqswyKOZu2t4Y5ZzThwuLspkw5EFipwCop8qdBKWib6k+b7ELu6GtScSF5wX127e0dWL6grcwdv5rmL7gLWGzGdnnn4vGNGGhd/yAmk84yK5d1efs9R4dzXB05SQPGtePPFO+QMSq3JusWN0x5s7bdF2tmjMg9/RjWFV38kHqIBUhMkMpCozKdufrt+3Hw1dMlJZCEMkkTZzaLnpRvzAD8367CdWJuFDJY0V1XJEOPx4jxCsoIyAe1G+vqvcvRnmo3vEDaqqRIEoRlfHNOjVe7rHuQbg+I6eSwI7fS15koOqEgZ0xyXeHGZ2pnDpX5aiVYSkodbwg26lWEGXtJGUGszO9OzezZ624GUWnzleyucmeH1N9jO6eXsenD0B9dy4r+XzC4MpQO565ubtMilEeqg0/oFaeN4hSxG18t/aHQVUqTm0VkwcNBU1TFzD1Jvl5ViMrM8Jv3J2zVoZRUOqoPPaHhVPtfLsbwclgmrt2M3sWUDOKTq0jRXNzkxAcS/Xhyql1jk8Z55w+3GGEAWQGtetYCu/MPxefLLgI78w/N/BuW9WgF6M8VBt+QM0nHKRph9v4TgHaoPcGnHfywIBh/nCt83mmkZUZ2+TB3O3KC9w0Jd9+XNPwipKmzF2nuRB1diWVojVm9qyqUWycUic0pI1T6nDl1LqMe1oXFhnrt+3HO/PPlfrjZXENO/kytKr3Kca+wNrHb+LmEw6qFHEa32nX6nQPlSqYphqn7ddyX76Zeeu2e04MM36qtI20EsauvMBKnXz5ce1BS1mZBHPhMeekKorx634QyTft93SbQ2dXEi1tnVJfv+rc8qXDV71PMcpDteFXJZd1eGSGlCqc1ShuenjAMPoXLzLUPatuEZ9jZt66GfTjXcbTgZeyy+a4QSlwHaR8+HFFwUSZCyVGpK6sseBnV3xvy2Ys27Crfx5uiVMVZFT0tEMAml7e4mluTjLJXBtaL/cptr7A2vB7IUyliL0sckUM6LP9j+zmojHnJKtlAxhF2swKmzLDb+Jm0LnPeP2Sx4z/nBYcE9mu3E9CWwGVOk4ql7BQrWyZiMd8GX0/u+KWts4Mo+9GTSKOpkvHC7t7MeCo7LHPzU1Vkw9DW2wGXRXt4y8EdlVM8mC20QeMRKkgqiEg08cuy7CNDzV+mrEIpwXHWhWT++TnmYieWJxUQRElH35ct8qW1iCrLEhq97N7CeiaWIPYdzVv8pRbpVDHTXqdfW6qqhqNd5R2/ES0FMDFAD4z2y8SUS2AFQDGANgBYBYzHxJceyOAe9N/PsTMvwo+7SLHLZhrRVU1ZC2XLBvjgkeAVd8BYDPYfSnD6Fp31KvmQOq1NcdLDHMu0GYmjtkbqPgps1xg8uFeUKlsaUXkfxaVWraWWJi7ol143Dz/nNOHY+XGzoxGKl7oOpbyZZhFtylGmWSxoOrqeRbA4wCesxybD2AdMy8govnpv++2XpReHO4H0ADDimwkopdFC0RZ4SXYqaoaeuNuuRE2x5Cd19stMLoO/8NXjzQWii+OyM+JJ4x+AKKkK9miF/Eiarl+7PcStPSyEIlcJvNe3IQfrOrAMUshts6upCe3jgi3BK8aSSKX6AkmH+61ckXJ8DPz2+mG61Yug9GSEQB+BeA/YDP8AGYCeJOZDwIAEb0J4HwAy33NNioELbimrIohuWrFPgennbd1DNl55nxUir6Zu/Y+ib+2epTzzt7sBJZ1nWCRC/pZF1FDFrsxr07EQQTMXdGOhWu2Zxl2p4Xo3pbNWP7ebumOPdXLwsqdQcv5Hf2iR5qla/r/VRc3XUUzdwTx8X+Zmfelf/8LjB67duoAWC3cnvSx4iUM/7QooUuI4H/DjmbgkbFGoNY6B5mKOlGbaehk/nvzuKsbii33Fg5kJIRNmiU/h3vdE+YA8We9ag7QVK2WFVyEsQRTO794dj2Odvfg0LFUf97AvBc3KeUN3NuyGc9v2FWQJuVdyRSOdvcgXpH5faT0a2bnL3OHb6qTzLwEE3vDdiCcbFyNQSjBXWZmBNwsENEcImolotb9+9USOQpCGKUD7AldXkslyHrk2o1/PJFdOVOmwjGPB3W3WHftTouMShE1p+YyKkY8z2UewszsfeCVLVk78lQv44FX5HJIk+XvFbY3g7V8ApCpSjI7f5kF5MzFyZoQZ02WA4w4g7nT10Y/HILIOT8lolOYeR8RnQLgM8E5nRhwBwHASBguoSyYeQmAJQDQ0NCQ/62KKmGVDrAGUp0akVuDniq78epRmT13zUJqppujepSkVn06EOsWsHXCvmt3WmRUpJlun6lbQDiPZR6CNPAWadWtPWStWI/LNO5BdvoEoLICSCkItpzoOpZC230z+jOLrSRTvUI3lFWxI1Lz3NW8KSs4XSrku6xzkB3/ywBuTP9+I4CXBOesATCDiIYR0TAAM9LHipdclA4wnwBkuJVKMLHKNZMHjTr8djfHaTPkbpaOZqD78+xxK8Qp9hkIy1xIykFLy0Tbz1P4TJ0+kzyWefArPZSVgnDDqYSEU29cgtEVy+6KMWEEN/rAQABWFuiVLU57u5KO1xRL2WMvFKKss5LhJ6LlAN4FMI6I9hDRzQAWAPgmEX0I4F/Sf4OIGojoaQBIB3X/O4A/pv970Az0Fi0qBd38MGmWg6EcmflTREXcMNqmoRf1x00lgY3PGtm8VjfL5OvSTwa3iCWhfdl9VDPnN2rAr28l6Gd12gz3c5w+k9NmQOj+ykGZB7/SQ9mCITPdBPTr62ULjaw37pC48b/7kKpKzD5zlGPBtCAQDOM1fcFbqBki3jTIFqcRNQkl1U4p6fkLka+gquq5VvLSeYJzWwF82/L3UgBLfc0uioRZOsCuODlthpFpK6tHI8usNXf6Ki4a7jXuYe7OndxMAxc5j3l4N/Dq940ib6LPxO9n5VY0zk31tOkF29zJWOR8qnqcHsf9Sg+dkrbs9eXN44DzjvmhxokAkOVOMaWbpp/94SsmYu6K9tAac9rn2NmVRLyCEI9RRrzCzDew5guYx03FjltbRaB09PyFyFfQJRv8EEbpAFFjkU0vGIZJZkCdDGlTjfq9PcUNFLG2d7Q3SfH7WTm6tgho+JZ8bFlg2HUxEePmw/crPXRK2po3c1z/QlNBpOS7NxeahxonouHUWqkBNXeUKg1SgmBfuKzN1xtOrXX0a7u991LR8xciX0Eb/kIhU5xsWQ1UDZVfJzOkfitm5ippKoxMXGnxuhhw+VPOY4cc2HWrzuk3s9dpwbCOO3b+a65ztC80bi0Szc5V+eS4JYDglIdgfU3UqL2U9PyFyFfQhr9QONW0N102Xto7+q2Y6XXB8ELQRUVWilmlf67sffkM7Ko8jvvJ7FVdMFQap185NdNYulXRJECYxJVLkqleNL28xdMCWYxlj71QiPdHXIAkDzcaGhq4tbW10NPILYsnqBtcM3jqhtm+UaVipicfv+3ayoRaPEFlZ+6GvYopACQPuccLRO9LddEQIJIlAvI6OmEj2vXK5qJyrgqEgRIMZh0fsw5QzZC4VHLqlUQ8phOzQoCINjJzg8q5ujpnoVDO3oWxQKj0sZ00yzC0Tthll6LuYA03D/ydqE0Hjy2JVhc8ojZ37g2eKTtplrHoXbEE6EmmFxyFLFyVrmoeKHSXJWsrRBnm04ebi0cVBvDO/HNx/bTR+Mvh43h+wy785fBxXD9tNNruU1BcKSJSsOSzzWU5ol09hcIeqKUKh506DTwdKLl/KpBVgTNWBVz2hPgavwFY6078i8Pi0tJhVd30U9EzxPr9UXA3mK4k2dOHm3beK3U1if7yDya9zBl/h4V1zkGS4TRqaFdPVGiqgaeqFzL3j8yFFB8KDKnNlI7K1ENecXVbkdHMPQjSzyeEsYsMWbDTLMns5tu3MyRekVGl0xzv4Ssm4q7mTUJFTYwIJw6u9KQIqkkXnRO5iGJE6GPub+soOidfbrViRbt6ihGvQUevqpXU0cwsXlFWr1+XjGqvXr90NBtPRCIkn1sxuAr8ztHq9jGbs5i6eK9GHwCGDR2En86uz2r24lT+oZcZTZeOl2YAixg6qBL3XzI+y2VmjmdmrcpiB6Wi248C2vBHBS8+fyD8cgRBipe53fOLI/4XlVe/b9QaErnBJFm4hUiB90rYc3ytY59vv/7ermRGVVDAKAU9fcFb0o5aMSI0TqnDwqsnZ1TaVLmPddFyu8ZKqej2o4D28UeF/s5XLn1xgWyDl9W/Ny6vle+EdefupY69m5TUbCGp6krqv7eD+8is8CkY001zHwWCzFHkAw+CaVBF41aQ2MFmloWwS1inPLhWumM37+M1PwEoLd1+FNA7/ijhVK/HxK5OEfXvJcpU4sh67WaNPVI8picFjQRVTX/GvR3gPulCUgwt+4LMMYhqx76/thpU0bh9bMQAzJ15jAg3TBvdXxbCxHRbOUk8RYZbtouvScSFridNOOgdf9Rw2j2bO32rwROpXXq7jezfuz8x/lbR6lufImQKmjfulj8FmAoaWaBX1QWlWkLCYbxiaNkXZI5+FzB7GQi7Mkk2bjLVh08WXCQd996WzUotG0WGW5a12nTpeG3oc4je8UcNc/csamIi8sOrBHndtPr2pwjZbjt50P0pQKUiZ0ezOC+ho1k9qc3MbRA8hfjW3MvmlQOC5AW47ZJlmAvNO/PPxScLLsI788/NMK7VCXElTafFqKWtU8no10jGFgWq9e4+9+gdfxSZNMsIaIqwG3ppPZsKw4BZd+aqPnZZT1w7Ih29W0VOUXG6V74H7NqQrqbpAUlOgy/NvWxetrHDIkhegNsuWabzByDVw7e0deJod3b57XgFOS5GC9dsdzX68QpC06Xjpa/nuom9Jhut448qUpeJTb+v6sbxkrXaVO1hohIdvSw4LHtfqouNCNWSFk6oft4RwalEtFvJBrsevqWtU6rXHzYk7pilO3b+a46Gv64AiW7lihcdv97xRwGRkZQVKLPLF1UygL1mz8raMwrPFfjanXbPMteUX6PvNGYYY+SqemlA3CpbAsCdK9qFr4uyZGV6/a50sFa20MhiFQRg8ex6bfAjim8fPxGNI6J2y39/I6I7beecTUSHLeeE3/qo2JEpaAD1WjNmPZumLkPtIsKLARP56WNV2S0YZd2snMoryIKyTg3n3QijlWIe2zSqEDQBrXFKndTfb/XZuymERtQkHHMORLEKAnD9tNGBjH6Q918MyXuFxveOn5m3A6gHACKKwWisvlpw6v9m5ov93qfkcTKSonaGboRRjljmpxcdE81PunveDVzxC/GTzOTrsruPqRBWK0XVJ6w8EFatGlEsgACcc/rw/r+dFEJmsNkp58B0GTm5nbzGMUTvf+6KdrTuPJglI1W5Vtf5ySYsV895AD5i5p0hjVc+hO1i8GLAZH54awIVxYyf6x40Xlfxd0tr/KdV5Jc8Jr7v6GmZx7uPiss/U8x4sglaY8hKmC01AxJWAlrjlDq07jyYobphACs3dqLhVCO3Q9bdKkbUr66Z6+IykrmdZAb8zhXtjr5/0ftnAMs27ELDqbXSey1cs13odopa8l4UCMvwXwNgueS1/0JEmwDsBfBvzLzFzw1SqRT27NmD48eP+51jNLlgpbiZeUUlsHWr9/HiE4GLXwWOHwb6Uhh8bB9GnvwlxCddmXmem7rGPG763r02hVk1B9k5n+z8JGNXHoVcU9+VEKt5BiHMBLT12/Zn/SuYzVC+6OkTGn17fXy/OQcyAw4478Sd+hCLDLhK/4EoJe9FgcCGn4iqAFwK4B7By+8DOJWZPyeiCwG0ADhNMs4cAHMAYPTo0Vmv79mzByeeeCLGjBkD8lDfI9IcOwgcTmUHNqnC8OkPUcy4lcDMOHDgAPYcOYKxQOYOXxYE3visPNCqGiSeNEteesLLk0yEduH5JMwENJnBk1XVtO70Tfy2BnQztrKduFO3MdGYKpnMUUreiwJhJHBdAOB9Zv7U/gIz/42ZP0///jqAOBGdLBqEmZcwcwMzNwwfPjzr9ePHj+Okk04qMaO/W2D0Y6EYfQAgIpx00knGU5JZ7MwMIsuMu5u6RtVwy8o3eA2WWgPXCjGPUgjshVhCArYAAA8LSURBVNn0xavB62POMsR+k6z8ZiHPmzkuq7SE05huC4yu85NNGIb/WkjcPET0f1DaUhPRmen7HfB7o5Ix+gBwZJ9YgVMRC8XomxCR4StvXQqlev9u6hrVEssqGbwhUwxVOVUIM5tVtogMG+ItS9es3inK+PVyb5X7NU6pw/XTRjvWFVKZM6AzgWUEcvUQ0VAA3wTwHcuxWwGAmZ8CcBWA/4eIegAkAVzDUcwYKwS93Rl/dh0+ghdWv4HbbjJ2tHv37sX3vvc9vPjii8HvdfwwlIx+EHWNnQK4aYqhKqcqYWWzyjKEAfhy3/i5tyw5jDBQuE2k/mk4tVZJESRzRWmDLyeQ4WfmowBOsh17yvL74wAeD3KPkiVWlWH8u/52BD9/7re47eYbAAAjRowIx+gfOygOHpuIFDKjp8l99MlD6vfOc7C0GKpyFgKnRSRMGabs3kD2ImPV+sskmA9fMVGp41YU2mIWGyVbpC1sX++OHTtwxhln4JZbbsH48eMxY8YMJJNJfPTRRzj//PMxdepU/NM//RO2bdsGAPjoo48wbdo0TJw4EffefRdOGDoE2NuGzz/+I847+xv4x5nXYeJ5s/DSmv8AAMz/H4/ho517UP/NazBv3jzs2LEDEyZMAABMmzYNW7YMiKHOPvtstLa24ujRo/jWt76FM888E1OmTMFLL72UOWkzjiCFgKk3peWXe4zdeUezc3loa+nmPBU0U0X2yF8Mgb1CxCZk7puwXWYi19Xi2fX9mnynJ7Wg70UjpiQNf658vR9++CFuv/12bNmyBTU1NVi5ciXmzJmDn/3sZ9i4cSMeffRR3HbbbQCAO+64A3fccQc2v/f/YWTtgOEZXAmsXvIw3v/P9Vi/5nXc9eBiMDMW3HsXvjJ2LNo7NmPhwoUZ9509ezaamw3Dum/fPuzbtw8NDQ340Y9+hHPPPRd/+MMfsH79esybNw9Hjx4duFAWRwAAEDD2G4ZbR1Rx08lH77Vef54IMyiaT6IWmwjDENtxMsz6SS3/lKThz8UXFwDGjh2L+nqjNd3UqVOxY8cO/Od//ieuvvpq1NfX4zvf+Q727dsHAHj33Xdx9dVXA0f24brGmf1jMDN+8PBjmNQwDf9y6dXo/Mt+fBobAQz/ByOwK2DWrFn9bp/m5mZcddVVAIC1a9diwYIFqK+vx9lnn43jx49j165dAxfa4ggZXLEEOPixPGtYVMrZ1M87ZRsXkGIt8Zur76tf8m2Ii/lJrVgpySJtufriDho0qP/3WCyGTz/9FDU1NWhvF2c2AsgyvstWvYH9Bw5h4xvPI37qmRgzZoxrUlpdXR1OOukkdHR0YMWKFXjqKSOMwsxYuXIlxo2T7GhtcYR+qkeplX6W+ei9ZBt7aeEYAsVY4jdqO958N7JRzRMIK+6gKdEdf752EF/60pcwduxY/Pb5XwKfbgF3vo9Nb60Ejh3EtGnTsHLlSiBWhd+8tKb/msNHPsffnVyL+OChWL9+PXbuNKpcnHjiiThy5Ij0XrNnz8aPf/xjHD58GJMmTQIAzJw5Ez/72c9gCqXa2toyLzrxFCNRy0o8AZw2w/DLy5Q+blp71YJmEXUJRY2o7Xjz7TJTeVKLmjus2ClJw5/PL+6yp5/AM888jcnnXI7x51yFl974f4HDu/HTh5uwaNEiTDpvFv68Yw+qv3QCAOD6Ky5Aa8dWTDz3ajz33HM4/fTTAQAnnXQSpk+fjgkTJmDevHlZ97nqqqvwm9/8BrNmDeyWf/jDHyKVSmHSpEkYP348fvjDH2ZeNKTW2N1XVKLfXWPKNWVBXxWtvapGP6IuoagRtdhEIVxmTjEAs1+AF3dYKSTy5ZKiacSydetWnHHGGcpj5O2x8NMtQnfKsS96kRgzFUSE3/zqaSxf/gJeWvoTw/1y4imhJmm5kfHZyRqOAMbCoOqKUXHhNNVA/FQhad5Sxmg3hhi3OjwEZPUDFl1TDrp+3YgFefT1SgKoG9s34buNN4OZUVNTg6VLlwIj/s/cz8cNackF8tZpSkWjH0aJ6DKhGGMT+UClX4DKNcWayJcrStbw5w1JAPWf/q9p2LTp5gJMyIV8GmNRieiKuFFCwtoPGCi7QmwaNVT6Baheo+WhA5Skjz+viAKoVGEcjyL5rKFjl4QmagGidI39dLD3pduBltt0AFgjRBbgFlURdbtGy0MH0IY/KGYANVZl/B2rCq26Zk5w0ufn6n5mdc2qodlPR73dQJ+tRLAOAGvSyALfP5k1Weq2iVqwPIpoV08YDKmNrqEXUaiGI15q8Ue0ybkmv/ipw6Nr97ijDb8mf0hbMkrO1WjgL/Ctg+XOaFdPHnnqqafw3HPPAQCeffZZ7N27t/+1b3/72/jggw8KNbX8IIovxKqMgK+VAjU512jKBb3jzyO33npr/+/PPvssJkyYgBEjRgAAnn766UJNK3/IavSLjmlVj0aTM8LoubsDwBEAvQB67AkE6Q5c/xPAhQCOAbiJmd8Pel9XQq4Rs2PHjv7yy++//z7Gjx+P5557Du+++y7+7d/+DT09Pfja176GJ598EoMGDcL8+fPx8ssvo7KyEjNmzMCjjz6KpqYmnHDCCRgzZgxaW1tx/fXXI5FI4N1338UFF1yARx99FK2trfjoo4/6K3Q+++yzaG1txeOPP47nn38ejz32GLq7u3HWWWfh5z//OWIxl45ZUUMWX9CGXqPJG2G5es5h5npJ1tgFMBqsnwajmfqTId1TTo5qxGzfvh233XYbtm7dii996UtYtGgRbrrpJqxYsQKbN29GT08PnnzySRw4cACrV6/Gli1b0NHRgXvvvTdjnKuuugoNDQ1YtmwZ2tvbkUgMuD+uvPJKrF69uv/vFStW4JprrsHWrVuxYsUKvPPOO2hvb0csFsOyZcuyJ3nsoJFNvLfN+HnsYKD3rNFoSo98+PgvA/AcG2wAUENEuRW556hGzKhRozB9+nQAwA033IB169Zh7Nix+Id/+AcAwI033oi3334b1dXVGDx4MG6++WasWrUKQ4YMUb7H8OHD8fd///fYsGEDDhw4gG3btmH69OlYt24dNm7ciK997Wuor6/HunXr8PHHH2debDZeMSWTvd3G391Hs2+k0WjKljB8/AxgLRExgP/FzEtsr9cBsEo59qSP7Qvh3mK8lA32gL3Ze01NDQ4cyO4dX1lZiT/84Q9Yt24dXnzxRTz++ON46623lO9zzTXXoLm5Gaeffjouv/xyEBGYGTfeeCMefvhh+YWixivcl+65qykFdE0fTRiEseP/OjP/IwyXzu1E9A0/gxDRHCJqJaLW/fv3B5uRatlgj+zatQvvvvsuAOCFF15AQ0MDduzYgT//+c8AgF//+tf453/+Z3z++ec4fPgwLrzwQixevBibNm3KGsupDPPll1+Ol156CcuXL8c111wDADjvvPPw4osv4rPPPgMAHDx4sL+kcz+yxitOPXc1RYMuTawJi8CGn5k70z8/A7AawJm2UzoBWBu4jkwfs4+zhJkbmLlh+PDhwSaVo7IE48aNwxNPPIEzzjgDhw4dwty5c/HLX/4SV199NSZOnIiKigrceuutOHLkCC6++GJMmjQJX//617Fo0aKssW666SbceuutqK+vRzKZ6ZYaNmwYzjjjDOzcuRNnnml8nF/96lfx0EMPYcaMGZg0aRK++c1v9nf76sfMHrZTocVbpUDUOnVpipdAZZmJaCiACmY+kv79TQAPMvPvLOdcBOC7MFQ9ZwF4jJnti0MGYZRlzoWq5+KLL8af/uShgmW+MX38VncPVWDrZymcMVmpWqsmwoyd/5qsyHVWaWJN+ZHPssxfBrA67fuuBPACM/+OiG4FAGZ+CsDrMIz+n2HIOf9rwHuqUaiyBIXELBtxZJ/h9jFr/3d9Wth5aUIh3y0RNaVLIMPPzB8DmCw4/pTldwZwe5D7RIExY8ZEe7dvIqwbpA1/KaDam1ajcUM7fzWaIkEXH9OERVEZfmbOklRqnIlia02Nf3TxMU0YFE2RtsGDB+PAgQPakHmAmXHgwAEMHjy40FPRaDQRomh2/CNHjsSePXsQWONfZgwePBgjR+oSxxqNZoCiMfzxeBxjx44t9DQ0Go2m6CkaV49Go9FowkEbfo1GoykztOHXaDSaMiNQyYZcQUT7Aex0PTEcTgbw1zzdqxjQn0cm+vPIRH8eA0TtsziVmZUKnUXS8OcTImpVrW9RDujPIxP9eWSiP48Bivmz0K4ejUajKTO04ddoNJoyQxt+wN4xrNzRn0cm+vPIRH8eAxTtZ1H2Pn6NRqMpN/SOX6PRaMqMsjb8RLSDiDYTUTsRtbpfUVoQ0VIi+oyI/mQ5VktEbxLRh+mfwwo5x3wh+SyaiKgz/f1oJ6ILCznHfEJEo4hoPRF9QERbiOiO9PFy/X7IPo+i/I6UtauHiHYAaGDmKGlx8wYRfQPA5wCeY+YJ6WM/BnCQmRcQ0XwAw5j57kLOMx9IPosmAJ8z86OFnFshIKJTAJzCzO8T0YkANgJoBHATyvP7Ifs8ZqEIvyNlveMvd5j5bQAHbYcvA/Cr9O+/gvHlLnkkn0XZwsz7mPn99O9HAGwFUIfy/X7IPo+ipNwNPwNYS0QbiWhOoScTEb7MzPvSv/8FRl/lcua7RNSRdgWVhVvDDhGNATAFwHvQ3w/75wEU4Xek3A3/15n5HwFcAOD29OO+Jk26X3L5+gKBJwF8BUA9gH0AflLY6eQfIjoBwEoAdzLz36yvleP3Q/B5FOV3pKwNPzN3pn9+BmA1gDMLO6NI8Gnan2n6NT8r8HwKBjN/ysy9zNwH4Bcos+8HEcVhGLllzLwqfbhsvx+iz6NYvyNla/iJaGg6SAMiGgpgBoA/OV9VFrwM4Mb07zcCeKmAcykopoFLcznK6PtBRnPrZwBsZeZFlpfK8vsh+zyK9TtStqoeIvp7GLt8wOhE9gIz/6iAU8o7RLQcwNkwqgx+CuB+AC0AmgGMhlEhdRYzl3zQU/JZnA3jEZ4B7ADwHYt/u6Qhoq8D+N8ANgPoSx/+AQy/djl+P2Sfx7Uowu9I2Rp+jUajKVfK1tWj0Wg05Yo2/BqNRlNmaMOv0Wg0ZYY2/BqNRlNmaMOv0Wg0ZYY2/BqNRlNmaMOv0Wg0ZYY2/BqNRlNm/P+64EWGOC/FmQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'wf2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a0199e9039e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mwf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wf2' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_xor(N):\n",
    "    X = []\n",
    "    Y = []\n",
    "    offset = 10\n",
    "    std = 2\n",
    "    for i in range(N):\n",
    "        idx = np.random.randint(0, 4)\n",
    "        if idx == 0:\n",
    "            s = np.random.normal([offset, offset], std)\n",
    "            y = 1\n",
    "        elif idx == 1:\n",
    "            s = np.random.normal([2*offset, offset], std)\n",
    "            y = 0\n",
    "        elif idx == 2:\n",
    "            s = np.random.normal([offset, 2*offset], std)\n",
    "            y = 0\n",
    "        elif idx == 3:\n",
    "            s = np.random.normal([2*offset, 2*offset], std)\n",
    "            y = 1\n",
    "        X.append(s)\n",
    "        Y.append(y)\n",
    "    return np.asarray(X), np.array(Y).reshape([-1, 1])\n",
    "        \n",
    "\n",
    "N = 1500\n",
    "X, Y = generate_xor(N)\n",
    "\n",
    "print X.shape\n",
    "display_N = 300\n",
    "neg_idx, pos_idx = np.where(Y == 0)[0][:display_N], np.where(Y == 1)[0][:display_N]\n",
    "fig = plt.figure()\n",
    "# ax = fig.gca(projection='3d')\n",
    "ax = fig.gca()\n",
    "ax.scatter(X[neg_idx,0], X[neg_idx, 1], label='negative')\n",
    "ax.scatter(X[pos_idx,0], X[pos_idx, 1], label='positive')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "X = torch.from_numpy(np.hstack([h, w, iid, iid2]).astype(np.float32))\n",
    "# X = torch.from_numpy(np.hstack([x1, x2, y1, y2, y3, iid, iid2]).astype(np.float32))\n",
    "# X = torch.from_numpy(np.hstack([x1, x2, y1, y2, y3, iid, iid2]).astype(np.float32))\n",
    "\n",
    "# X = torch.from_numpy(x1.astype(np.float32))\n",
    "# X = torch.from_numpy(np.hstack([x1, iid]).astype(np.float32))\n",
    "# X, norm = sklearn.preprocessing.normalize(X, axis=0, return_norm=True)\n",
    "# X = X.astype(np.float32)\n",
    "# print norm.shape\n",
    "Y = torch.from_numpy(bmi.astype(np.float32))\n",
    "# Y = torch.from_numpy(y4.astype(np.float32))\n",
    "# Y = torch.from_numpy((bmi > 25).astype(np.float32))\n",
    "print X.shape, Y.shape\n",
    "batch_size = 128\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "DNN_model = SimpleDNN(X.shape[-1], 16, 1, 2, F.relu)\n",
    "model = SelectNet(X.shape[-1], DNN_model, DNN_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "gamma = 0\n",
    "epochs = 1000\n",
    "iters = 1\n",
    "noise_std = 25\n",
    "noise_col_idx = [2, 3]\n",
    "writer = SummaryWriter('./AE_logs/XOR-a%f,b%f,g%f' % (alpha, beta, gamma))\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_masked_noise(x, noise_std, noise_col_idx)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_masked_noise(val_x, noise_std, noise_col_idx)\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "#             mask\n",
    "#             x = mask_column(x, mask_idx)\n",
    "#             val_x = mask_column(val_x, mask_idx)\n",
    "# \n",
    "            model.train()\n",
    "            out = model(x)\n",
    "            reg_loss, w_loss, entropy_loss = model.calc_reg_loss(F.mse_loss)\n",
    "            mse_loss = F.mse_loss(out, y)\n",
    "            loss = alpha*reg_loss + beta*w_loss + gamma*entropy_loss + mse_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "            \n",
    "                out = model(val_x)\n",
    "                val_mse_loss = F.mse_loss(out, val_y)\n",
    "#                 noised\n",
    "                noised_mse = F.mse_loss(model(noised_x), y)\n",
    "                val_noised_mse = F.mse_loss(model(val_noised_x), val_y)\n",
    "                \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            w_prine = torch.sigmoid(model.w).cpu().detach().numpy().flatten()\n",
    "            w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "#             buf = ','.join(['%d:%.2f' % (i+1,x) for i,x in enumerate(buf)])\n",
    "            buf = ','.join(['%2.3f, ' % (x) for i,x in enumerate(w_ratio)])\n",
    "            pbar.set_postfix_str('loss: %.3f, val_loss: %.4f, w_loss : %.3f, entropy : %.3f, regularizer : %.3f                     %s' %\n",
    "                                 (mse_loss.item(), val_mse_loss.item(), \n",
    "                                  w_loss.item(), entropy_loss.item(),\n",
    "                                  reg_loss.item(), buf))\n",
    "#             if mse_loss.item() < 100:\n",
    "            if epoch > 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/mse_loss', {'train': mse_loss.item(),\n",
    "                                                     'validation': val_mse_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_mse_loss', {'train': noised_mse.item(),\n",
    "                                                     'validation': val_noised_mse.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_loss', {'train': w_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/entropy', {'train': entropy_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w\\'', {'w%d' % (i+1) : v  for i, v in enumerate(w_prine)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_ratio', {'w%d' % (i+1) : v  for i, v in enumerate(w_ratio)},\n",
    "                                                     iters)\n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(Y == 0)[0][:200].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 329264/1960000 [10:27:59<50:33:23,  8.96it/s, acc : 0.949, val_acc : 0.590, loss: 0.126, val_loss: 5.2966, w_loss : 0.001, entropy : 7.991, regularizer : 0.238 w16:2.47,w256:2.61,w240:2.90,w128:2.92,w224:2.94,w106:4.45,w104:4.45,w89:4.46,w121:4.48,w119:4.55] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 17%|█▋        | 333569/1960000 [10:36:11<49:15:29,  9.17it/s, acc : 0.922, val_acc : 0.566, loss: 0.169, val_loss: 6.0591, w_loss : 0.001, entropy : 7.991, regularizer : 0.240 w16:2.48,w256:2.64,w240:2.90,w128:2.91,w224:2.94,w89:4.46,w104:4.47,w88:4.48,w121:4.49,w119:4.52]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 17%|█▋        | 337770/1960000 [10:44:11<47:24:26,  9.51it/s, acc : 0.934, val_acc : 0.516, loss: 0.165, val_loss: 6.2328, w_loss : 0.001, entropy : 7.991, regularizer : 0.243 w16:2.46,w256:2.63,w240:2.89,w128:2.89,w224:2.94,w88:4.45,w87:4.47,w121:4.49,w169:4.49,w119:4.50]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 17%|█▋        | 342093/1960000 [10:52:24<52:19:54,  8.59it/s, acc : 0.941, val_acc : 0.508, loss: 0.148, val_loss: 5.7114, w_loss : 0.001, entropy : 7.991, regularizer : 0.245 w16:2.47,w256:2.62,w240:2.89,w128:2.91,w160:2.95,w89:4.45,w169:4.46,w88:4.47,w121:4.48,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 18%|█▊        | 345441/1960000 [10:58:48<51:33:29,  8.70it/s, acc : 0.961, val_acc : 0.438, loss: 0.113, val_loss: 5.6092, w_loss : 0.001, entropy : 7.991, regularizer : 0.247 w16:2.47,w256:2.59,w240:2.89,w128:2.91,w224:2.94,w87:4.46,w104:4.46,w121:4.48,w88:4.50,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 18%|█▊        | 346534/1960000 [11:00:52<51:34:31,  8.69it/s, acc : 0.910, val_acc : 0.539, loss: 0.201, val_loss: 5.5548, w_loss : 0.001, entropy : 7.991, regularizer : 0.247 w16:2.47,w256:2.59,w240:2.91,w128:2.92,w160:2.94,w89:4.46,w169:4.46,w88:4.47,w121:4.50,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 18%|█▊        | 350427/1960000 [11:08:18<47:43:48,  9.37it/s, acc : 0.926, val_acc : 0.539, loss: 0.182, val_loss: 5.5840, w_loss : 0.001, entropy : 7.992, regularizer : 0.249 w16:2.47,w256:2.62,w240:2.89,w128:2.92,w160:2.95,w169:4.45,w88:4.46,w89:4.47,w121:4.49,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 18%|█▊        | 354702/1960000 [11:16:29<54:45:12,  8.14it/s, acc : 0.922, val_acc : 0.543, loss: 0.219, val_loss: 6.1432, w_loss : 0.001, entropy : 7.991, regularizer : 0.251 w16:2.48,w256:2.64,w128:2.89,w240:2.90,w224:2.94,w169:4.45,w89:4.47,w88:4.47,w121:4.50,w119:4.54]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 18%|█▊        | 358770/1960000 [11:24:14<47:04:30,  9.45it/s, acc : 0.938, val_acc : 0.570, loss: 0.160, val_loss: 5.3395, w_loss : 0.001, entropy : 7.991, regularizer : 0.254 w16:2.46,w256:2.64,w128:2.90,w240:2.93,w224:2.93,w89:4.46,w87:4.46,w121:4.48,w169:4.49,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 19%|█▊        | 363095/1960000 [11:32:29<49:55:23,  8.89it/s, acc : 0.953, val_acc : 0.555, loss: 0.129, val_loss: 5.9529, w_loss : 0.001, entropy : 7.991, regularizer : 0.256 w16:2.45,w256:2.61,w240:2.90,w128:2.91,w160:2.96,w88:4.46,w104:4.46,w87:4.48,w121:4.50,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 19%|█▊        | 367374/1960000 [11:40:39<50:21:56,  8.78it/s, acc : 0.930, val_acc : 0.523, loss: 0.141, val_loss: 6.6737, w_loss : 0.001, entropy : 7.992, regularizer : 0.258 w16:2.46,w256:2.62,w128:2.90,w240:2.92,w160:2.95,w88:4.47,w169:4.47,w89:4.47,w121:4.50,w119:4.50]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 25%|██▍       | 483065/1960000 [15:21:53<45:02:05,  9.11it/s, acc : 0.957, val_acc : 0.566, loss: 0.123, val_loss: 5.7979, w_loss : 0.001, entropy : 7.992, regularizer : 0.311 w16:2.48,w256:2.62,w128:2.92,w240:2.92,w224:2.95,w89:4.46,w169:4.46,w104:4.47,w121:4.49,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 25%|██▍       | 487428/1960000 [15:30:13<43:18:20,  9.45it/s, acc : 0.957, val_acc : 0.578, loss: 0.125, val_loss: 5.9383, w_loss : 0.001, entropy : 7.992, regularizer : 0.312 w16:2.50,w256:2.62,w128:2.91,w224:2.93,w240:2.93,w169:4.46,w88:4.46,w89:4.48,w121:4.49,w119:4.52]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 25%|██▌       | 491623/1960000 [15:38:13<48:04:59,  8.48it/s, acc : 0.934, val_acc : 0.539, loss: 0.155, val_loss: 6.5715, w_loss : 0.001, entropy : 7.992, regularizer : 0.314 w16:2.49,w256:2.61,w240:2.89,w128:2.92,w224:2.94,w88:4.46,w89:4.46,w104:4.47,w121:4.48,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 495906/1960000 [15:46:24<50:55:23,  7.99it/s, acc : 0.953, val_acc : 0.594, loss: 0.107, val_loss: 5.6300, w_loss : 0.001, entropy : 7.992, regularizer : 0.316 w16:2.49,w256:2.63,w128:2.92,w240:2.93,w224:2.94,w88:4.45,w120:4.45,w104:4.45,w121:4.50,w119:4.50] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 26%|██▌       | 500067/1960000 [15:54:20<44:36:02,  9.09it/s, acc : 0.945, val_acc : 0.469, loss: 0.144, val_loss: 7.4149, w_loss : 0.001, entropy : 7.992, regularizer : 0.317 w16:2.48,w256:2.61,w240:2.89,w128:2.92,w224:2.95,w89:4.45,w118:4.46,w88:4.46,w121:4.47,w119:4.51]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 26%|██▌       | 504036/1960000 [16:01:55<43:44:18,  9.25it/s, acc : 0.926, val_acc : 0.570, loss: 0.146, val_loss: 5.7669, w_loss : 0.001, entropy : 7.992, regularizer : 0.319 w16:2.47,w256:2.62,w128:2.90,w240:2.92,w224:2.96,w169:4.46,w104:4.47,w88:4.47,w121:4.48,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 31%|███       | 604242/1960000 [19:13:26<41:52:34,  8.99it/s, acc : 0.945, val_acc : 0.520, loss: 0.139, val_loss: 7.2341, w_loss : 0.001, entropy : 7.992, regularizer : 0.356 w16:2.51,w256:2.62,w240:2.89,w128:2.91,w224:2.95,w104:4.45,w89:4.45,w169:4.48,w121:4.48,w119:4.49]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 31%|███       | 608331/1960000 [19:21:14<55:46:56,  6.73it/s, acc : 0.945, val_acc : 0.527, loss: 0.170, val_loss: 7.5932, w_loss : 0.001, entropy : 7.992, regularizer : 0.357 w16:2.49,w256:2.64,w240:2.90,w128:2.91,w224:2.96,w105:4.45,w88:4.46,w169:4.46,w121:4.48,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 37%|███▋      | 723589/1960000 [23:05:03<36:03:33,  9.52it/s, acc : 0.977, val_acc : 0.496, loss: 0.061, val_loss: 8.5980, w_loss : 0.001, entropy : 7.992, regularizer : 0.392 w16:2.48,w256:2.63,w240:2.89,w128:2.92,w224:2.95,w104:4.45,w169:4.45,w118:4.45,w121:4.48,w119:4.48] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 40%|███▉      | 777652/1960000 [24:52:50<43:14:58,  7.59it/s, acc : 0.953, val_acc : 0.641, loss: 0.128, val_loss: 6.4718, w_loss : 0.001, entropy : 7.992, regularizer : 0.406 w16:2.48,w256:2.61,w240:2.89,w128:2.91,w224:2.96,w104:4.44,w88:4.45,w169:4.46,w121:4.47,w119:4.50]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 43%|████▎     | 833739/1960000 [26:40:48<33:39:02,  9.30it/s, acc : 0.965, val_acc : 0.574, loss: 0.124, val_loss: 7.2532, w_loss : 0.001, entropy : 7.992, regularizer : 0.420 w16:2.46,w256:2.62,w240:2.89,w128:2.91,w160:2.98,w118:4.45,w89:4.46,w169:4.46,w121:4.49,w119:4.49]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 43%|████▎     | 837922/1960000 [26:48:46<34:25:55,  9.05it/s, acc : 0.938, val_acc : 0.508, loss: 0.147, val_loss: 6.8653, w_loss : 0.001, entropy : 7.992, regularizer : 0.420 w16:2.48,w256:2.61,w240:2.89,w128:2.90,w160:2.97,w104:4.44,w88:4.44,w169:4.46,w121:4.47,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 43%|████▎     | 841820/1960000 [26:56:13<33:13:25,  9.35it/s, acc : 0.925, val_acc : 0.566, loss: 0.264, val_loss: 7.3154, w_loss : 0.001, entropy : 7.992, regularizer : 0.421 w16:2.48,w256:2.63,w240:2.90,w128:2.92,w224:2.99,w118:4.44,w169:4.45,w89:4.45,w121:4.48,w119:4.50]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 43%|████▎     | 845007/1960000 [27:02:17<32:37:23,  9.49it/s, acc : 0.961, val_acc : 0.520, loss: 0.114, val_loss: 8.3761, w_loss : 0.001, entropy : 7.992, regularizer : 0.422 w16:2.48,w256:2.63,w240:2.90,w128:2.91,w160:2.98,w104:4.45,w118:4.45,w169:4.46,w121:4.48,w119:4.49] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 43%|████▎     | 846198/1960000 [27:04:33<33:32:49,  9.22it/s, acc : 0.945, val_acc : 0.527, loss: 0.142, val_loss: 7.7043, w_loss : 0.001, entropy : 7.992, regularizer : 0.422 w16:2.48,w256:2.64,w240:2.92,w128:2.93,w224:2.97,w89:4.44,w103:4.45,w169:4.46,w121:4.48,w119:4.50] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 43%|████▎     | 850008/1960000 [27:11:49<31:50:31,  9.68it/s, acc : 0.957, val_acc : 0.535, loss: 0.097, val_loss: 7.4205, w_loss : 0.001, entropy : 7.992, regularizer : 0.423 w16:2.49,w256:2.62,w128:2.92,w240:2.93,w160:2.98,w88:4.44,w169:4.45,w89:4.46,w121:4.46,w119:4.51]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 44%|████▎     | 853905/1960000 [27:19:16<33:44:01,  9.11it/s, acc : 0.941, val_acc : 0.543, loss: 0.175, val_loss: 5.9730, w_loss : 0.001, entropy : 7.992, regularizer : 0.424 w16:2.47,w256:2.65,w240:2.92,w128:2.92,w160:2.97,w89:4.44,w104:4.45,w169:4.45,w121:4.47,w119:4.53]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 858045/1960000 [27:27:10<33:05:31,  9.25it/s, acc : 0.969, val_acc : 0.520, loss: 0.080, val_loss: 8.4695, w_loss : 0.001, entropy : 7.992, regularizer : 0.425 w16:2.47,w256:2.64,w240:2.90,w128:2.90,w224:2.97,w89:4.44,w118:4.44,w169:4.47,w121:4.49,w119:4.49]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 44%|████▍     | 862274/1960000 [27:35:14<34:06:09,  8.94it/s, acc : 0.938, val_acc : 0.523, loss: 0.160, val_loss: 8.0520, w_loss : 0.001, entropy : 7.992, regularizer : 0.426 w16:2.48,w256:2.63,w240:2.90,w128:2.93,w224:2.97,w89:4.43,w104:4.43,w169:4.46,w121:4.47,w119:4.50]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 44%|████▍     | 866279/1960000 [27:42:52<32:01:40,  9.49it/s, acc : 0.961, val_acc : 0.496, loss: 0.111, val_loss: 9.0451, w_loss : 0.001, entropy : 7.992, regularizer : 0.427 w16:2.48,w256:2.61,w240:2.91,w128:2.93,w224:2.97,w87:4.43,w89:4.44,w169:4.46,w121:4.49,w119:4.49]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 44%|████▍     | 870626/1960000 [27:51:16<32:44:04,  9.24it/s, acc : 0.910, val_acc : 0.586, loss: 0.218, val_loss: 6.5607, w_loss : 0.001, entropy : 7.992, regularizer : 0.428 w16:2.48,w256:2.62,w128:2.91,w240:2.91,w224:2.97,w87:4.44,w169:4.44,w89:4.46,w119:4.50,w121:4.50]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 45%|████▍     | 874799/1960000 [27:59:13<32:40:38,  9.22it/s, acc : 0.961, val_acc : 0.562, loss: 0.113, val_loss: 8.0755, w_loss : 0.001, entropy : 7.992, regularizer : 0.429 w16:2.49,w256:2.63,w128:2.91,w240:2.92,w160:2.98,w89:4.44,w118:4.45,w169:4.45,w121:4.48,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 45%|████▍     | 878950/1960000 [28:07:08<31:06:48,  9.65it/s, acc : 0.957, val_acc : 0.547, loss: 0.106, val_loss: 7.2447, w_loss : 0.001, entropy : 7.992, regularizer : 0.429 w16:2.47,w256:2.61,w128:2.89,w240:2.90,w160:2.99,w87:4.44,w118:4.45,w169:4.46,w121:4.48,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 45%|████▌     | 882742/1960000 [28:14:22<40:00:24,  7.48it/s, acc : 0.965, val_acc : 0.492, loss: 0.118, val_loss: 8.7844, w_loss : 0.001, entropy : 7.992, regularizer : 0.430 w16:2.48,w256:2.61,w128:2.91,w240:2.92,w160:2.97,w118:4.44,w169:4.45,w89:4.46,w121:4.47,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 45%|████▌     | 886737/1960000 [28:21:59<31:59:14,  9.32it/s, acc : 0.969, val_acc : 0.492, loss: 0.087, val_loss: 9.5902, w_loss : 0.001, entropy : 7.992, regularizer : 0.431 w16:2.47,w256:2.62,w128:2.90,w240:2.92,w160:2.98,w104:4.44,w89:4.44,w169:4.46,w121:4.46,w119:4.49]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 45%|████▌     | 890978/1960000 [28:30:05<32:16:30,  9.20it/s, acc : 0.969, val_acc : 0.562, loss: 0.094, val_loss: 6.5714, w_loss : 0.001, entropy : 7.992, regularizer : 0.432 w16:2.47,w256:2.61,w128:2.90,w240:2.92,w160:2.98,w87:4.44,w89:4.44,w121:4.47,w169:4.48,w119:4.51]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 46%|████▌     | 894900/1960000 [28:37:34<32:23:44,  9.13it/s, acc : 0.945, val_acc : 0.527, loss: 0.122, val_loss: 8.4466, w_loss : 0.001, entropy : 7.992, regularizer : 0.433 w16:2.48,w256:2.63,w128:2.91,w240:2.92,w192:2.98,w89:4.44,w118:4.45,w169:4.46,w121:4.48,w119:4.50]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 46%|████▌     | 899028/1960000 [28:45:25<31:08:29,  9.46it/s, acc : 0.934, val_acc : 0.543, loss: 0.169, val_loss: 7.6849, w_loss : 0.001, entropy : 7.992, regularizer : 0.434 w16:2.48,w256:2.64,w128:2.90,w240:2.90,w224:2.96,w118:4.43,w104:4.44,w169:4.47,w121:4.47,w119:4.52] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 46%|████▌     | 903255/1960000 [28:53:28<32:23:11,  9.06it/s, acc : 0.934, val_acc : 0.484, loss: 0.122, val_loss: 8.9389, w_loss : 0.001, entropy : 7.992, regularizer : 0.434 w16:2.49,w256:2.64,w240:2.90,w128:2.91,w160:2.98,w118:4.43,w89:4.45,w169:4.46,w121:4.47,w119:4.49] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 46%|████▋     | 907201/1960000 [29:00:59<34:15:31,  8.54it/s, acc : 0.953, val_acc : 0.500, loss: 0.108, val_loss: 10.6192, w_loss : 0.001, entropy : 7.992, regularizer : 0.435 w16:2.48,w256:2.63,w240:2.91,w128:2.91,w224:3.00,w118:4.45,w169:4.45,w89:4.45,w121:4.50,w119:4.51]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 47%|████▋     | 911482/1960000 [29:09:10<32:31:47,  8.95it/s, acc : 0.949, val_acc : 0.555, loss: 0.117, val_loss: 7.4290, w_loss : 0.001, entropy : 7.992, regularizer : 0.436 w16:2.49,w256:2.61,w128:2.89,w240:2.90,w224:2.98,w118:4.44,w89:4.44,w169:4.46,w121:4.48,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 915598/1960000 [29:17:00<30:40:31,  9.46it/s, acc : 0.965, val_acc : 0.574, loss: 0.102, val_loss: 6.9338, w_loss : 0.001, entropy : 7.992, regularizer : 0.437 w16:2.48,w256:2.62,w240:2.90,w128:2.91,w160:2.97,w169:4.45,w89:4.45,w104:4.46,w121:4.46,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 47%|████▋     | 919749/1960000 [29:24:57<31:15:04,  9.25it/s, acc : 0.957, val_acc : 0.535, loss: 0.116, val_loss: 7.3796, w_loss : 0.001, entropy : 7.992, regularizer : 0.438 w16:2.48,w256:2.61,w240:2.91,w128:2.91,w160:2.97,w89:4.44,w118:4.45,w169:4.46,w121:4.50,w119:4.50]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 47%|████▋     | 923995/1960000 [29:33:02<31:46:14,  9.06it/s, acc : 0.961, val_acc : 0.551, loss: 0.107, val_loss: 7.6265, w_loss : 0.001, entropy : 7.992, regularizer : 0.439 w16:2.49,w256:2.62,w128:2.90,w240:2.93,w160:2.98,w88:4.43,w87:4.44,w169:4.47,w121:4.48,w119:4.50]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 47%|████▋     | 928040/1960000 [29:40:45<29:54:26,  9.58it/s, acc : 0.953, val_acc : 0.438, loss: 0.134, val_loss: 8.8669, w_loss : 0.001, entropy : 7.992, regularizer : 0.439 w16:2.49,w256:2.64,w128:2.90,w240:2.91,w160:2.99,w88:4.44,w87:4.44,w169:4.45,w121:4.46,w119:4.51]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 48%|████▊     | 932291/1960000 [29:48:51<37:46:30,  7.56it/s, acc : 0.961, val_acc : 0.453, loss: 0.128, val_loss: 8.1106, w_loss : 0.001, entropy : 7.992, regularizer : 0.440 w16:2.49,w256:2.60,w240:2.91,w128:2.92,w160:2.97,w88:4.43,w104:4.44,w169:4.46,w121:4.48,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 48%|████▊     | 936452/1960000 [29:56:47<38:30:54,  7.38it/s, acc : 0.918, val_acc : 0.512, loss: 0.208, val_loss: 9.0981, w_loss : 0.001, entropy : 7.992, regularizer : 0.441 w16:2.47,w256:2.61,w240:2.91,w128:2.91,w160:2.96,w87:4.44,w89:4.45,w169:4.45,w121:4.48,w119:4.53]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 48%|████▊     | 940592/1960000 [30:04:41<34:35:28,  8.19it/s, acc : 0.977, val_acc : 0.543, loss: 0.075, val_loss: 7.0335, w_loss : 0.001, entropy : 7.992, regularizer : 0.442 w16:2.49,w256:2.61,w128:2.90,w240:2.91,w224:2.99,w105:4.44,w89:4.45,w169:4.46,w121:4.50,w119:4.53]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 48%|████▊     | 944844/1960000 [30:12:47<30:05:32,  9.37it/s, acc : 0.965, val_acc : 0.531, loss: 0.087, val_loss: 8.2146, w_loss : 0.001, entropy : 7.992, regularizer : 0.443 w16:2.49,w256:2.62,w128:2.90,w240:2.91,w224:2.97,w89:4.45,w104:4.45,w169:4.46,w121:4.47,w119:4.49]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 48%|████▊     | 948864/1960000 [30:20:26<32:37:23,  8.61it/s, acc : 0.973, val_acc : 0.461, loss: 0.074, val_loss: 9.6435, w_loss : 0.001, entropy : 7.992, regularizer : 0.443 w16:2.49,w256:2.64,w128:2.91,w240:2.91,w224:2.97,w104:4.44,w89:4.45,w169:4.46,w121:4.49,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 49%|████▊     | 953111/1960000 [30:28:33<42:16:43,  6.62it/s, acc : 0.914, val_acc : 0.578, loss: 0.202, val_loss: 7.2095, w_loss : 0.001, entropy : 7.992, regularizer : 0.444 w16:2.49,w256:2.64,w128:2.90,w240:2.90,w160:3.00,w118:4.44,w88:4.44,w169:4.47,w121:4.48,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 49%|████▉     | 957016/1960000 [30:35:59<30:01:34,  9.28it/s, acc : 0.945, val_acc : 0.555, loss: 0.107, val_loss: 8.7852, w_loss : 0.001, entropy : 7.992, regularizer : 0.445 w16:2.48,w256:2.62,w128:2.90,w240:2.92,w224:3.01,w118:4.44,w89:4.46,w169:4.47,w121:4.50,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 49%|████▉     | 961180/1960000 [30:43:55<33:37:04,  8.25it/s, acc : 0.941, val_acc : 0.547, loss: 0.166, val_loss: 7.4734, w_loss : 0.001, entropy : 7.992, regularizer : 0.446 w16:2.47,w256:2.61,w128:2.90,w240:2.91,w160:2.97,w88:4.43,w118:4.45,w169:4.46,w121:4.49,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 49%|████▉     | 965409/1960000 [30:51:59<29:22:56,  9.40it/s, acc : 0.938, val_acc : 0.512, loss: 0.137, val_loss: 8.2405, w_loss : 0.001, entropy : 7.992, regularizer : 0.446 w16:2.48,w256:2.62,w240:2.89,w128:2.91,w224:2.99,w88:4.44,w118:4.44,w169:4.46,w121:4.47,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 49%|████▉     | 969453/1960000 [30:59:42<32:29:42,  8.47it/s, acc : 0.957, val_acc : 0.523, loss: 0.126, val_loss: 7.8632, w_loss : 0.001, entropy : 7.992, regularizer : 0.447 w16:2.47,w256:2.62,w128:2.92,w240:2.93,w160:2.96,w89:4.44,w169:4.45,w118:4.46,w121:4.48,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 973678/1960000 [31:07:45<29:18:46,  9.35it/s, acc : 0.961, val_acc : 0.508, loss: 0.103, val_loss: 7.5720, w_loss : 0.001, entropy : 7.992, regularizer : 0.448 w16:2.46,w256:2.62,w240:2.91,w128:2.92,w160:2.99,w89:4.45,w104:4.45,w169:4.45,w121:4.48,w119:4.53]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 50%|████▉     | 977674/1960000 [31:15:23<33:32:25,  8.14it/s, acc : 0.957, val_acc : 0.547, loss: 0.118, val_loss: 8.3137, w_loss : 0.001, entropy : 7.992, regularizer : 0.449 w16:2.48,w256:2.61,w128:2.91,w240:2.92,w160:2.98,w89:4.44,w118:4.45,w169:4.46,w121:4.48,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 50%|█████     | 981922/1960000 [31:23:30<31:12:26,  8.71it/s, acc : 0.941, val_acc : 0.566, loss: 0.123, val_loss: 7.7158, w_loss : 0.001, entropy : 7.992, regularizer : 0.449 w16:2.46,w256:2.62,w128:2.89,w240:2.91,w160:2.98,w88:4.44,w89:4.45,w169:4.46,w121:4.47,w119:4.51]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 50%|█████     | 986307/1960000 [31:31:51<29:42:43,  9.10it/s, acc : 0.941, val_acc : 0.520, loss: 0.164, val_loss: 9.4380, w_loss : 0.001, entropy : 7.992, regularizer : 0.450 w16:2.47,w256:2.59,w128:2.89,w240:2.90,w224:2.98,w89:4.44,w87:4.44,w169:4.46,w121:4.47,w119:4.51]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 51%|█████     | 990602/1960000 [31:40:11<29:38:39,  9.08it/s, acc : 0.957, val_acc : 0.551, loss: 0.107, val_loss: 7.7704, w_loss : 0.001, entropy : 7.992, regularizer : 0.451 w16:2.48,w256:2.62,w240:2.90,w128:2.92,w160:2.97,w118:4.44,w104:4.45,w169:4.48,w121:4.49,w119:4.50] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 51%|█████     | 994818/1960000 [31:48:13<28:06:10,  9.54it/s, acc : 0.945, val_acc : 0.508, loss: 0.121, val_loss: 8.4565, w_loss : 0.001, entropy : 7.992, regularizer : 0.452 w16:2.47,w256:2.66,w240:2.91,w128:2.91,w224:2.98,w118:4.44,w104:4.45,w169:4.47,w121:4.48,w119:4.51] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 51%|█████     | 998763/1960000 [31:55:44<29:08:05,  9.16it/s, acc : 0.930, val_acc : 0.508, loss: 0.186, val_loss: 8.0705, w_loss : 0.001, entropy : 7.992, regularizer : 0.452 w16:2.48,w256:2.63,w240:2.89,w128:2.93,w224:2.99,w87:4.43,w89:4.44,w169:4.45,w121:4.48,w119:4.51]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 51%|█████     | 1001845/1960000 [32:01:37<28:53:52,  9.21it/s, acc : 0.961, val_acc : 0.500, loss: 0.138, val_loss: 8.2935, w_loss : 0.001, entropy : 7.992, regularizer : 0.453 w16:2.48,w256:2.64,w128:2.90,w240:2.91,w224:2.99,w89:4.44,w118:4.44,w169:4.46,w121:4.47,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 51%|█████     | 1002728/1960000 [32:03:17<28:02:02,  9.49it/s, acc : 0.961, val_acc : 0.609, loss: 0.096, val_loss: 7.3114, w_loss : 0.001, entropy : 7.992, regularizer : 0.453 w16:2.49,w256:2.62,w128:2.90,w240:2.90,w224:2.97,w104:4.44,w118:4.44,w103:4.44,w121:4.47,w119:4.50] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 51%|█████▏    | 1006088/1960000 [32:09:42<27:38:06,  9.59it/s, acc : 0.965, val_acc : 0.516, loss: 0.100, val_loss: 9.4554, w_loss : 0.001, entropy : 7.992, regularizer : 0.454 w16:2.49,w256:2.61,w128:2.90,w240:2.92,w224:2.99,w105:4.44,w118:4.45,w121:4.48,w169:4.48,w119:4.51] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 51%|█████▏    | 1007001/1960000 [32:11:26<30:58:32,  8.55it/s, acc : 0.969, val_acc : 0.527, loss: 0.090, val_loss: 7.3923, w_loss : 0.001, entropy : 7.992, regularizer : 0.454 w16:2.49,w256:2.62,w128:2.90,w240:2.91,w224:2.98,w88:4.43,w169:4.45,w104:4.46,w121:4.49,w119:4.50]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 52%|█████▏    | 1010242/1960000 [32:17:37<29:43:18,  8.88it/s, acc : 0.930, val_acc : 0.523, loss: 0.160, val_loss: 9.2226, w_loss : 0.001, entropy : 7.992, regularizer : 0.454 w16:2.49,w256:2.62,w240:2.91,w128:2.91,w160:2.96,w118:4.43,w89:4.43,w169:4.46,w121:4.49,w119:4.50]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 52%|█████▏    | 1011144/1960000 [32:19:21<29:45:39,  8.86it/s, acc : 0.965, val_acc : 0.625, loss: 0.118, val_loss: 6.7121, w_loss : 0.001, entropy : 7.992, regularizer : 0.454 w16:2.49,w256:2.62,w128:2.92,w240:2.92,w160:2.98,w88:4.43,w89:4.44,w169:4.46,w121:4.47,w119:4.52]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 52%|█████▏    | 1014513/1960000 [32:25:46<32:07:41,  8.17it/s, acc : 0.949, val_acc : 0.559, loss: 0.108, val_loss: 8.0412, w_loss : 0.001, entropy : 7.992, regularizer : 0.455 w16:2.48,w256:2.64,w128:2.91,w240:2.91,w160:2.99,w118:4.44,w89:4.44,w169:4.45,w121:4.48,w119:4.51]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1015394/1960000 [32:27:27<31:42:15,  8.28it/s, acc : 0.980, val_acc : 0.520, loss: 0.058, val_loss: 8.2818, w_loss : 0.001, entropy : 7.992, regularizer : 0.455 w16:2.48,w256:2.63,w240:2.89,w128:2.92,w224:2.99,w89:4.44,w104:4.44,w169:4.45,w121:4.48,w119:4.49]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 52%|█████▏    | 1018518/1960000 [32:33:25<27:55:35,  9.36it/s, acc : 0.949, val_acc : 0.488, loss: 0.127, val_loss: 8.4534, w_loss : 0.001, entropy : 7.992, regularizer : 0.456 w16:2.47,w256:2.63,w240:2.92,w128:2.92,w224:2.99,w104:4.43,w89:4.45,w169:4.47,w121:4.47,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 52%|█████▏    | 1019672/1960000 [32:35:37<32:13:56,  8.10it/s, acc : 0.969, val_acc : 0.551, loss: 0.083, val_loss: 8.3988, w_loss : 0.001, entropy : 7.992, regularizer : 0.456 w16:2.46,w256:2.63,w128:2.91,w240:2.92,w224:2.98,w89:4.45,w118:4.46,w121:4.46,w169:4.47,w119:4.53] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 52%|█████▏    | 1022811/1960000 [32:41:36<35:03:51,  7.42it/s, acc : 0.953, val_acc : 0.578, loss: 0.158, val_loss: 8.0701, w_loss : 0.001, entropy : 7.992, regularizer : 0.456 w16:2.47,w256:2.62,w240:2.90,w128:2.93,w160:2.99,w89:4.43,w103:4.44,w169:4.46,w119:4.48,w121:4.49]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 52%|█████▏    | 1023625/1960000 [32:43:09<28:38:07,  9.08it/s, acc : 0.969, val_acc : 0.512, loss: 0.105, val_loss: 8.1445, w_loss : 0.001, entropy : 7.992, regularizer : 0.456 w16:2.48,w256:2.62,w240:2.92,w128:2.93,w160:2.98,w118:4.44,w89:4.45,w169:4.47,w121:4.48,w119:4.50]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 52%|█████▏    | 1026719/1960000 [32:49:04<27:42:08,  9.36it/s, acc : 0.945, val_acc : 0.586, loss: 0.121, val_loss: 7.6814, w_loss : 0.001, entropy : 7.992, regularizer : 0.457 w16:2.48,w256:2.62,w240:2.91,w128:2.91,w160:2.99,w89:4.44,w87:4.44,w169:4.46,w121:4.49,w119:4.51]   IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 52%|█████▏    | 1027861/1960000 [32:51:15<34:05:51,  7.59it/s, acc : 0.945, val_acc : 0.531, loss: 0.081, val_loss: 7.1827, w_loss : 0.001, entropy : 7.992, regularizer : 0.457 w16:2.47,w256:2.62,w128:2.91,w240:2.91,w224:3.00,w89:4.44,w104:4.45,w169:4.46,w121:4.48,w119:4.52]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 54%|█████▎    | 1050188/1960000 [33:33:58<26:43:07,  9.46it/s, acc : 0.934, val_acc : 0.488, loss: 0.184, val_loss: 8.7124, w_loss : 0.001, entropy : 7.992, regularizer : 0.461 w16:2.48,w256:2.63,w128:2.89,w240:2.89,w224:2.98,w104:4.44,w118:4.46,w169:4.47,w121:4.47,w119:4.49] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-478f4f21969d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreg_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mentropy_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msrc_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/miniconda2/envs/python-conda/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/miniconda2/envs/python-conda/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from utils.SimpleCNN import SimpleCNN\n",
    "import sklearn.metrics\n",
    "def calc_accracy(y, out):\n",
    "    label = y.flatten().cpu().detach().numpy().astype(np.int)\n",
    "    pred = torch.argmax(out, dim=-1).cpu().detach().numpy().astype(np.int)\n",
    "    return sklearn.metrics.accuracy_score(label, pred)\n",
    "\n",
    "def add_noise_on_pixel(x, pixel_mask, distribution):\n",
    "    noise = distribution.sample(x.size())\n",
    "    batch = x.shape[0]\n",
    "    ret = x.clone()\n",
    "    ret += pixel_mask.repeat(batch, 1).type(torch.FloatTensor)*noise\n",
    "    return ret\n",
    "            \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn = SimpleCNN(1, 16, 3)\n",
    "        self.kernel_weights = self.cnn.kernel_weights\n",
    "        self.linear = nn.Linear(4*64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = x.view(batch, 1, 16, 16)\n",
    "        x = self.cnn(x)\n",
    "        out = self.linear(x.view(batch, -1))\n",
    "        return out\n",
    "\n",
    "batch_size = 256\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize([16,16]),\n",
    "    transforms.Grayscale(),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    transforms.Lambda(lambda x:x.flatten()),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize([16,16]),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    transforms.Lambda(lambda x:x.flatten()),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform_test)\n",
    "val_dataloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "X = np.zeros([500, 256])\n",
    "\n",
    "# DNN_model = SimpleDNN(X.shape[-1], 128, 10, 3, F.relu)\n",
    "# model = SelectNet(X.shape[-1], DNN_model, DNN_model.kernel_weights).cuda()\n",
    "simple_model = Net()\n",
    "model = SelectNet(X.shape[-1], simple_model, simple_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "# beta = 0\n",
    "gamma = 0\n",
    "epochs = 10000\n",
    "iters = 1\n",
    "noise_distribution = torch.distributions.Uniform(0.5, 1)\n",
    "noise_pixel_mask = torch.zeros([1, X.shape[-1]], dtype=torch.uint8)\n",
    "writer = SummaryWriter('./AE_logs/cifar10-a%f,b%f,g%f' % (alpha, beta, gamma))\n",
    "src_loss_criterion = nn.CrossEntropyLoss()\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "#         mask_idx = np.random.randint(0, X.shape[-1])\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_noise_on_pixel(x, noise_pixel_mask, noise_distribution)\n",
    "            x, y = x.cuda(), y.type(torch.long).flatten().cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_noise_on_pixel(val_x, noise_pixel_mask, noise_distribution)\n",
    "            val_x, val_y = val_x.cuda(), val_y.type(torch.long).flatten().cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "# \n",
    "            model.train()\n",
    "            train_out = model(x)\n",
    "            reg_loss, w_loss, entropy_loss = model.calc_reg_loss(F.mse_loss)\n",
    "            src_loss = src_loss_criterion(train_out, y)\n",
    "            loss = alpha*reg_loss + beta*w_loss + gamma*entropy_loss + src_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "            \n",
    "#                 val_out = torch.softmax(model(val_x), dim=-1)\n",
    "                val_out = model(val_x)\n",
    "                val_src_loss = src_loss_criterion(val_out, val_y)\n",
    "                \n",
    "                \n",
    "#                 noised\n",
    "                noised_train_out = model(noised_x)\n",
    "                noised_val_out = model(val_noised_x)\n",
    "                noised_src = src_loss_criterion(noised_train_out, y)\n",
    "                val_noised_src = src_loss_criterion(noised_val_out, val_y)\n",
    "#                 acc\n",
    "                train_acc = calc_accracy(y, train_out)\n",
    "                val_acc = calc_accracy(val_y, val_out)\n",
    "                noised_train_acc = calc_accracy(y, noised_train_out)\n",
    "                noised_val_acc = calc_accracy(val_y, noised_val_out)\n",
    "                \n",
    "            \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            w_prine = torch.sigmoid(model.w).cpu().detach().numpy().flatten()\n",
    "            w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "            sorted_ratio = sorted([(i+1,x) for i,x in enumerate(w_ratio)], key=lambda x:x[1])\n",
    "            buf = sorted_ratio[:5] + sorted_ratio[-5:]\n",
    "            buf = ','.join(['w%d:%.2f' % (i,x*1000) for i,x in buf])\n",
    "            pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, loss: %.3f, val_loss: %.4f, w_loss : %.3f, entropy : %.3f, regularizer : %.3f %s' %\n",
    "                                 (\n",
    "                                     train_acc.item(), val_acc.item(),\n",
    "                                     src_loss.item(), val_src_loss.item(), \n",
    "                                     w_loss.item(), entropy_loss.item(),\n",
    "                                     reg_loss.item(), buf))\n",
    "            if epoch >= 0 and iters % 10 == 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/cross-entropy', {'train': src_loss.item(),\n",
    "                                                     'validation': val_src_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_loss', {'train': noised_src.item(),\n",
    "                                                     'validation': val_noised_src.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/accuracy', {'train': train_acc.item(),\n",
    "                                                     'validation': val_acc.item(),\n",
    "                                                     'noised_train': noised_train_acc.item(),\n",
    "                                                     'noised_validation': noised_val_acc.item(),\n",
    "                                                    },\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_loss', {'train': w_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/entropy', {'train': entropy_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_prine', {'w%d' % (i+1) : v  for i, v in enumerate(w_prine)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_ratio', {'w%d' % (i+1) : v  for i, v in enumerate(w_ratio)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_z', {'nothing':0 },\n",
    "                                                     iters)\n",
    "            \n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5423, -1.0209, -1.2853,  ..., -2.7056, -4.7699, -2.2127],\n",
      "        [ 1.2831, -2.4430,  0.1475,  ..., -3.7054,  2.0896, -1.9394],\n",
      "        [-2.4956, -5.0181, -0.0313,  ..., -0.4448, -3.1917, -4.7664],\n",
      "        ...,\n",
      "        [ 2.2278, -1.8391, -1.0016,  ..., -2.8042,  0.8744, -1.7559],\n",
      "        [-3.5473,  2.8513, -5.2338,  ..., -1.5710, -3.2852,  5.1037],\n",
      "        [ 0.8293,  0.6683, -1.3910,  ..., -3.9263,  2.9264, -4.3292]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.1633, -2.8003,  0.1967,  ..., -1.9671, -1.2115, -1.2480],\n",
      "        [-3.2047, -1.2256, -2.8525,  ...,  0.1483, -5.6269,  3.8549],\n",
      "        [-3.7398, -3.4939,  0.0435,  ...,  1.3515, -4.3519, -0.6898],\n",
      "        ...,\n",
      "        [-2.2211, -3.2185, -0.1646,  ..., -1.1037, -3.5690, -3.2245],\n",
      "        [ 0.0757, -4.3401, -1.7924,  ...,  4.0516, -5.0759,  0.6905],\n",
      "        [-2.3204, -3.1334, -1.7814,  ...,  3.7790, -5.0765, -1.6959]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print train_out\n",
    "print noised_train_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3363/2350000 [04:30<50:26:18, 12.92it/s, acc : 0.996, val_acc : 0.977, loss: 0.017, val_loss: 0.0630, w_loss : 0.982, entropy : 6.644, regularizer : 0.011 w37:10.00,w54:10.00,w26:10.00,w64:10.00,w34:10.00,w57:10.00,w58:10.00,w36:10.00,w75:10.00,w66:10.00]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  9%|▉         | 220736/2350000 [4:54:00<47:09:08, 12.54it/s, acc : 0.996, val_acc : 0.988, loss: 0.046, val_loss: 0.0790, w_loss : 0.000, entropy : 5.803, regularizer : 0.020 w91:0.00,w99:0.00,w10:0.00,w90:0.00,w1:0.00,w54:22.19,w55:22.34,w77:22.56,w38:23.80,w86:24.67] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 13%|█▎        | 301233/2350000 [6:41:07<45:51:46, 12.41it/s, acc : 1.000, val_acc : 0.988, loss: 0.000, val_loss: 0.0890, w_loss : 0.000, entropy : 5.812, regularizer : 0.020 w91:0.00,w99:0.00,w10:0.00,w1:0.00,w90:0.00,w15:22.10,w77:22.15,w58:22.48,w38:23.87,w86:23.98]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 16%|█▋        | 382465/2350000 [8:29:19<43:13:12, 12.65it/s, acc : 1.000, val_acc : 0.996, loss: 0.000, val_loss: 0.0086, w_loss : 0.000, entropy : 5.825, regularizer : 0.018 w91:0.00,w99:0.00,w10:0.00,w1:0.00,w81:0.00,w68:22.01,w77:22.23,w24:22.39,w86:23.00,w38:23.56]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 23%|██▎       | 544789/2350000 [12:05:33<40:09:59, 12.48it/s, acc : 1.000, val_acc : 0.988, loss: 0.000, val_loss: 0.0903, w_loss : 0.000, entropy : 5.851, regularizer : 0.016 w91:0.00,w99:0.00,w1:0.00,w10:0.00,w80:0.00,w16:22.30,w77:22.41,w78:22.50,w68:23.26,w38:23.65] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 24%|██▍       | 563799/2350000 [12:30:50<39:43:51, 12.49it/s, acc : 1.000, val_acc : 0.977, loss: 0.000, val_loss: 0.1622, w_loss : 0.000, entropy : 5.854, regularizer : 0.017 w91:0.00,w1:0.00,w99:0.00,w10:0.00,w80:0.00,w86:22.21,w16:22.62,w77:22.90,w68:23.19,w38:24.11]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aad0e3c580f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mtrain_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mreg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_reg_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0msrc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_loss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/miniconda2/envs/python-conda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/git/SelectNet/src/SelectNet.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_lay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownstream_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/miniconda2/envs/python-conda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/git/SelectNet/src/SelectNet.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# ratio = self.calc_ratio()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from utils.SimpleCNN import SimpleCNN\n",
    "import sklearn.metrics\n",
    "def calc_accracy(y, out):\n",
    "    label = y.flatten().cpu().detach().numpy().astype(np.int)\n",
    "    pred = torch.argmax(out, dim=-1).cpu().detach().numpy().astype(np.int)\n",
    "    return sklearn.metrics.accuracy_score(label, pred)\n",
    "\n",
    "def add_noise_on_pixel(x, pixel_mask, distribution):\n",
    "    noise = distribution.sample(x.size())\n",
    "    batch = x.shape[0]\n",
    "    ret = x.clone()\n",
    "    ret += pixel_mask.repeat(batch, 1).type(torch.FloatTensor)*noise\n",
    "    return ret\n",
    "            \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn = SimpleCNN(1, 16, 2)\n",
    "        self.kernel_weights = self.cnn.kernel_weights\n",
    "        self.linear = nn.Linear(4*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = x.view(batch, 1, 10, 10)\n",
    "        x = self.cnn(x)\n",
    "        out = self.linear(x.view(batch, -1))\n",
    "        return out\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize([10,10]),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                           transforms.Lambda(lambda x:x.flatten()),\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.Resize([10,10]),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                           transforms.Lambda(lambda x:x.flatten()),\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "X = np.zeros([50000, 100])\n",
    "\n",
    "# DNN_model = SimpleDNN(X.shape[-1], 128, 10, 3, F.relu)\n",
    "# model = SelectNet(X.shape[-1], DNN_model, DNN_model.kernel_weights).cuda()\n",
    "simple_model = Net()\n",
    "model = SelectNet(X.shape[-1], simple_model, simple_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "# beta = 0\n",
    "gamma = 0\n",
    "epochs = 10000\n",
    "iters = 1\n",
    "noise_distribution = torch.distributions.Uniform(0.5, 1)\n",
    "noise_pixel_mask = torch.tensor([[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 1, 1]], dtype=torch.uint8)\n",
    "writer = SummaryWriter('./logs/noised_cnn_mnist-a%f,b%f,g%f' % (alpha, beta, gamma))\n",
    "src_loss_criterion = nn.CrossEntropyLoss()\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "#         mask_idx = np.random.randint(0, X.shape[-1])\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_noise_on_pixel(x, noise_pixel_mask, noise_distribution)\n",
    "            x, y = x.cuda(), y.type(torch.long).flatten().cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_noise_on_pixel(val_x, noise_pixel_mask, noise_distribution)\n",
    "            val_x, val_y = val_x.cuda(), val_y.type(torch.long).flatten().cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "# \n",
    "            model.train()\n",
    "            train_out = model(x)\n",
    "            reg_loss, w_loss, entropy_loss = model.calc_reg_loss(F.mse_loss)\n",
    "            src_loss = src_loss_criterion(train_out, y)\n",
    "            loss = alpha*reg_loss + beta*w_loss + gamma*entropy_loss + src_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "            \n",
    "#                 val_out = torch.softmax(model(val_x), dim=-1)\n",
    "                val_out = model(val_x)\n",
    "                val_src_loss = src_loss_criterion(val_out, val_y)\n",
    "                \n",
    "                \n",
    "#                 noised\n",
    "                noised_train_out = model(noised_x)\n",
    "                noised_val_out = model(val_noised_x)\n",
    "                noised_src = src_loss_criterion(noised_train_out, y)\n",
    "                val_noised_src = src_loss_criterion(noised_val_out, val_y)\n",
    "#                 acc\n",
    "                train_acc = calc_accracy(y, train_out)\n",
    "                val_acc = calc_accracy(val_y, val_out)\n",
    "                noised_train_acc = calc_accracy(y, noised_train_out)\n",
    "                noised_val_acc = calc_accracy(val_y, noised_val_out)\n",
    "                \n",
    "            \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            w_prine = torch.sigmoid(model.w).cpu().detach().numpy().flatten()\n",
    "            w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "            sorted_ratio = sorted([(i+1,x) for i,x in enumerate(w_ratio)], key=lambda x:x[1])\n",
    "            buf = sorted_ratio[:5] + sorted_ratio[-5:]\n",
    "            buf = ','.join(['w%d:%.2f' % (i,x*1000) for i,x in buf])\n",
    "            pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, loss: %.3f, val_loss: %.4f, w_loss : %.3f, entropy : %.3f, regularizer : %.3f %s' %\n",
    "                                 (\n",
    "                                     train_acc.item(), val_acc.item(),\n",
    "                                     src_loss.item(), val_src_loss.item(), \n",
    "                                     w_loss.item(), entropy_loss.item(),\n",
    "                                     reg_loss.item(), buf))\n",
    "            if epoch >= 0 and iters % 10 == 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/cross-entropy', {'train': src_loss.item(),\n",
    "                                                     'validation': val_src_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_loss', {'train': noised_src.item(),\n",
    "                                                     'validation': val_noised_src.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/accuracy', {'train': train_acc.item(),\n",
    "                                                     'validation': val_acc.item(),\n",
    "                                                     'noised_train': noised_train_acc.item(),\n",
    "                                                     'noised_validation': noised_val_acc.item(),\n",
    "                                                    },\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_loss', {'train': w_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/entropy', {'train': entropy_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_prine', {'w%d' % (i+1) : v  for i, v in enumerate(w_prine)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_ratio', {'w%d' % (i+1) : v  for i, v in enumerate(w_ratio)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_z', {'nothing':0 },\n",
    "                                                     iters)\n",
    "            \n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w_ratio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-708380299995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print val_x.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print sorted_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mw_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# plt.plot(np.ones([100,]), w_ratio, 'r.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w_ratio' is not defined"
     ]
    }
   ],
   "source": [
    "# torch.save(model, './models/mnist_10x10.hdf5')\n",
    "# print val_x.shape\n",
    "# print sorted_ratio\n",
    "print w_ratio\n",
    "# plt.plot(np.ones([100,]), w_ratio, 'r.')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 1, 1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 1, 1]], dtype=torch.uint8)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 1, 1]], dtype=torch.uint8)\n",
      "torch.Size([1, 100])\n",
      "0.9854296875\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.001\n",
    "def get_torch_mask(model, threshold):\n",
    "    pixel_mask =  ratio*model.select_lay.in_dim < threshold\n",
    "    return pixel_mask.cpu().detach()\n",
    "    \n",
    "def add_noise_on_pixel(x, pixel_mask):\n",
    "    uniform = torch.distributions.Uniform(0.5, 1)\n",
    "    noise = uniform.sample(x.size())\n",
    "    batch = x.shape[0]\n",
    "    ret = x.clone()\n",
    "    ret += pixel_mask.repeat(batch, 1).type(torch.FloatTensor)*noise\n",
    "    return ret\n",
    "\n",
    "def test_accuracy_with_noise(model, val_G, mask, iters=100):\n",
    "    mean_acc = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for it in xrange(iters):\n",
    "            x, y = next(val_G)\n",
    "            x, y = x, y.type(torch.long).flatten().cuda()\n",
    "            x = add_noise_on_pixel(x, pixel_mask).cuda()\n",
    "            out = model(x)\n",
    "            acc = calc_accracy(y, out)\n",
    "            mean_acc.append(acc)\n",
    "    return np.mean(mean_acc)\n",
    "            \n",
    "    \n",
    "pixel_mask = get_torch_mask(model, threshold)\n",
    "print pixel_mask\n",
    "print pixel_mask.shape\n",
    "pixel_idx = [i for i in range(pixel_mask.shape[-1]) if pixel_mask[0, i] == 1]\n",
    "# print np.[pixel_idx]\n",
    "print test_accuracy_with_noise(model, val_G, pixel_mask, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 100]) torch.Size([256])\n",
      "(10, 10, 3) 0.0 1.0\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe03aed5c90>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAACmpJREFUeJzt3U/IVXUex/HPZ7R/1lBBEaQyCkmDFEP1EJUQlC1qjNzMoqBg2riZyiKIGoIWbSMqiECsNkUtrEVEVAPVYoikR4tKLQhtTCu0aCqK8Sn6zOK5Axb53KPP+c157pf3CwLv7fTry+N9e84999yjkwhATb8begAA7RA4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UtbrHoGXZWtFgY2tZo3YsarYs2PpH0ZeJx2zUJfIWk6RYLQ2N/R48Rv1+TZarjdhyiA4UROFAYgQOFEThQGIEDhRE4UFinwG1fbfsj2x/bvrv1UAD6MTZw24skPSrpGkmrJd1ge3XrwQDMX5c9+MWSPk6yO8mMpGclrW87FoA+dAl8qaRPD3u8b/TcL9jeYHva9vTBvqYDMC+9nWRLsinJVJKpM/taFMC8dAl8v6Tlhz1eNnoOwALXJfC3Ja2yvdL28ZKul/RC27EA9GHst8mS/GT7FkmvSFok6YkkO5pPBmDeOn1dNMlLkl5qPAuAnnElG1AYgQOFEThQGIEDhRE4UFiTmy5OmlY3Mpwkxy1u81JYtWpVk3V3797d+5qHDh3qfU1JSpNVu2EPDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4U1uRWmtvU5k6lQ96dsrpzzjmnybr3339/k3U3btzY+5r799f7W7HZgwOFEThQGIEDhRE4UBiBA4UROFDY2MBtL7f9uu2dtnfY7v/zCQBNdPkc/CdJdybZbvv3krbZ/keSnY1nAzBPY/fgST5Psn306+8k7ZK0tPVgAObvqN6D214h6QJJW1sMA6BfnS9VtX2KpOck3Z7k29/49xskbehxNgDz1Clw28dpNu6nkzz/W9sk2SRp02h7LhsHFoAuZ9Et6XFJu5I82H4kAH3p8h58jaSbJF1p+93RP39uPBeAHow9RE/yT7X59ieAxriSDSiMwIHCCBwojMCBwggcKKzJTRcvkjTdYF1O5UuzlyX0b/369U3W/eqrr5qs+/XXXzdZt4UhX7fswYHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwprcVXWbuANqK8uXL2+y7hVXXNFk3XvvvbfJuj/88EOTdathDw4URuBAYQQOFEbgQGEEDhRG4EBhBA4U1jlw24tsv2P7xZYDAejP0ezBN0ra1WoQAP3rFLjtZZLWSdrcdhwAfeq6B39I0l2Sfj7SBrY32J62Pd3LZADmbWzgtq+VdCDJtrm2S7IpyVSSqd6mAzAvXfbgayRdZ/sTSc9KutL2U02nAtCLsYEnuSfJsiQrJF0v6bUkNzafDMC88Tk4UNhRfR88yRuS3mgyCYDesQcHCiNwoDACBwojcKAwAgcKa3JXVbSzdu3aJuvu2bOnybrvvfdek3XRDXtwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAw7qrayFlnndVk3XXr1jVZ95FHHmmy7szMTJN10Q17cKAwAgcKI3CgMAIHCiNwoDACBwrrFLjt02xvsf2h7V22L209GID56/o5+MOSXk7yF9vHS1rScCYAPRkbuO1TJV0u6a+SlGRGElcvABOgyyH6SkkHJT1p+x3bm22f3HguAD3oEvhiSRdKeizJBZK+l3T3rzeyvcH2tO3pnmcEcIy6BL5P0r4kW0ePt2g2+F9IsinJVJKpPgcEcOzGBp7kC0mf2j539NRaSTubTgWgF13Pot8q6enRGfTdkm5uNxKAvnQKPMm7kjj0BiYMV7IBhRE4UBiBA4UROFAYgQOFEThQWJO7ql4kqcX1qm6wZivnn39+k3UPHDjQZN233nqryboYFntwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwprctNFSCeccEKTdd98880m687MzDRZd5Jk6AGOQte/KJA9OFAYgQOFEThQGIEDhRE4UBiBA4UROFBYp8Bt32F7h+0PbD9j+8TWgwGYv7GB214q6TZJU0nOk7RI0vWtBwMwf10P0RdLOsn2YklLJH3WbiQAfRkbeJL9kh6QtFfS55K+SfLqr7ezvcH2tO3pg/3PCeAYdDlEP13SekkrJZ0t6WTbN/56uySbkkwlmTqz/zkBHIMuh+hXSdqT5GCSHyU9L+mytmMB6EOXwPdKusT2EtuWtFbSrrZjAehDl/fgWyVtkbRd0vuj/2ZT47kA9KDT98GT3CfpvsazAOgZV7IBhRE4UBiBA4UROFAYgQOFOen/XpJTdqZ7X7UdN1iz1V1V/3PoUJN1W/wMpHZ3Km0x76TdVXU6GftjYA8OFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhTW5K6qtg9K+leHTc+Q9GXvA7QzSfNO0qzSZM27EGb9Q5Izx23UJPCubE8nmRpsgKM0SfNO0qzSZM07SbNyiA4URuBAYUMHvmng///RmqR5J2lWabLmnZhZB30PDqCtoffgABoaLHDbV9v+yPbHtu8eao5xbC+3/brtnbZ32N449Exd2F5k+x3bLw49y1xsn2Z7i+0Pbe+yfenQM83F9h2j18EHtp+xfeLQM81lkMBtL5L0qKRrJK2WdIPt1UPM0sFPku5MslrSJZL+toBnPdxGSbuGHqKDhyW9nOSPkv6kBTyz7aWSbpM0leQ8SYskXT/sVHMbag9+saSPk+xOMiPpWUnrB5plTkk+T7J99OvvNPsCXDrsVHOzvUzSOkmbh55lLrZPlXS5pMclKclMkn8PO9VYiyWdZHuxpCWSPht4njkNFfhSSZ8e9nifFng0kmR7haQLJG0ddpKxHpJ0l6Sfhx5kjJWSDkp6cvR2YrPtk4ce6kiS7Jf0gKS9kj6X9E2SV4edam6cZOvI9imSnpN0e5Jvh57nSGxfK+lAkm1Dz9LBYkkXSnosyQWSvpe0kM/HnK7ZI82Vks6WdLLtG4edam5DBb5f0vLDHi8bPbcg2T5Os3E/neT5oecZY42k62x/otm3PlfafmrYkY5on6R9Sf53RLRFs8EvVFdJ2pPkYJIfJT0v6bKBZ5rTUIG/LWmV7ZW2j9fsiYoXBpplTrat2feIu5I8OPQ84yS5J8myJCs0+3N9LcmC3Msk+ULSp7bPHT21VtLOAUcaZ6+kS2wvGb0u1moBnxSUZg+R/u+S/GT7FkmvaPZM5BNJdgwxSwdrJN0k6X3b746e+3uSlwacqZJbJT09+oN+t6SbB57niJJstb1F0nbNfrryjhb4VW1cyQYUxkk2oDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwr7L47uMM8CzhYXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "def visualize_noise(img, pixel_mask):\n",
    "    assert len(img.shape) == 3 and img.shape[-1] == 3\n",
    "    mask = pixel_mask.reshape(10, 10)\n",
    "    mask = np.swapaxes(mask, 0, 1)\n",
    "    \n",
    "    ret = img.copy()\n",
    "    np.putmask(ret[:,:,0], mask, 1)\n",
    "    np.putmask(ret[:,:,1], mask, 0)\n",
    "    np.putmask(ret[:,:,2], mask, 0)\n",
    "    return ret\n",
    "\n",
    "def denormalize(x):\n",
    "    return x*0.3081 + 0.1307\n",
    "    \n",
    "for x, y in val_dataloader:\n",
    "    print x.shape, y.shape\n",
    "    break\n",
    "x = x[0:1,:]\n",
    "x = denormalize(x)\n",
    "m = x.numpy()\n",
    "m = np.repeat(m, 3, axis=0)\n",
    "# m = add_noise_on_pixel(m, pixel_idx)\n",
    "m = m.reshape([3, 10, 10])\n",
    "m = np.swapaxes(m, 0, 2)\n",
    "m = np.swapaxes(m, 0, 1)\n",
    "m = visualize_noise(m, pixel_mask)\n",
    "\n",
    "print m.shape, np.min(m), np.max(m)\n",
    "print y[0]\n",
    "plt.imshow(m, cmap=None, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist model visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import sklearn.metrics\n",
    "\n",
    "def calc_accracy(y, out):\n",
    "    label = y.flatten().cpu().detach().numpy().astype(np.int)\n",
    "    pred = torch.argmax(out, dim=-1).cpu().detach().numpy().astype(np.int)\n",
    "    return sklearn.metrics.accuracy_score(label, pred)\n",
    "            \n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float32)\n",
    "Y = iris.target.reshape([-1, 1]).astype(np.float32)\n",
    "# print iris.data.shape\n",
    "N = len(Y)\n",
    "batch_size = 8\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "\n",
    "DNN_model = SimpleDNN(X.shape[-1], 16, 3, 2, F.relu)\n",
    "model = SelectNet(X.shape[-1], DNN_model, DNN_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "gamma = 0\n",
    "epochs = 10000\n",
    "iters = 1\n",
    "noise_std = 25\n",
    "noise_col_idx = []\n",
    "writer = SummaryWriter('./AE_logs/Iris-a%f,b%f,g%f' % (alpha, beta, gamma))\n",
    "src_loss_criterion = nn.CrossEntropyLoss()\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "#         mask_idx = np.random.randint(0, X.shape[-1])\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_masked_noise(x, noise_std, noise_col_idx)\n",
    "            x, y = x.cuda(), y.type(torch.long).flatten().cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_masked_noise(val_x, noise_std, noise_col_idx)\n",
    "            val_x, val_y = val_x.cuda(), val_y.type(torch.long).flatten().cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "#             mask\n",
    "#             x = mask_column(x, mask_idx)\n",
    "#             val_x = mask_column(val_x, mask_idx)\n",
    "# \n",
    "            model.train()\n",
    "#             train_out = torch.softmax(model(x), dim=-1)\n",
    "            train_out = model(x)\n",
    "            reg_loss, w_loss, entropy_loss = model.calc_reg_loss(F.mse_loss)\n",
    "            src_loss = src_loss_criterion(train_out, y)\n",
    "            loss = alpha*reg_loss + beta*w_loss + gamma*entropy_loss + src_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "            \n",
    "#                 val_out = torch.softmax(model(val_x), dim=-1)\n",
    "                val_out = model(val_x)\n",
    "                val_src_loss = src_loss_criterion(val_out, val_y)\n",
    "                \n",
    "                \n",
    "#                 noised\n",
    "                noised_train_out = model(noised_x)\n",
    "                noised_val_out = model(val_noised_x)\n",
    "                noised_src = src_loss_criterion(noised_train_out, y)\n",
    "                val_noised_src = src_loss_criterion(noised_val_out, val_y)\n",
    "#                 acc\n",
    "                train_acc = calc_accracy(y, train_out)\n",
    "                val_acc = calc_accracy(val_y, val_out)\n",
    "                noised_train_acc = calc_accracy(y, noised_train_out)\n",
    "                noised_val_acc = calc_accracy(val_y, noised_val_out)\n",
    "                \n",
    "            \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            w_prine = torch.sigmoid(model.w).cpu().detach().numpy().flatten()\n",
    "            w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "#             buf = ','.join(['%d:%.2f' % (i+1,x) for i,x in enumerate(buf)])\n",
    "            buf = ','.join(['%2.3f, ' % (x) for i,x in enumerate(w_ratio)])\n",
    "            pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, loss: %.3f, val_loss: %.4f, w_loss : %.3f, entropy : %.3f, regularizer : %.3f                     %s' %\n",
    "                                 (\n",
    "                                     train_acc.item(), val_acc.item(),\n",
    "                                     src_loss.item(), val_src_loss.item(), \n",
    "                                     w_loss.item(), entropy_loss.item(),\n",
    "                                     reg_loss.item(), buf))\n",
    "            if epoch > 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/cross-entropy', {'train': src_loss.item(),\n",
    "                                                     'validation': val_src_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_loss', {'train': noised_src.item(),\n",
    "                                                     'validation': val_noised_src.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/accuracy', {'train': train_acc.item(),\n",
    "                                                     'validation': val_acc.item(),\n",
    "                                                     'noised_train': noised_train_acc.item(),\n",
    "                                                     'noised_validation': noised_val_acc.item(),\n",
    "                                                    },\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_loss', {'train': w_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/entropy', {'train': entropy_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_prine', {'w%d' % (i+1) : v  for i, v in enumerate(w_prine)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_ratio', {'w%d' % (i+1) : v  for i, v in enumerate(w_ratio)},\n",
    "                                                     iters)\n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/930 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1], [2], [3], [4], [0, 1], [0, 2], [0, 3], [0, 4], [1, 2], [1, 3], [1, 4], [2, 3], [2, 4], [3, 4], [0, 1, 2], [0, 1, 3], [0, 1, 4], [0, 2, 3], [0, 2, 4], [0, 3, 4], [1, 2, 3], [1, 2, 4], [1, 3, 4], [2, 3, 4], [0, 1, 2, 3], [0, 1, 2, 4], [0, 1, 3, 4], [0, 2, 3, 4], [1, 2, 3, 4], [0, 1, 2, 3, 4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 930/930 [28:41<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------+--------------------------------------------------------------------------------------------------------------+\n",
      "| Rank |  Accuracy over 30   |                                                using features                                                |\n",
      "+------+---------------------+--------------------------------------------------------------------------------------------------------------+\n",
      "|  1   |  0.9603174605066814 |        [0, 1, 2, 3, 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']        |\n",
      "|  2   |  0.9561904764743079 |             [1, 2, 3, 4, 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'sw * pw']             |\n",
      "|  3   |  0.9523809526080176 |                        [1, 2, 4, 'sepal width (cm)', 'petal length (cm)', 'sw * pw']                         |\n",
      "|  4   |  0.9507936510207161 | [0, 1, 2, 3, 4, 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'sw * pw'] |\n",
      "|  5   |  0.9507936509639497 |                                    [1, 4, 'sepal width (cm)', 'sw * pw']                                     |\n",
      "|  6   |  0.9457142859981172 |                   [0, 2, 3, 'sepal length (cm)', 'petal length (cm)', 'petal width (cm)']                    |\n",
      "|  7   |  0.9453968256617349 |                                           [3, 'petal width (cm)']                                            |\n",
      "|  8   |  0.9415873018522111 |            [0, 1, 2, 4, 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'sw * pw']             |\n",
      "|  9   |  0.9409523812172904 |                         [1, 3, 4, 'sepal width (cm)', 'petal width (cm)', 'sw * pw']                         |\n",
      "|  10  |  0.9358730162893022 |                                [1, 3, 'sepal width (cm)', 'petal width (cm)']                                |\n",
      "|  11  |  0.9295238097508748 |                    [0, 1, 3, 'sepal length (cm)', 'sepal width (cm)', 'petal width (cm)']                    |\n",
      "|  12  |  0.9269841274193354 |                                    [3, 4, 'petal width (cm)', 'sw * pw']                                     |\n",
      "|  13  |  0.9260317462777334 |                   [0, 1, 2, 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)']                    |\n",
      "|  14  |  0.9234920637380509 |                        [0, 1, 4, 'sepal length (cm)', 'sepal width (cm)', 'sw * pw']                         |\n",
      "|  15  |  0.9219047621223662 |                    [1, 2, 3, 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']                    |\n",
      "|  16  |  0.9212698417428941 |                               [0, 3, 'sepal length (cm)', 'petal width (cm)']                                |\n",
      "|  17  |  0.9212698416672056 |                               [0, 2, 'sepal length (cm)', 'petal length (cm)']                               |\n",
      "|  18  |  0.9161904763986194 |             [0, 1, 3, 4, 'sepal length (cm)', 'sepal width (cm)', 'petal width (cm)', 'sw * pw']             |\n",
      "|  19  |  0.9158730163271466 |                                           [2, 'petal length (cm)']                                           |\n",
      "|  20  |  0.914285714579007  |                               [2, 3, 'petal length (cm)', 'petal width (cm)']                                |\n",
      "|  21  |  0.9111111116220081 |            [0, 2, 3, 4, 'sepal length (cm)', 'petal length (cm)', 'petal width (cm)', 'sw * pw']             |\n",
      "|  22  |  0.8996825400042157 |                        [0, 2, 4, 'sepal length (cm)', 'petal length (cm)', 'sw * pw']                        |\n",
      "|  23  |  0.8879365086744703 |                               [1, 2, 'sepal width (cm)', 'petal length (cm)']                                |\n",
      "|  24  |  0.8815873021928092 |                        [0, 3, 4, 'sepal length (cm)', 'petal width (cm)', 'sw * pw']                         |\n",
      "|  25  |  0.8793650800462754 |                                    [0, 4, 'sepal length (cm)', 'sw * pw']                                    |\n",
      "|  26  |   0.86444444521079  |                                                [4, 'sw * pw']                                                |\n",
      "|  27  |  0.8476190485840752 |                                    [2, 4, 'petal length (cm)', 'sw * pw']                                    |\n",
      "|  28  |  0.8434920641921816 |                        [2, 3, 4, 'petal length (cm)', 'petal width (cm)', 'sw * pw']                         |\n",
      "|  29  |  0.6422222236224585 |                               [0, 1, 'sepal length (cm)', 'sepal width (cm)']                                |\n",
      "|  30  | 0.31555555601441665 |                                           [1, 'sepal width (cm)']                                            |\n",
      "|  31  | 0.30222222282536454 |                                           [0, 'sepal length (cm)']                                           |\n",
      "+------+---------------------+--------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from itertools import combinations\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float32)\n",
    "buf = (X[:,1] * X[:,3]).reshape([-1, 1])\n",
    "X = np.concatenate([X, buf], axis=1)\n",
    "Y = iris.target.reshape([-1, 1]).astype(np.float32)\n",
    "buf = X[:]\n",
    "def init_sess():\n",
    "    K.clear_session()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                        # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "def train_model(X, Y, iters, pbar):\n",
    "    input_dim = X.shape[-1]\n",
    "    arr = []\n",
    "    cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        \n",
    "    for i in range(iters):\n",
    "        init_sess()\n",
    "        X_train,X_test,y_train,y_test=train_test_split(X,Y,train_size=0.3)\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64,input_shape=(input_dim,), activation='relu'))\n",
    "#         model.add(Dropout(0.2))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "#         model.add(Dropout(0.2))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "        model.fit(X_train,y_train, epochs=500,batch_size=5,\n",
    "                  verbose=0, validation_data=[X_test, y_test],\n",
    "                  callbacks=[cb]\n",
    "                 )\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        arr.append(accuracy)\n",
    "        pbar.update(1)\n",
    "    return np.mean(arr)\n",
    "idx_set = []\n",
    "feature_names = iris.feature_names + ['sw * pw']\n",
    "for i in range(len(feature_names)):\n",
    "    for idxs in combinations(np.arange(len(feature_names)), i+1):\n",
    "        idx_set.append(list(idxs))\n",
    "print idx_set\n",
    "# print X.shape\n",
    "iters = 30\n",
    "acc_arr = []\n",
    "with tqdm(total=len(idx_set)*iters) as pbar:\n",
    "    for idx in idx_set:\n",
    "        acc = train_model(X[:, idx], Y, iters, pbar)\n",
    "        acc_arr.append([idx, acc])\n",
    "acc_arr = sorted(acc_arr, key=lambda x: x[1], reverse=True)\n",
    "T = PrettyTable()\n",
    "T.field_names = [\"Rank\", \"Accuracy over %d \" % iters, \"using features\"]\n",
    "for i, (idx, acc) in enumerate(acc_arr):\n",
    "    row = [i+1, acc, idx + [feature_names[x] for x in idx]]\n",
    "    T.add_row(row)\n",
    "print T    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------------------------------------------------------------------------------------------+\n",
      "| Rank | Accuracy over 30  |                                      using features                                      |\n",
      "+------+-------------------+------------------------------------------------------------------------------------------+\n",
      "|  1   |       0.960       |        [0, 1, 2, 3, 'sepal length', 'sepal width', 'petal length', 'petal width']        |\n",
      "|  2   |       0.956       |          [1, 2, 3, 4, 'sepal width', 'petal length', 'petal width', 'sw * pw']           |\n",
      "|  3   |       0.952       |                   [1, 2, 4, 'sepal width', 'petal length', 'sw * pw']                    |\n",
      "|  4   |       0.951       | [0, 1, 2, 3, 4, 'sepal length', 'sepal width', 'petal length', 'petal width', 'sw * pw'] |\n",
      "|  5   |       0.951       |                             [1, 4, 'sepal width', 'sw * pw']                             |\n",
      "|  6   |       0.946       |                 [0, 2, 3, 'sepal length', 'petal length', 'petal width']                 |\n",
      "|  7   |       0.945       |                                    [3, 'petal width']                                    |\n",
      "|  8   |       0.942       |          [0, 1, 2, 4, 'sepal length', 'sepal width', 'petal length', 'sw * pw']          |\n",
      "|  9   |       0.941       |                    [1, 3, 4, 'sepal width', 'petal width', 'sw * pw']                    |\n",
      "|  10  |       0.936       |                           [1, 3, 'sepal width', 'petal width']                           |\n",
      "|  11  |       0.930       |                 [0, 1, 3, 'sepal length', 'sepal width', 'petal width']                  |\n",
      "|  12  |       0.927       |                             [3, 4, 'petal width', 'sw * pw']                             |\n",
      "|  13  |       0.926       |                 [0, 1, 2, 'sepal length', 'sepal width', 'petal length']                 |\n",
      "|  14  |       0.923       |                   [0, 1, 4, 'sepal length', 'sepal width', 'sw * pw']                    |\n",
      "|  15  |       0.922       |                 [1, 2, 3, 'sepal width', 'petal length', 'petal width']                  |\n",
      "|  16  |       0.921       |                          [0, 3, 'sepal length', 'petal width']                           |\n",
      "|  17  |       0.921       |                          [0, 2, 'sepal length', 'petal length']                          |\n",
      "|  18  |       0.916       |          [0, 1, 3, 4, 'sepal length', 'sepal width', 'petal width', 'sw * pw']           |\n",
      "|  19  |       0.916       |                                   [2, 'petal length']                                    |\n",
      "|  20  |       0.914       |                          [2, 3, 'petal length', 'petal width']                           |\n",
      "|  21  |       0.911       |          [0, 2, 3, 4, 'sepal length', 'petal length', 'petal width', 'sw * pw']          |\n",
      "|  22  |       0.900       |                   [0, 2, 4, 'sepal length', 'petal length', 'sw * pw']                   |\n",
      "|  23  |       0.888       |                          [1, 2, 'sepal width', 'petal length']                           |\n",
      "|  24  |       0.882       |                   [0, 3, 4, 'sepal length', 'petal width', 'sw * pw']                    |\n",
      "|  25  |       0.879       |                            [0, 4, 'sepal length', 'sw * pw']                             |\n",
      "|  26  |       0.864       |                                      [4, 'sw * pw']                                      |\n",
      "|  27  |       0.848       |                            [2, 4, 'petal length', 'sw * pw']                             |\n",
      "|  28  |       0.843       |                   [2, 3, 4, 'petal length', 'petal width', 'sw * pw']                    |\n",
      "|  29  |       0.642       |                          [0, 1, 'sepal length', 'sepal width']                           |\n",
      "|  30  |       0.316       |                                    [1, 'sepal width']                                    |\n",
      "|  31  |       0.302       |                                   [0, 'sepal length']                                    |\n",
      "+------+-------------------+------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "T = PrettyTable()\n",
    "T.field_names = [\"Rank\", \"Accuracy over %d \" % iters, \"using features\"]\n",
    "for i, (idx, acc) in enumerate(acc_arr):\n",
    "    acc = '%.3f' % acc\n",
    "    row = [i+1, acc, idx + [feature_names[x].replace(' (cm)','') for x in idx]]\n",
    "    T.add_row(row)\n",
    "print T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "(0, 1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "print '%s' % ([iris.feature_names[x] for x in idxs ])\n",
    "print idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = nn.Conv2d(1, 16, 3, padding=1)\n",
    "print cnn.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_noise(model, val_G, label, iters=100):\n",
    "    x_ax = np.linspace(1, 30, 100)\n",
    "    src_arr = []\n",
    "    noised_arr = []\n",
    "    for std in x_ax:\n",
    "        src_mse_loss = 0\n",
    "        noised_mse_loss = 0\n",
    "        normal = torch.distributions.Normal(0, std)\n",
    "        for i in range(iters):\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "            N = val_x.shape[0]\n",
    "            noise = torch.cat([torch.zeros_like(val_x)[:,:-2], normal.sample([N,2]).cuda()], dim=1)\n",
    "            out1,_ = model(val_x)\n",
    "            out2,_ = model(val_x + noise)\n",
    "            src_mse_loss += F.mse_loss(out1, val_y)\n",
    "            noised_mse_loss += F.mse_loss(out2, val_y)\n",
    "        src_mse_loss /= iters\n",
    "        noised_mse_loss /= iters\n",
    "        src_arr.append(src_mse_loss.item())\n",
    "        noised_arr.append(noised_mse_loss.item())\n",
    "    \n",
    "#     plt.plot(x_ax, src_arr, label=label + ' mse')\n",
    "    plt.plot(x_ax, noised_arr, label=label + ' mse with noise')\n",
    "# eval_noise(att_model, val_G, 'selection', 10)\n",
    "eval_noise(model, val_G, 'src', 10 )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print X.shape, Y.shape\n",
    "print Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float32)\n",
    "Y = iris.target.reshape([-1, 1]).astype(np.float32)\n",
    "# print iris.data.shape\n",
    "N = len(Y)\n",
    "batch_size = 32\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "model = Attention_Autoendecoder(X.shape[-1]).cuda()\n",
    "# opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "opt = optim.Adam(model.parameters())\n",
    "alpha = 100\n",
    "beta = 0\n",
    "epochs = 1000\n",
    "iters = 1\n",
    "noise_std = 5\n",
    "noise_col_idx = [2, 3]\n",
    "writer = SummaryWriter('./AE_logs/Iris-a%f,b%f' % (alpha, beta))\n",
    "reg_l2_coe = 0.1\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        mask_idx = np.random.randint(0, X.shape[-1])\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_masked_noise(x, noise_std, noise_col_idx)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_masked_noise(val_x, noise_std, noise_col_idx)\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "#             mask\n",
    "#             x = mask_column(x, mask_idx)\n",
    "#             val_x = mask_column(val_x, mask_idx)\n",
    "# \n",
    "            model.train()\n",
    "            out, att_w = model(x)\n",
    "            w_ = torch.softmax(att_w, dim=-1)\n",
    "            mse_loss = F.mse_loss(out, y)\n",
    "            att_loss = alpha*(F.l1_loss(att_w, torch.zeros_like(att_w)) + beta*entropy_loss(w_))\n",
    "            reg_loss = reg_l2_coe * regularizer(model.kernel_weights, F.mse_loss)\n",
    "            loss = att_loss + mse_loss + reg_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                out, _ = model(val_x)\n",
    "                val_mse_loss = F.mse_loss(out, val_y)\n",
    "                val_loss = att_loss + val_mse_loss + reg_loss\n",
    "#                 noised\n",
    "                noised_mse = F.mse_loss(model(noised_x)[0], y)\n",
    "                val_noised_mse = F.mse_loss(model(val_noised_x)[0], val_y)\n",
    "                \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            att_w_arr = att_w.cpu().detach().numpy().flatten()\n",
    "            ratio_w = (att_w / torch.sum(att_w)).cpu().detach().numpy().flatten()\n",
    "#             buf = ','.join(['%d:%.2f' % (i+1,x) for i,x in enumerate(buf)])\n",
    "            buf = ','.join(['%2.3f, ' % (x) for i,x in enumerate(ratio_w)])\n",
    "            buf += 'l1 %.3f, entropy %.3f' % (F.l1_loss(att_w, torch.zeros_like(att_w)).item(), entropy_loss(w_).item())\n",
    "            pbar.set_postfix_str('loss: %.3f, val_loss: %.4f, att_loss : %.3f, regularizer : %.3f                     %s' %\n",
    "                                 (mse_loss.item(), val_mse_loss.item(), \n",
    "                                  att_loss.item(),\n",
    "                                  reg_loss.item(), buf))\n",
    "#             if mse_loss.item() < 100:\n",
    "            if epoch > 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item(),\n",
    "                                                     'validation': val_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/mse_loss', {'train': mse_loss.item(),\n",
    "                                                     'validation': val_mse_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_mse_loss', {'train': noised_mse.item(),\n",
    "                                                     'validation': val_noised_mse.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/att_loss', {'train': att_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/att_w', {'w%d' % (i+1) : v  for i, v in enumerate(att_w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/ratio_att_w', {'w%d' % (i+1) : v  for i, v in enumerate(ratio_w)},\n",
    "                                                     iters)\n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n",
    "print att_w[0,: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_mse_loss = 0\n",
    "noised_mse_loss = 0\n",
    "normal = torch.distributions.Normal(0, 20)\n",
    "\n",
    "for i in range(100):\n",
    "    val_x, val_y = next(val_G)\n",
    "    val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "    N = val_x.shape[0]\n",
    "    noise = torch.cat([torch.zeros_like(val_x)[:,:-2], normal.sample([N,2]).cuda()], dim=1)\n",
    "    out1,_ = model(val_x)\n",
    "    out2,_ = model(val_x + noise)\n",
    "    src_mse_loss += F.mse_loss(out1, val_y)\n",
    "    noised_mse_loss += F.mse_loss(out2, val_y)\n",
    "    \n",
    "print src_mse_loss\n",
    "print noised_mse_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(torch.FloatTensor([1,0,0]), dim=0)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "input_x = np.hstack([h, w, iid, iid2])\n",
    "print input_x.shape\n",
    "m = Sequential()\n",
    "m.add(Dense(32, activation='selu'))\n",
    "m.add(Dense(32, activation='selu'))\n",
    "m.add(Dense(1, activation='linear'))\n",
    "m.compile(loss='mse', optimizer='adam')\n",
    "m.fit(input_x, bmi, epochs=100, batch_size=128, validation_split=0.1)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x1.shape\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(x1.flatten(), y1.flatten(), y2.flatten(), label='curve')\n",
    "ax.legend()\n",
    "print X.shape\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "theta = np.linspace(-4 * np.pi, 4 * np.pi, 100)\n",
    "z = np.linspace(-2, 2, 100)\n",
    "r = z**2 + 1\n",
    "x = r * np.sin(theta)\n",
    "y = r * np.cos(theta)\n",
    "ax.plot(x, y, z, label='parametric curve')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.14 (conda)",
   "language": "python",
   "name": "python-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
