{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^((?!.*((w_prine)|(w_value)).*).)*$\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optimi\n",
    "import sklearn.preprocessing\n",
    "import sklearn.metrics\n",
    "import torchvision\n",
    "from utils.Training_utils import *\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.CustomDataset import CustomDataset\n",
    "from utils.SimpleDNN import SimpleDNN\n",
    "from utils.SimpleCNN import SimpleCNN\n",
    "from SelectNet import *\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 8) (5000, 1)\n",
      "0.3208 0.46678406\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 676817/1800000 [6:49:07<11:23:25, 27.39it/s, acc :      1.000, val_acc :      0.992, loss:      0.003,                              val_loss:     0.0198, w_loss :      0.125, entropy :      2.404,                              regularizer :      0.052                                     -0.5*x2:  0.01,                           x1^2 permutation: 11.48,                              normal random: 85.95,                             x2 permutation: 92.34,                             uniform random:102.14,                            x1 permuatation:124.26,                                         x2:203.84,                                         x1:379.98]"
     ]
    }
   ],
   "source": [
    "def F1(x1, x2):\n",
    "    return 0.02*np.power(x1, 2) + 0.3*x2 - 2.\n",
    "def F2(x1, x2):\n",
    "    return -0.5*x2 \n",
    "\n",
    "N = 5000\n",
    "low = -50\n",
    "high = 75\n",
    "cut = 13\n",
    "x1 = np.random.uniform(low, high, N)\n",
    "x2 = np.random.uniform(low, high, N)\n",
    "x3 = F2(x1, x2)\n",
    "x4 = np.random.uniform(low, high, N)\n",
    "x5 = np.random.normal((low+high)/2., 10, N)\n",
    "\n",
    "x6 = x1[np.random.permutation(N)]\n",
    "x7 = np.power(x1, 2)[np.random.permutation(N)]\n",
    "x8 = x2[np.random.permutation(N)]\n",
    "X = np.swapaxes(np.vstack([x1, x2, x3, x4, x5, x6, x7, x8]), 0, 1)\n",
    "feature_names = [\n",
    "            'x1', 'x2', '-0.5*x2', 'uniform random', 'normal random', \n",
    "            'x1 permuatation', 'x1^2 permutation', 'x2 permutation',\n",
    "]\n",
    "\n",
    "Y = F1(x1, x2).reshape([-1, 1]) < cut\n",
    "Y = Y.astype(np.float32)\n",
    "print X.shape, Y.shape\n",
    "print np.mean(Y), np.std(Y)\n",
    "\n",
    "# visualization\n",
    "vis_N = np.random.permutation(N)[:1000]\n",
    "# pos_mask = (Y < cut)[:vis_N]\n",
    "# neg_mask = (Y >= cut)[:vis_N]\n",
    "pos_mask = Y[vis_N] == 1\n",
    "neg_mask = Y[vis_N] == 0\n",
    "# print mask\n",
    "plt.scatter(x1[vis_N], x2[vis_N], marker='o', s=pos_mask, label='Positive')\n",
    "plt.scatter(x1[vis_N], x2[vis_N], marker='o', s=neg_mask, label='Negative')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# \n",
    "batch_size = 256\n",
    "N = len(Y)\n",
    "x_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda x:torch.from_numpy(x)),\n",
    "    transforms.Lambda(lambda x:x.float()),\n",
    "    transforms.Lambda(lambda x:x.cuda()),\n",
    "])\n",
    "y_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda y:torch.from_numpy(y)),\n",
    "    transforms.Lambda(lambda y:y.type(torch.float).flatten()),\n",
    "    transforms.Lambda(lambda y:y.cuda()),\n",
    "])\n",
    "# X = sklearn.preprocessing.normalize(X, axis=0)\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y,\n",
    "                                                                         x_transforms=x_transforms,\n",
    "                                                                         y_transforms=y_transforms,\n",
    "                                                                        ), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.dnn = SimpleDNN(in_dim, 16, 1, 3, F.relu)\n",
    "        self.kernel_weights = self.dnn.kernel_weights\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dnn(x)\n",
    "        return x\n",
    "def synthesized_noise_fn(x):\n",
    "    noise_distribution = torch.distributions.Uniform(0.5, 5)\n",
    "    x[:, 2:] += noise_distribution.sample(x.shape)[:, 2:].cuda()\n",
    "    return x\n",
    "ver = 3\n",
    "p = 1\n",
    "simple_model = Net(X.shape[-1])\n",
    "model = SelectNet(X.shape[-1], simple_model, simple_model.kernel_weights, ver, p, use_norm_lay=False).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "# beta = 0\n",
    "gamma = 0\n",
    "epochs = 100000\n",
    "iters = 1\n",
    "\n",
    "src_loss_criterion = nn.BCEWithLogitsLoss()\n",
    "train(model, opt, src_loss_criterion, train_dataloader, \n",
    "      val_dataloader, alpha, beta, gamma, \n",
    "      epochs, noise_fn=synthesized_noise_fn, \n",
    "      metric_fn=calc_accracy_sigmoid, log_name='Synthesizied', \n",
    "      feature_names=feature_names, \n",
    "      log_period=10, K=4\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00462151  0.00472388 -0.00472388  0.00457797  0.01101238  0.00462151\n",
      "  0.0099789   0.00472388]\n",
      "[0.01336569 0.01332985 0.01332985 0.01338067 0.00887285 0.01336569\n",
      " 0.01002106 0.01332985]\n"
     ]
    }
   ],
   "source": [
    "X.shape\n",
    "a = sklearn.preprocessing.normalize(X, axis=0)\n",
    "print np.mean(a, axis=0)\n",
    "print np.std(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_mask = Y[vis_N]\n",
    "neg_mask = Y[vis_N]\n",
    "# print mask\n",
    "# plt.scatter(x1[vis_N], x2[vis_N], marker='o', s=pos_mask, label='Positive')\n",
    "# plt.scatter(x1[vis_N], x2[vis_N], marker='o', s=neg_mask, label='Negative')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "# pos_mask\n",
    "neg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_N.shape\n",
    "Y.shape\n",
    "Y[vis_N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(79.9920, device='cuda:0', grad_fn=<NormBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = model.select_lay\n",
    "l.w.norm(l.p) / "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dengue data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4894, 63) (4894, 1)\n",
      "[2942.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 43440/180000 [55:10<2:51:29, 13.27it/s, acc :      0.840, val_acc :      0.833, loss:      0.354,                              val_loss:     0.4748, w_loss :      0.001, entropy :      3.697,                              regularizer :      0.054                      Cancer with Metastasis:  0.00,                            Hyperthyroidism:  0.00,                             Mental Illness:  0.00,                            Hyperlipidaemia:  0.00,                                   exam_WBC: 55.44,                              merged_height: 79.23,                                    exam_NA:159.32,                                       Temp:270.19]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "data = np.load('/home/k123/git/ncku_project/src/medical/data.npz')\n",
    "iid1 = [0, 1, 9, 10, 11, 24]\n",
    "iid2 = [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 24]\n",
    "iid3 = [0, 1, 2, 3, 5, 6, 7, 9, 10, 11, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "\n",
    "iid = iid1\n",
    "\n",
    "\n",
    "X = data['x'][:, iid]\n",
    "X = data['x']\n",
    "v_mask = data['missing_mask']\n",
    "Y = data['y']\n",
    "X = X[v_mask, :].astype(np.float32)\n",
    "Y = Y[v_mask, :].astype(np.float32)\n",
    "\n",
    "print X.shape, Y.shape\n",
    "print sum(Y)\n",
    "            \n",
    "\n",
    "batch_size = 256\n",
    "N = len(Y)\n",
    "x_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda x:torch.from_numpy(x)),\n",
    "    transforms.Lambda(lambda x:x.float()),\n",
    "    transforms.Lambda(lambda x:x.cuda()),\n",
    "])\n",
    "y_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda y:torch.from_numpy(y)),\n",
    "    transforms.Lambda(lambda y:y.type(torch.float).flatten()),\n",
    "    transforms.Lambda(lambda y:y.cuda()),\n",
    "])\n",
    "            \n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y,\n",
    "                                                                         x_transforms=x_transforms,\n",
    "                                                                         y_transforms=y_transforms,\n",
    "                                                                        ), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(Net, self).__init__()\n",
    "        self.dnn = SimpleDNN(in_dim, 16, 1, 3, F.relu)\n",
    "        self.kernel_weights = self.dnn.kernel_weights\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dnn(x)\n",
    "        return x\n",
    "def dengue_noise_fn(x):\n",
    "    noise_distribution = torch.distributions.Uniform(0.5, 1)\n",
    "    x[:, 0] += noise_distribution.sample(x.shape)[:, 0].cuda()\n",
    "    return x\n",
    "simple_model = Net(X.shape[-1])\n",
    "model = SelectNet(X.shape[-1], simple_model, simple_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "# beta = 0\n",
    "gamma = 0\n",
    "epochs = 10000\n",
    "iters = 1\n",
    "src_loss_criterion = nn.BCEWithLogitsLoss()\n",
    "feature_names = data['feature_names']\n",
    "train(model, opt, src_loss_criterion, train_dataloader, \n",
    "      val_dataloader, alpha, beta, gamma, \n",
    "      epochs, noise_fn=dengue_noise_fn, \n",
    "      metric_fn=calc_accracy_sigmoid, log_name='Dengue', \n",
    "      feature_names=feature_names, \n",
    "      log_period=10, K=4\n",
    "     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'Temp', 0.2378159)\n",
      "(u'exam_NA', 0.09374473)\n",
      "(u'merged_height', 0.075081654)\n",
      "(u'exam_WBC', 0.068373166)\n",
      "(u'exam_Hb', 0.0621576)\n",
      "(u'exam_CRP', 0.046066813)\n",
      "(u'SBP', 0.044948414)\n",
      "(u'sex', 0.039721448)\n",
      "(u'exam_PT', 0.034997687)\n",
      "(u'Pulse', 0.033641547)\n",
      "(u'age', 0.03350617)\n",
      "(u'exam_APTT', 0.03278675)\n",
      "(u'merged_weight', 0.02721474)\n",
      "(u'exam_Plt', 0.025029268)\n",
      "(u'bmi', 0.024489818)\n",
      "(u'exam_GLU', 0.023236427)\n",
      "(u'MAP', 0.021679584)\n",
      "(u'Breath', 0.021462012)\n",
      "(u'DBP', 0.020698708)\n",
      "(u'exam_AST', 0.014917306)\n",
      "(u'exam_ALT', 0.00986625)\n",
      "(u'exam_CREA', 0.008563927)\n",
      "[u'Temp', u'exam_NA', u'merged_height', u'exam_WBC', u'exam_Hb', u'exam_CRP', u'SBP', u'sex', u'exam_PT', u'Pulse', u'age', u'exam_APTT', u'merged_weight', u'exam_Plt', u'bmi', u'exam_GLU', u'MAP', u'Breath', u'DBP', u'exam_AST', u'exam_ALT', u'exam_CREA']\n",
      "[0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24]\n"
     ]
    }
   ],
   "source": [
    "w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "sorted_ratio = sorted([(data['feature_names'][i],x) for i,x in enumerate(w_ratio)], key=lambda x:x[1], reverse=True)\n",
    "for x in sorted_ratio[:22]:\n",
    "    print x\n",
    "names = [x[0] for x in sorted_ratio[:22]]\n",
    "print names\n",
    "idx =[data['feature_names'].tolist().index(n) for n in names]\n",
    "print sorted(idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesized XOR data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ab387f337240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miid2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;31m# X = torch.from_numpy(np.hstack([x1, x2, y1, y2, y3, iid, iid2]).astype(np.float32))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# X = torch.from_numpy(np.hstack([x1, x2, y1, y2, y3, iid, iid2]).astype(np.float32))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_xor(N):\n",
    "    X = []\n",
    "    Y = []\n",
    "    offset = 10\n",
    "    std = 2\n",
    "    for i in range(N):\n",
    "        idx = np.random.randint(0, 4)\n",
    "        if idx == 0:\n",
    "            s = np.random.normal([offset, offset], std)\n",
    "            y = 1\n",
    "        elif idx == 1:\n",
    "            s = np.random.normal([2*offset, offset], std)\n",
    "            y = 0\n",
    "        elif idx == 2:\n",
    "            s = np.random.normal([offset, 2*offset], std)\n",
    "            y = 0\n",
    "        elif idx == 3:\n",
    "            s = np.random.normal([2*offset, 2*offset], std)\n",
    "            y = 1\n",
    "        X.append(s)\n",
    "        Y.append(y)\n",
    "    return np.asarray(X), np.array(Y).reshape([-1, 1])\n",
    "        \n",
    "\n",
    "N = 1500\n",
    "X, Y = generate_xor(N)\n",
    "\n",
    "print X.shape\n",
    "display_N = 300\n",
    "neg_idx, pos_idx = np.where(Y == 0)[0][:display_N], np.where(Y == 1)[0][:display_N]\n",
    "fig = plt.figure()\n",
    "# ax = fig.gca(projection='3d')\n",
    "ax = fig.gca()\n",
    "ax.scatter(X[neg_idx,0], X[neg_idx, 1], label='negative')\n",
    "ax.scatter(X[pos_idx,0], X[pos_idx, 1], label='positive')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "X = torch.from_numpy(np.hstack([h, w, iid, iid2]).astype(np.float32))\n",
    "# X = torch.from_numpy(np.hstack([x1, x2, y1, y2, y3, iid, iid2]).astype(np.float32))\n",
    "# X = torch.from_numpy(np.hstack([x1, x2, y1, y2, y3, iid, iid2]).astype(np.float32))\n",
    "\n",
    "# X = torch.from_numpy(x1.astype(np.float32))\n",
    "# X = torch.from_numpy(np.hstack([x1, iid]).astype(np.float32))\n",
    "# X, norm = sklearn.preprocessing.normalize(X, axis=0, return_norm=True)\n",
    "# X = X.astype(np.float32)\n",
    "# print norm.shape\n",
    "Y = torch.from_numpy(bmi.astype(np.float32))\n",
    "# Y = torch.from_numpy(y4.astype(np.float32))\n",
    "# Y = torch.from_numpy((bmi > 25).astype(np.float32))\n",
    "print X.shape, Y.shape\n",
    "batch_size = 128\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "DNN_model = SimpleDNN(X.shape[-1], 16, 1, 2, F.relu)\n",
    "model = SelectNet(X.shape[-1], DNN_model, DNN_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "gamma = 0\n",
    "epochs = 1000\n",
    "iters = 1\n",
    "noise_std = 25\n",
    "noise_col_idx = [2, 3]\n",
    "writer = SummaryWriter('./AE_logs/XOR-a%f,b%f,g%f' % (alpha, beta, gamma))\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_masked_noise(x, noise_std, noise_col_idx)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_masked_noise(val_x, noise_std, noise_col_idx)\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "#             mask\n",
    "#             x = mask_column(x, mask_idx)\n",
    "#             val_x = mask_column(val_x, mask_idx)\n",
    "# \n",
    "            model.train()\n",
    "            out = model(x)\n",
    "            reg_loss, w_loss, entropy_loss = model.calc_reg_loss(F.mse_loss)\n",
    "            mse_loss = F.mse_loss(out, y)\n",
    "            loss = alpha*reg_loss + beta*w_loss + gamma*entropy_loss + mse_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "            \n",
    "                out = model(val_x)\n",
    "                val_mse_loss = F.mse_loss(out, val_y)\n",
    "#                 noised\n",
    "                noised_mse = F.mse_loss(model(noised_x), y)\n",
    "                val_noised_mse = F.mse_loss(model(val_noised_x), val_y)\n",
    "                \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            w_prine = torch.sigmoid(model.w).cpu().detach().numpy().flatten()\n",
    "            w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "#             buf = ','.join(['%d:%.2f' % (i+1,x) for i,x in enumerate(buf)])\n",
    "            buf = ','.join(['%2.3f, ' % (x) for i,x in enumerate(w_ratio)])\n",
    "            pbar.set_postfix_str('loss: %.3f, val_loss: %.4f, w_loss : %.3f, entropy : %.3f, regularizer : %.3f                     %s' %\n",
    "                                 (mse_loss.item(), val_mse_loss.item(), \n",
    "                                  w_loss.item(), entropy_loss.item(),\n",
    "                                  reg_loss.item(), buf))\n",
    "#             if mse_loss.item() < 100:\n",
    "            if epoch > 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/mse_loss', {'train': mse_loss.item(),\n",
    "                                                     'validation': val_mse_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_mse_loss', {'train': noised_mse.item(),\n",
    "                                                     'validation': val_noised_mse.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_loss', {'train': w_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/entropy', {'train': entropy_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w\\'', {'w%d' % (i+1) : v  for i, v in enumerate(w_prine)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_ratio', {'w%d' % (i+1) : v  for i, v in enumerate(w_ratio)},\n",
    "                                                     iters)\n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(Y == 0)[0][:200].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 55748/3910000 [6:54:21<492:37:00,  2.17it/s, acc :      0.719, val_acc :      0.703, loss:      0.835,                              val_loss:     0.8734, w_loss :      0.002, entropy :     10.192,                              regularizer :      0.053                                  pixel_1181:  0.17,                                    pixel_1:  0.23,                                  pixel_820:  0.26,                                   pixel_20:  0.26,                                  pixel_668:  1.11,                                  pixel_708:  1.12,                                  pixel_710:  1.12,                                  pixel_589:  1.12]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 60046/3910000 [7:27:24<421:51:44,  2.54it/s, acc :      0.727, val_acc :      0.789, loss:      0.807,                              val_loss:     0.6310, w_loss :      0.002, entropy :     10.193,                              regularizer :      0.056                                  pixel_1181:  0.17,                                    pixel_1:  0.23,                                  pixel_820:  0.27,                                   pixel_20:  0.27,                                  pixel_650:  1.10,                                  pixel_610:  1.11,                                  pixel_630:  1.11,                                  pixel_750:  1.12]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 64154/3910000 [7:55:17<490:17:24,  2.18it/s, acc :      0.719, val_acc :      0.766, loss:      0.693,                              val_loss:     0.6761, w_loss :      0.002, entropy :     10.194,                              regularizer :      0.060                                  pixel_1181:  0.18,                                    pixel_1:  0.23,                                  pixel_440:  0.29,                                   pixel_20:  0.29,                                  pixel_628:  1.10,                                  pixel_402:  1.10,                                  pixel_710:  1.11,                                  pixel_768:  1.13]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 68452/3910000 [8:24:42<567:42:20,  1.88it/s, acc :      0.773, val_acc :      0.719, loss:      0.736,                              val_loss:     0.8059, w_loss :      0.002, entropy :     10.196,                              regularizer :      0.063                                  pixel_1181:  0.21,                                    pixel_1:  0.24,                                   pixel_20:  0.27,                                  pixel_820:  0.29,                                  pixel_168:  1.11,                                  pixel_768:  1.11,                                  pixel_208:  1.13,                                  pixel_402:  1.18]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 72499/3910000 [8:52:10<425:15:54,  2.51it/s, acc :      0.773, val_acc :      0.781, loss:      0.725,                              val_loss:     0.6410, w_loss :      0.002, entropy :     10.197,                              regularizer :      0.066                                  pixel_1181:  0.23,                                    pixel_1:  0.26,                                   pixel_20:  0.26,                                  pixel_820:  0.29,                                  pixel_768:  1.10,                                  pixel_187:  1.10,                                  pixel_229:  1.11,                                  pixel_402:  1.17]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 76812/3910000 [9:21:29<433:01:06,  2.46it/s, acc :      0.750, val_acc :      0.727, loss:      0.664,                              val_loss:     0.8412, w_loss :      0.001, entropy :     10.198,                              regularizer :      0.070                                     pixel_1:  0.25,                                 pixel_1181:  0.26,                                   pixel_20:  0.28,                                  pixel_820:  0.30,                                  pixel_629:  1.08,                                  pixel_668:  1.09,                                  pixel_768:  1.11,                                  pixel_402:  1.19]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 80972/3910000 [9:49:47<422:09:23,  2.52it/s, acc :      0.797, val_acc :      0.789, loss:      0.624,                              val_loss:     0.7104, w_loss :      0.001, entropy :     10.199,                              regularizer :      0.073                                     pixel_1:  0.27,                                 pixel_1181:  0.27,                                   pixel_20:  0.27,                                  pixel_820:  0.30,                                  pixel_250:  1.10,                                  pixel_768:  1.11,                                  pixel_769:  1.11,                                  pixel_402:  1.19]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 85309/3910000 [10:19:20<433:13:51,  2.45it/s, acc :      0.766, val_acc :      0.773, loss:      0.784,                              val_loss:     0.6804, w_loss :      0.001, entropy :     10.199,                              regularizer :      0.076                                  pixel_1181:  0.28,                                    pixel_1:  0.28,                                  pixel_440:  0.30,                                  pixel_861:  0.31,                                  pixel_708:  1.08,                                  pixel_188:  1.09,                                  pixel_768:  1.12,                                  pixel_402:  1.17]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 89657/3910000 [10:49:02<457:04:21,  2.32it/s, acc :      0.773, val_acc :      0.734, loss:      0.756,                              val_loss:     0.6703, w_loss :      0.001, entropy :     10.200,                              regularizer :      0.079                                  pixel_1181:  0.28,                                    pixel_1:  0.29,                                  pixel_440:  0.30,                                  pixel_861:  0.31,                                  pixel_608:  1.08,                                  pixel_768:  1.10,                                  pixel_567:  1.10,                                  pixel_402:  1.11]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  2%|▏         | 93741/3910000 [11:16:47<423:07:18,  2.51it/s, acc :      0.758, val_acc :      0.719, loss:      0.615,                              val_loss:     0.7511, w_loss :      0.001, entropy :     10.200,                              regularizer :      0.082                                  pixel_1181:  0.27,                                    pixel_1:  0.27,                                  pixel_440:  0.30,                                  pixel_861:  0.32,                                  pixel_766:  1.09,                                  pixel_193:  1.09,                                  pixel_768:  1.11,                                  pixel_402:  1.12]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 97998/3910000 [11:45:47<429:23:16,  2.47it/s, acc :      0.812, val_acc :      0.727, loss:      0.576,                              val_loss:     0.7518, w_loss :      0.001, entropy :     10.201,                              regularizer :      0.085                                  pixel_1181:  0.26,                                    pixel_1:  0.27,                                   pixel_20:  0.30,                                  pixel_440:  0.31,                                  pixel_767:  1.08,                                  pixel_766:  1.08,                                  pixel_768:  1.09,                                  pixel_402:  1.09]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 102259/3910000 [12:14:47<423:26:45,  2.50it/s, acc :      0.797, val_acc :      0.719, loss:      0.583,                              val_loss:     0.8685, w_loss :      0.001, entropy :     10.201,                              regularizer :      0.088                                  pixel_1181:  0.25,                                    pixel_1:  0.26,                                   pixel_20:  0.31,                                  pixel_861:  0.31,                                  pixel_629:  1.08,                                   pixel_90:  1.08,                                  pixel_768:  1.08,                                  pixel_589:  1.10]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 106594/3910000 [12:44:18<422:54:21,  2.50it/s, acc :      0.711, val_acc :      0.750, loss:      0.715,                              val_loss:     0.5966, w_loss :      0.001, entropy :     10.202,                              regularizer :      0.091                                  pixel_1181:  0.27,                                    pixel_1:  0.27,                                   pixel_20:  0.30,                                  pixel_440:  0.32,                                  pixel_588:  1.09,                                  pixel_209:  1.09,                                  pixel_402:  1.10,                                  pixel_768:  1.12]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 110914/3910000 [13:13:43<412:10:31,  2.56it/s, acc :      0.781, val_acc :      0.773, loss:      0.644,                              val_loss:     0.6802, w_loss :      0.001, entropy :     10.203,                              regularizer :      0.093                                     pixel_1:  0.27,                                 pixel_1181:  0.28,                                   pixel_20:  0.31,                                  pixel_440:  0.32,                                  pixel_764:  1.09,                                  pixel_208:  1.09,                                  pixel_402:  1.09,                                  pixel_768:  1.13]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 115210/3910000 [13:42:48<429:31:41,  2.45it/s, acc :      0.836, val_acc :      0.742, loss:      0.571,                              val_loss:     0.7505, w_loss :      0.001, entropy :     10.203,                              regularizer :      0.096                                     pixel_1:  0.28,                                 pixel_1181:  0.28,                                  pixel_861:  0.32,                                   pixel_20:  0.32,                                  pixel_766:  1.07,                                  pixel_191:  1.07,                                  pixel_402:  1.08,                                  pixel_768:  1.08]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 119526/3910000 [14:12:12<414:22:16,  2.54it/s, acc :      0.844, val_acc :      0.805, loss:      0.584,                              val_loss:     0.6699, w_loss :      0.001, entropy :     10.203,                              regularizer :      0.099                                     pixel_1:  0.27,                                 pixel_1181:  0.29,                                   pixel_20:  0.30,                                  pixel_861:  0.33,                                  pixel_188:  1.07,                                  pixel_767:  1.07,                                  pixel_768:  1.08,                                  pixel_402:  1.09]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 123814/3910000 [14:41:17<431:44:52,  2.44it/s, acc :      0.805, val_acc :      0.742, loss:      0.561,                              val_loss:     0.7971, w_loss :      0.001, entropy :     10.203,                              regularizer :      0.102                                     pixel_1:  0.26,                                 pixel_1181:  0.28,                                   pixel_20:  0.30,                                  pixel_861:  0.34,                                  pixel_769:  1.09,                                  pixel_631:  1.09,                                  pixel_402:  1.09,                                  pixel_768:  1.11]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 127779/3910000 [15:08:16<422:29:07,  2.49it/s, acc :      0.719, val_acc :      0.703, loss:      0.764,                              val_loss:     0.8058, w_loss :      0.001, entropy :     10.203,                              regularizer :      0.104                                     pixel_1:  0.28,                                   pixel_20:  0.29,                                 pixel_1181:  0.30,                                  pixel_861:  0.33,                                  pixel_349:  1.07,                                  pixel_208:  1.07,                                  pixel_769:  1.10,                                  pixel_768:  1.14]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 132100/3910000 [15:37:48<413:59:56,  2.53it/s, acc :      0.750, val_acc :      0.750, loss:      0.721,                              val_loss:     0.6314, w_loss :      0.001, entropy :     10.204,                              regularizer :      0.107                                     pixel_1:  0.25,                                   pixel_20:  0.28,                                 pixel_1181:  0.30,                                  pixel_861:  0.32,                                  pixel_209:  1.07,                                  pixel_230:  1.08,                                  pixel_768:  1.09,                                  pixel_769:  1.12]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|▎         | 136425/3910000 [16:07:27<411:19:58,  2.55it/s, acc :      0.789, val_acc :      0.789, loss:      0.664,                              val_loss:     0.6673, w_loss :      0.001, entropy :     10.204,                              regularizer :      0.109                                     pixel_1:  0.24,                                   pixel_20:  0.29,                                 pixel_1181:  0.31,                                  pixel_801:  0.32,                                  pixel_128:  1.07,                                  pixel_768:  1.08,                                  pixel_402:  1.08,                                  pixel_769:  1.08]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  4%|▎         | 140399/3910000 [16:34:38<413:17:03,  2.53it/s, acc :      0.766, val_acc :      0.750, loss:      0.630,                              val_loss:     0.7574, w_loss :      0.001, entropy :     10.204,                              regularizer :      0.111                                     pixel_1:  0.24,                                   pixel_20:  0.26,                                  pixel_801:  0.31,                                 pixel_1181:  0.31,                                  pixel_766:  1.08,                                  pixel_690:  1.08,                                  pixel_770:  1.10,                                  pixel_169:  1.10]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "final_size = 20\n",
    "final_in_dim = final_size*final_size*3\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn = SimpleCNN(3, 16, 3)\n",
    "        self.kernel_weights = self.cnn.kernel_weights\n",
    "        self.linear = nn.Linear(4*64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = x.view(batch, 3, final_size, final_size)\n",
    "        x = self.cnn(x)\n",
    "        out = self.linear(x.view(batch, -1))\n",
    "        return out\n",
    "def cifar_noise_fn(x):\n",
    "    return x\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "x_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([final_size, final_size]),\n",
    "#     transforms.Grayscale(),\n",
    "    transforms.RandomCrop(20, padding=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    transforms.Lambda(lambda x:x.float().flatten()),\n",
    "    transforms.Lambda(lambda x:x.cuda()),\n",
    "])\n",
    "y_transforms = transforms.Compose([\n",
    "    transforms.Lambda(lambda y:torch.from_numpy(y).type(torch.long).flatten()),\n",
    "    transforms.Lambda(lambda y:y.cuda()),\n",
    "])\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=None)\n",
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=None)\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(trainset.train_data, np.array(trainset.train_labels).reshape([-1, 1]),\n",
    "                             x_transforms=x_transforms,\n",
    "                             y_transforms=y_transforms,\n",
    "                             )\n",
    "val_dataset = CustomDataset(testset.test_data, np.array(testset.test_labels).reshape([-1, 1]),\n",
    "                            x_transforms=x_transforms,\n",
    "                            y_transforms=y_transforms,\n",
    "                           )\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "G = generator(train_dataset)\n",
    "# DNN_model = SimpleDNN(X.shape[-1], 128, 10, 3, F.relu)\n",
    "# model = SelectNet(X.shape[-1], DNN_model, DNN_model.kernel_weights).cuda()\n",
    "simple_model = Net()\n",
    "model = SelectNet(final_in_dim, simple_model, simple_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "# beta = 0\n",
    "gamma = 0\n",
    "epochs = 10000\n",
    "iters = 1\n",
    "src_loss_criterion = nn.CrossEntropyLoss()\n",
    "feature_names = ['pixel_%d' % (i+1) for i in range(final_in_dim)]\n",
    "train(model, opt, src_loss_criterion, train_dataloader, \n",
    "      val_dataloader, alpha, beta, gamma, \n",
    "      epochs, noise_fn=cifar_noise_fn, \n",
    "      metric_fn=calc_accracy_softmax, log_name='Cifar-10', \n",
    "      feature_names=feature_names,\n",
    "      log_period=50, K=4\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(trainset.train_labels).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3363/2350000 [04:30<50:26:18, 12.92it/s, acc : 0.996, val_acc : 0.977, loss: 0.017, val_loss: 0.0630, w_loss : 0.982, entropy : 6.644, regularizer : 0.011 w37:10.00,w54:10.00,w26:10.00,w64:10.00,w34:10.00,w57:10.00,w58:10.00,w36:10.00,w75:10.00,w66:10.00]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  9%|▉         | 220736/2350000 [4:54:00<47:09:08, 12.54it/s, acc : 0.996, val_acc : 0.988, loss: 0.046, val_loss: 0.0790, w_loss : 0.000, entropy : 5.803, regularizer : 0.020 w91:0.00,w99:0.00,w10:0.00,w90:0.00,w1:0.00,w54:22.19,w55:22.34,w77:22.56,w38:23.80,w86:24.67] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 13%|█▎        | 301233/2350000 [6:41:07<45:51:46, 12.41it/s, acc : 1.000, val_acc : 0.988, loss: 0.000, val_loss: 0.0890, w_loss : 0.000, entropy : 5.812, regularizer : 0.020 w91:0.00,w99:0.00,w10:0.00,w1:0.00,w90:0.00,w15:22.10,w77:22.15,w58:22.48,w38:23.87,w86:23.98]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 16%|█▋        | 382465/2350000 [8:29:19<43:13:12, 12.65it/s, acc : 1.000, val_acc : 0.996, loss: 0.000, val_loss: 0.0086, w_loss : 0.000, entropy : 5.825, regularizer : 0.018 w91:0.00,w99:0.00,w10:0.00,w1:0.00,w81:0.00,w68:22.01,w77:22.23,w24:22.39,w86:23.00,w38:23.56]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 23%|██▎       | 544789/2350000 [12:05:33<40:09:59, 12.48it/s, acc : 1.000, val_acc : 0.988, loss: 0.000, val_loss: 0.0903, w_loss : 0.000, entropy : 5.851, regularizer : 0.016 w91:0.00,w99:0.00,w1:0.00,w10:0.00,w80:0.00,w16:22.30,w77:22.41,w78:22.50,w68:23.26,w38:23.65] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 24%|██▍       | 563799/2350000 [12:30:50<39:43:51, 12.49it/s, acc : 1.000, val_acc : 0.977, loss: 0.000, val_loss: 0.1622, w_loss : 0.000, entropy : 5.854, regularizer : 0.017 w91:0.00,w1:0.00,w99:0.00,w10:0.00,w80:0.00,w86:22.21,w16:22.62,w77:22.90,w68:23.19,w38:24.11]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aad0e3c580f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mtrain_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mreg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_reg_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0msrc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_loss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/miniconda2/envs/python-conda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/git/SelectNet/src/SelectNet.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_lay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownstream_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/miniconda2/envs/python-conda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/k123/git/SelectNet/src/SelectNet.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# ratio = self.calc_ratio()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from utils.SimpleCNN import SimpleCNN\n",
    "import sklearn.metrics\n",
    "def calc_accracy(y, out):\n",
    "    label = y.flatten().cpu().detach().numpy().astype(np.int)\n",
    "    pred = torch.argmax(out, dim=-1).cpu().detach().numpy().astype(np.int)\n",
    "    return sklearn.metrics.accuracy_score(label, pred)\n",
    "\n",
    "def add_noise_on_pixel(x, pixel_mask, distribution):\n",
    "    noise = distribution.sample(x.size())\n",
    "    batch = x.shape[0]\n",
    "    ret = x.clone()\n",
    "    ret += pixel_mask.repeat(batch, 1).type(torch.FloatTensor)*noise\n",
    "    return ret\n",
    "            \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn = SimpleCNN(1, 16, 2)\n",
    "        self.kernel_weights = self.cnn.kernel_weights\n",
    "        self.linear = nn.Linear(4*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch = x.shape[0]\n",
    "        x = x.view(batch, 1, 10, 10)\n",
    "        x = self.cnn(x)\n",
    "        out = self.linear(x.view(batch, -1))\n",
    "        return out\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize([10,10]),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                           transforms.Lambda(lambda x:x.flatten()),\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.Resize([10,10]),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                           transforms.Lambda(lambda x:x.flatten()),\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "X = np.zeros([50000, 100])\n",
    "\n",
    "# DNN_model = SimpleDNN(X.shape[-1], 128, 10, 3, F.relu)\n",
    "# model = SelectNet(X.shape[-1], DNN_model, DNN_model.kernel_weights).cuda()\n",
    "simple_model = Net()\n",
    "model = SelectNet(X.shape[-1], simple_model, simple_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "# beta = 0\n",
    "gamma = 0\n",
    "epochs = 10000\n",
    "iters = 1\n",
    "noise_distribution = torch.distributions.Uniform(0.5, 1)\n",
    "noise_pixel_mask = torch.tensor([[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 1, 1]], dtype=torch.uint8)\n",
    "writer = SummaryWriter('./logs/noised_cnn_mnist-a%f,b%f,g%f' % (alpha, beta, gamma))\n",
    "src_loss_criterion = nn.CrossEntropyLoss()\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "#         mask_idx = np.random.randint(0, X.shape[-1])\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_noise_on_pixel(x, noise_pixel_mask, noise_distribution)\n",
    "            x, y = x.cuda(), y.type(torch.long).flatten().cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_noise_on_pixel(val_x, noise_pixel_mask, noise_distribution)\n",
    "            val_x, val_y = val_x.cuda(), val_y.type(torch.long).flatten().cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "# \n",
    "            model.train()\n",
    "            train_out = model(x)\n",
    "            reg_loss, w_loss, entropy_loss = model.calc_reg_loss(F.mse_loss)\n",
    "            src_loss = src_loss_criterion(train_out, y)\n",
    "            loss = alpha*reg_loss + beta*w_loss + gamma*entropy_loss + src_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "            \n",
    "#                 val_out = torch.softmax(model(val_x), dim=-1)\n",
    "                val_out = model(val_x)\n",
    "                val_src_loss = src_loss_criterion(val_out, val_y)\n",
    "                \n",
    "                \n",
    "#                 noised\n",
    "                noised_train_out = model(noised_x)\n",
    "                noised_val_out = model(val_noised_x)\n",
    "                noised_src = src_loss_criterion(noised_train_out, y)\n",
    "                val_noised_src = src_loss_criterion(noised_val_out, val_y)\n",
    "#                 acc\n",
    "                train_acc = calc_accracy(y, train_out)\n",
    "                val_acc = calc_accracy(val_y, val_out)\n",
    "                noised_train_acc = calc_accracy(y, noised_train_out)\n",
    "                noised_val_acc = calc_accracy(val_y, noised_val_out)\n",
    "                \n",
    "            \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            w_prine = torch.sigmoid(model.w).cpu().detach().numpy().flatten()\n",
    "            w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "            sorted_ratio = sorted([(i+1,x) for i,x in enumerate(w_ratio)], key=lambda x:x[1])\n",
    "            buf = sorted_ratio[:5] + sorted_ratio[-5:]\n",
    "            buf = ','.join(['w%d:%.2f' % (i,x*1000) for i,x in buf])\n",
    "            pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, loss: %.3f, val_loss: %.4f, w_loss : %.3f, entropy : %.3f, regularizer : %.3f %s' %\n",
    "                                 (\n",
    "                                     train_acc.item(), val_acc.item(),\n",
    "                                     src_loss.item(), val_src_loss.item(), \n",
    "                                     w_loss.item(), entropy_loss.item(),\n",
    "                                     reg_loss.item(), buf))\n",
    "            if epoch >= 0 and iters % 10 == 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/cross-entropy', {'train': src_loss.item(),\n",
    "                                                     'validation': val_src_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_loss', {'train': noised_src.item(),\n",
    "                                                     'validation': val_noised_src.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/accuracy', {'train': train_acc.item(),\n",
    "                                                     'validation': val_acc.item(),\n",
    "                                                     'noised_train': noised_train_acc.item(),\n",
    "                                                     'noised_validation': noised_val_acc.item(),\n",
    "                                                    },\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_loss', {'train': w_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/entropy', {'train': entropy_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_prine', {'w%d' % (i+1) : v  for i, v in enumerate(w_prine)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_ratio', {'w%d' % (i+1) : v  for i, v in enumerate(w_ratio)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_z', {'nothing':0 },\n",
    "                                                     iters)\n",
    "            \n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# torch.save(model, './models/mnist_10x10.hdf5')\n",
    "# print val_x.shape\n",
    "# print sorted_ratio\n",
    "# print ['%.5f' % w for w in sorted_ratio]\n",
    "s = 0\n",
    "for i, (_, w) in enumerate(reversed(sorted_ratio)):\n",
    "    s += w\n",
    "#     print '%3d, %.7f, %.7f' % (i, s, w)\n",
    "# print ['%d, %.7f' % w[1] for w in sorted_ratio]\n",
    "# print w_ratio\n",
    "# plt.plot(np.ones([100,]), w_ratio, 'r.')\n",
    "ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "plt.hist(ratio, bins=np.linspace(0, 0.1, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 1, 1]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 1, 1]], dtype=torch.uint8)\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 1, 1, 1]], dtype=torch.uint8)\n",
      "torch.Size([1, 100])\n",
      "0.9859765625\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.001\n",
    "def get_torch_mask(model, threshold):\n",
    "    ratio = model.select_lay.calc_ratio()\n",
    "    pixel_mask =  ratio*model.select_lay.in_dim < threshold\n",
    "    return pixel_mask.cpu().detach()\n",
    "    \n",
    "def add_noise_on_pixel(x, pixel_mask):\n",
    "    uniform = torch.distributions.Uniform(0.5, 1)\n",
    "    noise = uniform.sample(x.size())\n",
    "    batch = x.shape[0]\n",
    "    ret = x.clone()\n",
    "    ret += pixel_mask.repeat(batch, 1).type(torch.FloatTensor)*noise\n",
    "    return ret\n",
    "\n",
    "def test_accuracy_with_noise(model, val_G, mask, iters=100):\n",
    "    mean_acc = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for it in xrange(iters):\n",
    "            x, y = next(val_G)\n",
    "            x, y = x, y.type(torch.long).flatten().cuda()\n",
    "            x = add_noise_on_pixel(x, pixel_mask).cuda()\n",
    "            out = model(x)\n",
    "            acc = calc_accracy(y, out)\n",
    "            mean_acc.append(acc)\n",
    "    return np.mean(mean_acc)\n",
    "            \n",
    "    \n",
    "pixel_mask = get_torch_mask(model, threshold)\n",
    "print pixel_mask\n",
    "print pixel_mask.shape\n",
    "pixel_idx = [i for i in range(pixel_mask.shape[-1]) if pixel_mask[0, i] == 1]\n",
    "# print np.[pixel_idx]\n",
    "print test_accuracy_with_noise(model, val_G, pixel_mask, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 100]) torch.Size([256])\n",
      "(10, 10, 3) 0.0 1.0\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fed3ec03290>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_noise(img, pixel_mask):\n",
    "    assert len(img.shape) == 3 and img.shape[-1] == 3\n",
    "    mask = pixel_mask.reshape(10, 10)\n",
    "    mask = np.swapaxes(mask, 0, 1)\n",
    "    \n",
    "    ret = img.copy()\n",
    "    np.putmask(ret[:,:,0], mask, 1)\n",
    "    np.putmask(ret[:,:,1], mask, 0)\n",
    "    np.putmask(ret[:,:,2], mask, 0)\n",
    "    return ret\n",
    "\n",
    "def denormalize(x):\n",
    "    return x*0.3081 + 0.1307\n",
    "    \n",
    "for x, y in val_dataloader:\n",
    "    print x.shape, y.shape\n",
    "    break\n",
    "x = x[0:1,:]\n",
    "x = denormalize(x)\n",
    "m = x.numpy()\n",
    "m = np.repeat(m, 3, axis=0)\n",
    "# m = add_noise_on_pixel(m, pixel_idx)\n",
    "m = m.reshape([3, 10, 10])\n",
    "m = np.swapaxes(m, 0, 2)\n",
    "m = np.swapaxes(m, 0, 1)\n",
    "m = visualize_noise(m, pixel_mask)\n",
    "\n",
    "print m.shape, np.min(m), np.max(m)\n",
    "print y[0]\n",
    "plt.imshow(m, cmap=None, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 100]) torch.Size([256])\n",
      "(10, 10, 3) 0.0 1.0\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe03aed5c90>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAACmpJREFUeJzt3U/IVXUex/HPZ7R/1lBBEaQyCkmDFEP1EJUQlC1qjNzMoqBg2riZyiKIGoIWbSMqiECsNkUtrEVEVAPVYoikR4tKLQhtTCu0aCqK8Sn6zOK5Axb53KPP+c157pf3CwLv7fTry+N9e84999yjkwhATb8begAA7RA4UBiBA4UROFAYgQOFEThQGIEDhRE4UBiBA4UtbrHoGXZWtFgY2tZo3YsarYs2PpH0ZeJx2zUJfIWk6RYLQ2N/R48Rv1+TZarjdhyiA4UROFAYgQOFEThQGIEDhRE4UFinwG1fbfsj2x/bvrv1UAD6MTZw24skPSrpGkmrJd1ge3XrwQDMX5c9+MWSPk6yO8mMpGclrW87FoA+dAl8qaRPD3u8b/TcL9jeYHva9vTBvqYDMC+9nWRLsinJVJKpM/taFMC8dAl8v6Tlhz1eNnoOwALXJfC3Ja2yvdL28ZKul/RC27EA9GHst8mS/GT7FkmvSFok6YkkO5pPBmDeOn1dNMlLkl5qPAuAnnElG1AYgQOFEThQGIEDhRE4UFiTmy5OmlY3Mpwkxy1u81JYtWpVk3V3797d+5qHDh3qfU1JSpNVu2EPDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4U1uRWmtvU5k6lQ96dsrpzzjmnybr3339/k3U3btzY+5r799f7W7HZgwOFEThQGIEDhRE4UBiBA4UROFDY2MBtL7f9uu2dtnfY7v/zCQBNdPkc/CdJdybZbvv3krbZ/keSnY1nAzBPY/fgST5Psn306+8k7ZK0tPVgAObvqN6D214h6QJJW1sMA6BfnS9VtX2KpOck3Z7k29/49xskbehxNgDz1Clw28dpNu6nkzz/W9sk2SRp02h7LhsHFoAuZ9Et6XFJu5I82H4kAH3p8h58jaSbJF1p+93RP39uPBeAHow9RE/yT7X59ieAxriSDSiMwIHCCBwojMCBwggcKKzJTRcvkjTdYF1O5UuzlyX0b/369U3W/eqrr5qs+/XXXzdZt4UhX7fswYHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwggcKIzAgcIIHCiMwIHCCBwojMCBwprcVXWbuANqK8uXL2+y7hVXXNFk3XvvvbfJuj/88EOTdathDw4URuBAYQQOFEbgQGEEDhRG4EBhBA4U1jlw24tsv2P7xZYDAejP0ezBN0ra1WoQAP3rFLjtZZLWSdrcdhwAfeq6B39I0l2Sfj7SBrY32J62Pd3LZADmbWzgtq+VdCDJtrm2S7IpyVSSqd6mAzAvXfbgayRdZ/sTSc9KutL2U02nAtCLsYEnuSfJsiQrJF0v6bUkNzafDMC88Tk4UNhRfR88yRuS3mgyCYDesQcHCiNwoDACBwojcKAwAgcKa3JXVbSzdu3aJuvu2bOnybrvvfdek3XRDXtwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAw7qrayFlnndVk3XXr1jVZ95FHHmmy7szMTJN10Q17cKAwAgcKI3CgMAIHCiNwoDACBwrrFLjt02xvsf2h7V22L209GID56/o5+MOSXk7yF9vHS1rScCYAPRkbuO1TJV0u6a+SlGRGElcvABOgyyH6SkkHJT1p+x3bm22f3HguAD3oEvhiSRdKeizJBZK+l3T3rzeyvcH2tO3pnmcEcIy6BL5P0r4kW0ePt2g2+F9IsinJVJKpPgcEcOzGBp7kC0mf2j539NRaSTubTgWgF13Pot8q6enRGfTdkm5uNxKAvnQKPMm7kjj0BiYMV7IBhRE4UBiBA4UROFAYgQOFEThQWJO7ql4kqcX1qm6wZivnn39+k3UPHDjQZN233nqryboYFntwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwprctNFSCeccEKTdd98880m687MzDRZd5Jk6AGOQte/KJA9OFAYgQOFEThQGIEDhRE4UBiBA4UROFBYp8Bt32F7h+0PbD9j+8TWgwGYv7GB214q6TZJU0nOk7RI0vWtBwMwf10P0RdLOsn2YklLJH3WbiQAfRkbeJL9kh6QtFfS55K+SfLqr7ezvcH2tO3pg/3PCeAYdDlEP13SekkrJZ0t6WTbN/56uySbkkwlmTqz/zkBHIMuh+hXSdqT5GCSHyU9L+mytmMB6EOXwPdKusT2EtuWtFbSrrZjAehDl/fgWyVtkbRd0vuj/2ZT47kA9KDT98GT3CfpvsazAOgZV7IBhRE4UBiBA4UROFAYgQOFOen/XpJTdqZ7X7UdN1iz1V1V/3PoUJN1W/wMpHZ3Km0x76TdVXU6GftjYA8OFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhRG4EBhBA4URuBAYQQOFEbgQGEEDhTW5K6qtg9K+leHTc+Q9GXvA7QzSfNO0qzSZM27EGb9Q5Izx23UJPCubE8nmRpsgKM0SfNO0qzSZM07SbNyiA4URuBAYUMHvmng///RmqR5J2lWabLmnZhZB30PDqCtoffgABoaLHDbV9v+yPbHtu8eao5xbC+3/brtnbZ32N449Exd2F5k+x3bLw49y1xsn2Z7i+0Pbe+yfenQM83F9h2j18EHtp+xfeLQM81lkMBtL5L0qKRrJK2WdIPt1UPM0sFPku5MslrSJZL+toBnPdxGSbuGHqKDhyW9nOSPkv6kBTyz7aWSbpM0leQ8SYskXT/sVHMbag9+saSPk+xOMiPpWUnrB5plTkk+T7J99OvvNPsCXDrsVHOzvUzSOkmbh55lLrZPlXS5pMclKclMkn8PO9VYiyWdZHuxpCWSPht4njkNFfhSSZ8e9nifFng0kmR7haQLJG0ddpKxHpJ0l6Sfhx5kjJWSDkp6cvR2YrPtk4ce6kiS7Jf0gKS9kj6X9E2SV4edam6cZOvI9imSnpN0e5Jvh57nSGxfK+lAkm1Dz9LBYkkXSnosyQWSvpe0kM/HnK7ZI82Vks6WdLLtG4edam5DBb5f0vLDHi8bPbcg2T5Os3E/neT5oecZY42k62x/otm3PlfafmrYkY5on6R9Sf53RLRFs8EvVFdJ2pPkYJIfJT0v6bKBZ5rTUIG/LWmV7ZW2j9fsiYoXBpplTrat2feIu5I8OPQ84yS5J8myJCs0+3N9LcmC3Msk+ULSp7bPHT21VtLOAUcaZ6+kS2wvGb0u1moBnxSUZg+R/u+S/GT7FkmvaPZM5BNJdgwxSwdrJN0k6X3b746e+3uSlwacqZJbJT09+oN+t6SbB57niJJstb1F0nbNfrryjhb4VW1cyQYUxkk2oDACBwojcKAwAgcKI3CgMAIHCiNwoDACBwr7L47uMM8CzhYXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "def visualize_noise(img, pixel_mask):\n",
    "    assert len(img.shape) == 3 and img.shape[-1] == 3\n",
    "    mask = pixel_mask.reshape(10, 10)\n",
    "    mask = np.swapaxes(mask, 0, 1)\n",
    "    \n",
    "    ret = img.copy()\n",
    "    np.putmask(ret[:,:,0], mask, 1)\n",
    "    np.putmask(ret[:,:,1], mask, 0)\n",
    "    np.putmask(ret[:,:,2], mask, 0)\n",
    "    return ret\n",
    "\n",
    "def denormalize(x):\n",
    "    return x*0.3081 + 0.1307\n",
    "    \n",
    "for x, y in val_dataloader:\n",
    "    print x.shape, y.shape\n",
    "    break\n",
    "x = x[0:1,:]\n",
    "x = denormalize(x)\n",
    "m = x.numpy()\n",
    "m = np.repeat(m, 3, axis=0)\n",
    "# m = add_noise_on_pixel(m, pixel_idx)\n",
    "m = m.reshape([3, 10, 10])\n",
    "m = np.swapaxes(m, 0, 2)\n",
    "m = np.swapaxes(m, 0, 1)\n",
    "m = visualize_noise(m, pixel_mask)\n",
    "\n",
    "print m.shape, np.min(m), np.max(m)\n",
    "print y[0]\n",
    "plt.imshow(m, cmap=None, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist model visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# in Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import sklearn.metrics\n",
    "\n",
    "def calc_accracy(y, out):\n",
    "    label = y.flatten().cpu().detach().numpy().astype(np.int)\n",
    "    pred = torch.argmax(out, dim=-1).cpu().detach().numpy().astype(np.int)\n",
    "    return sklearn.metrics.accuracy_score(label, pred)\n",
    "            \n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float32)\n",
    "Y = iris.target.reshape([-1, 1]).astype(np.float32)\n",
    "# print iris.data.shape\n",
    "N = len(Y)\n",
    "batch_size = 8\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "\n",
    "DNN_model = SimpleDNN(X.shape[-1], 16, 3, 2, F.relu)\n",
    "model = SelectNet(X.shape[-1], DNN_model, DNN_model.kernel_weights).cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "alpha = 0.1\n",
    "beta = 100\n",
    "gamma = 0\n",
    "epochs = 10000\n",
    "iters = 1\n",
    "noise_std = 25\n",
    "noise_col_idx = []\n",
    "writer = SummaryWriter('./AE_logs/Iris-a%f,b%f,g%f' % (alpha, beta, gamma))\n",
    "src_loss_criterion = nn.CrossEntropyLoss()\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "#         mask_idx = np.random.randint(0, X.shape[-1])\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_masked_noise(x, noise_std, noise_col_idx)\n",
    "            x, y = x.cuda(), y.type(torch.long).flatten().cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_masked_noise(val_x, noise_std, noise_col_idx)\n",
    "            val_x, val_y = val_x.cuda(), val_y.type(torch.long).flatten().cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "#             mask\n",
    "#             x = mask_column(x, mask_idx)\n",
    "#             val_x = mask_column(val_x, mask_idx)\n",
    "# \n",
    "            model.train()\n",
    "#             train_out = torch.softmax(model(x), dim=-1)\n",
    "            train_out = model(x)\n",
    "            reg_loss, w_loss, entropy_loss = model.calc_reg_loss(F.mse_loss)\n",
    "            src_loss = src_loss_criterion(train_out, y)\n",
    "            loss = alpha*reg_loss + beta*w_loss + gamma*entropy_loss + src_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "            \n",
    "#                 val_out = torch.softmax(model(val_x), dim=-1)\n",
    "                val_out = model(val_x)\n",
    "                val_src_loss = src_loss_criterion(val_out, val_y)\n",
    "                \n",
    "                \n",
    "#                 noised\n",
    "                noised_train_out = model(noised_x)\n",
    "                noised_val_out = model(val_noised_x)\n",
    "                noised_src = src_loss_criterion(noised_train_out, y)\n",
    "                val_noised_src = src_loss_criterion(noised_val_out, val_y)\n",
    "#                 acc\n",
    "                train_acc = calc_accracy(y, train_out)\n",
    "                val_acc = calc_accracy(val_y, val_out)\n",
    "                noised_train_acc = calc_accracy(y, noised_train_out)\n",
    "                noised_val_acc = calc_accracy(val_y, noised_val_out)\n",
    "                \n",
    "            \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            w_prine = torch.sigmoid(model.w).cpu().detach().numpy().flatten()\n",
    "            w_ratio = model.select_lay.calc_ratio().cpu().detach().numpy().flatten()\n",
    "#             buf = ','.join(['%d:%.2f' % (i+1,x) for i,x in enumerate(buf)])\n",
    "            buf = ','.join(['%2.3f, ' % (x) for i,x in enumerate(w_ratio)])\n",
    "            pbar.set_postfix_str('acc : %.3f, val_acc : %.3f, loss: %.3f, val_loss: %.4f, w_loss : %.3f, entropy : %.3f, regularizer : %.3f                     %s' %\n",
    "                                 (\n",
    "                                     train_acc.item(), val_acc.item(),\n",
    "                                     src_loss.item(), val_src_loss.item(), \n",
    "                                     w_loss.item(), entropy_loss.item(),\n",
    "                                     reg_loss.item(), buf))\n",
    "            if epoch > 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/cross-entropy', {'train': src_loss.item(),\n",
    "                                                     'validation': val_src_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_loss', {'train': noised_src.item(),\n",
    "                                                     'validation': val_noised_src.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/accuracy', {'train': train_acc.item(),\n",
    "                                                     'validation': val_acc.item(),\n",
    "                                                     'noised_train': noised_train_acc.item(),\n",
    "                                                     'noised_validation': noised_val_acc.item(),\n",
    "                                                    },\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_loss', {'train': w_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/entropy', {'train': entropy_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_prine', {'w%d' % (i+1) : v  for i, v in enumerate(w_prine)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w_ratio', {'w%d' % (i+1) : v  for i, v in enumerate(w_ratio)},\n",
    "                                                     iters)\n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/930 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1], [2], [3], [4], [0, 1], [0, 2], [0, 3], [0, 4], [1, 2], [1, 3], [1, 4], [2, 3], [2, 4], [3, 4], [0, 1, 2], [0, 1, 3], [0, 1, 4], [0, 2, 3], [0, 2, 4], [0, 3, 4], [1, 2, 3], [1, 2, 4], [1, 3, 4], [2, 3, 4], [0, 1, 2, 3], [0, 1, 2, 4], [0, 1, 3, 4], [0, 2, 3, 4], [1, 2, 3, 4], [0, 1, 2, 3, 4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 930/930 [28:41<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------+--------------------------------------------------------------------------------------------------------------+\n",
      "| Rank |  Accuracy over 30   |                                                using features                                                |\n",
      "+------+---------------------+--------------------------------------------------------------------------------------------------------------+\n",
      "|  1   |  0.9603174605066814 |        [0, 1, 2, 3, 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']        |\n",
      "|  2   |  0.9561904764743079 |             [1, 2, 3, 4, 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'sw * pw']             |\n",
      "|  3   |  0.9523809526080176 |                        [1, 2, 4, 'sepal width (cm)', 'petal length (cm)', 'sw * pw']                         |\n",
      "|  4   |  0.9507936510207161 | [0, 1, 2, 3, 4, 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'sw * pw'] |\n",
      "|  5   |  0.9507936509639497 |                                    [1, 4, 'sepal width (cm)', 'sw * pw']                                     |\n",
      "|  6   |  0.9457142859981172 |                   [0, 2, 3, 'sepal length (cm)', 'petal length (cm)', 'petal width (cm)']                    |\n",
      "|  7   |  0.9453968256617349 |                                           [3, 'petal width (cm)']                                            |\n",
      "|  8   |  0.9415873018522111 |            [0, 1, 2, 4, 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'sw * pw']             |\n",
      "|  9   |  0.9409523812172904 |                         [1, 3, 4, 'sepal width (cm)', 'petal width (cm)', 'sw * pw']                         |\n",
      "|  10  |  0.9358730162893022 |                                [1, 3, 'sepal width (cm)', 'petal width (cm)']                                |\n",
      "|  11  |  0.9295238097508748 |                    [0, 1, 3, 'sepal length (cm)', 'sepal width (cm)', 'petal width (cm)']                    |\n",
      "|  12  |  0.9269841274193354 |                                    [3, 4, 'petal width (cm)', 'sw * pw']                                     |\n",
      "|  13  |  0.9260317462777334 |                   [0, 1, 2, 'sepal length (cm)', 'sepal width (cm)', 'petal length (cm)']                    |\n",
      "|  14  |  0.9234920637380509 |                        [0, 1, 4, 'sepal length (cm)', 'sepal width (cm)', 'sw * pw']                         |\n",
      "|  15  |  0.9219047621223662 |                    [1, 2, 3, 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']                    |\n",
      "|  16  |  0.9212698417428941 |                               [0, 3, 'sepal length (cm)', 'petal width (cm)']                                |\n",
      "|  17  |  0.9212698416672056 |                               [0, 2, 'sepal length (cm)', 'petal length (cm)']                               |\n",
      "|  18  |  0.9161904763986194 |             [0, 1, 3, 4, 'sepal length (cm)', 'sepal width (cm)', 'petal width (cm)', 'sw * pw']             |\n",
      "|  19  |  0.9158730163271466 |                                           [2, 'petal length (cm)']                                           |\n",
      "|  20  |  0.914285714579007  |                               [2, 3, 'petal length (cm)', 'petal width (cm)']                                |\n",
      "|  21  |  0.9111111116220081 |            [0, 2, 3, 4, 'sepal length (cm)', 'petal length (cm)', 'petal width (cm)', 'sw * pw']             |\n",
      "|  22  |  0.8996825400042157 |                        [0, 2, 4, 'sepal length (cm)', 'petal length (cm)', 'sw * pw']                        |\n",
      "|  23  |  0.8879365086744703 |                               [1, 2, 'sepal width (cm)', 'petal length (cm)']                                |\n",
      "|  24  |  0.8815873021928092 |                        [0, 3, 4, 'sepal length (cm)', 'petal width (cm)', 'sw * pw']                         |\n",
      "|  25  |  0.8793650800462754 |                                    [0, 4, 'sepal length (cm)', 'sw * pw']                                    |\n",
      "|  26  |   0.86444444521079  |                                                [4, 'sw * pw']                                                |\n",
      "|  27  |  0.8476190485840752 |                                    [2, 4, 'petal length (cm)', 'sw * pw']                                    |\n",
      "|  28  |  0.8434920641921816 |                        [2, 3, 4, 'petal length (cm)', 'petal width (cm)', 'sw * pw']                         |\n",
      "|  29  |  0.6422222236224585 |                               [0, 1, 'sepal length (cm)', 'sepal width (cm)']                                |\n",
      "|  30  | 0.31555555601441665 |                                           [1, 'sepal width (cm)']                                            |\n",
      "|  31  | 0.30222222282536454 |                                           [0, 'sepal length (cm)']                                           |\n",
      "+------+---------------------+--------------------------------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from itertools import combinations\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float32)\n",
    "buf = (X[:,1] * X[:,3]).reshape([-1, 1])\n",
    "X = np.concatenate([X, buf], axis=1)\n",
    "Y = iris.target.reshape([-1, 1]).astype(np.float32)\n",
    "buf = X[:]\n",
    "def init_sess():\n",
    "    K.clear_session()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "    config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "                                        # (nothing gets printed in Jupyter, only if you run it standalone)\n",
    "    sess = tf.Session(config=config)\n",
    "    set_session(sess)  # set this TensorFlow session as the default session for Keras\n",
    "\n",
    "def train_model(X, Y, iters, pbar):\n",
    "    input_dim = X.shape[-1]\n",
    "    arr = []\n",
    "    cb = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "        \n",
    "    for i in range(iters):\n",
    "        init_sess()\n",
    "        X_train,X_test,y_train,y_test=train_test_split(X,Y,train_size=0.3)\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64,input_shape=(input_dim,), activation='relu'))\n",
    "#         model.add(Dropout(0.2))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "#         model.add(Dropout(0.2))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "        model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "        model.fit(X_train,y_train, epochs=500,batch_size=5,\n",
    "                  verbose=0, validation_data=[X_test, y_test],\n",
    "                  callbacks=[cb]\n",
    "                 )\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        arr.append(accuracy)\n",
    "        pbar.update(1)\n",
    "    return np.mean(arr)\n",
    "idx_set = []\n",
    "feature_names = iris.feature_names + ['sw * pw']\n",
    "for i in range(len(feature_names)):\n",
    "    for idxs in combinations(np.arange(len(feature_names)), i+1):\n",
    "        idx_set.append(list(idxs))\n",
    "print idx_set\n",
    "# print X.shape\n",
    "iters = 30\n",
    "acc_arr = []\n",
    "with tqdm(total=len(idx_set)*iters) as pbar:\n",
    "    for idx in idx_set:\n",
    "        acc = train_model(X[:, idx], Y, iters, pbar)\n",
    "        acc_arr.append([idx, acc])\n",
    "acc_arr = sorted(acc_arr, key=lambda x: x[1], reverse=True)\n",
    "T = PrettyTable()\n",
    "T.field_names = [\"Rank\", \"Accuracy over %d \" % iters, \"using features\"]\n",
    "for i, (idx, acc) in enumerate(acc_arr):\n",
    "    row = [i+1, acc, idx + [feature_names[x] for x in idx]]\n",
    "    T.add_row(row)\n",
    "print T    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+------------------------------------------------------------------------------------------+\n",
      "| Rank | Accuracy over 30  |                                      using features                                      |\n",
      "+------+-------------------+------------------------------------------------------------------------------------------+\n",
      "|  1   |       0.960       |        [0, 1, 2, 3, 'sepal length', 'sepal width', 'petal length', 'petal width']        |\n",
      "|  2   |       0.956       |          [1, 2, 3, 4, 'sepal width', 'petal length', 'petal width', 'sw * pw']           |\n",
      "|  3   |       0.952       |                   [1, 2, 4, 'sepal width', 'petal length', 'sw * pw']                    |\n",
      "|  4   |       0.951       | [0, 1, 2, 3, 4, 'sepal length', 'sepal width', 'petal length', 'petal width', 'sw * pw'] |\n",
      "|  5   |       0.951       |                             [1, 4, 'sepal width', 'sw * pw']                             |\n",
      "|  6   |       0.946       |                 [0, 2, 3, 'sepal length', 'petal length', 'petal width']                 |\n",
      "|  7   |       0.945       |                                    [3, 'petal width']                                    |\n",
      "|  8   |       0.942       |          [0, 1, 2, 4, 'sepal length', 'sepal width', 'petal length', 'sw * pw']          |\n",
      "|  9   |       0.941       |                    [1, 3, 4, 'sepal width', 'petal width', 'sw * pw']                    |\n",
      "|  10  |       0.936       |                           [1, 3, 'sepal width', 'petal width']                           |\n",
      "|  11  |       0.930       |                 [0, 1, 3, 'sepal length', 'sepal width', 'petal width']                  |\n",
      "|  12  |       0.927       |                             [3, 4, 'petal width', 'sw * pw']                             |\n",
      "|  13  |       0.926       |                 [0, 1, 2, 'sepal length', 'sepal width', 'petal length']                 |\n",
      "|  14  |       0.923       |                   [0, 1, 4, 'sepal length', 'sepal width', 'sw * pw']                    |\n",
      "|  15  |       0.922       |                 [1, 2, 3, 'sepal width', 'petal length', 'petal width']                  |\n",
      "|  16  |       0.921       |                          [0, 3, 'sepal length', 'petal width']                           |\n",
      "|  17  |       0.921       |                          [0, 2, 'sepal length', 'petal length']                          |\n",
      "|  18  |       0.916       |          [0, 1, 3, 4, 'sepal length', 'sepal width', 'petal width', 'sw * pw']           |\n",
      "|  19  |       0.916       |                                   [2, 'petal length']                                    |\n",
      "|  20  |       0.914       |                          [2, 3, 'petal length', 'petal width']                           |\n",
      "|  21  |       0.911       |          [0, 2, 3, 4, 'sepal length', 'petal length', 'petal width', 'sw * pw']          |\n",
      "|  22  |       0.900       |                   [0, 2, 4, 'sepal length', 'petal length', 'sw * pw']                   |\n",
      "|  23  |       0.888       |                          [1, 2, 'sepal width', 'petal length']                           |\n",
      "|  24  |       0.882       |                   [0, 3, 4, 'sepal length', 'petal width', 'sw * pw']                    |\n",
      "|  25  |       0.879       |                            [0, 4, 'sepal length', 'sw * pw']                             |\n",
      "|  26  |       0.864       |                                      [4, 'sw * pw']                                      |\n",
      "|  27  |       0.848       |                            [2, 4, 'petal length', 'sw * pw']                             |\n",
      "|  28  |       0.843       |                   [2, 3, 4, 'petal length', 'petal width', 'sw * pw']                    |\n",
      "|  29  |       0.642       |                          [0, 1, 'sepal length', 'sepal width']                           |\n",
      "|  30  |       0.316       |                                    [1, 'sepal width']                                    |\n",
      "|  31  |       0.302       |                                   [0, 'sepal length']                                    |\n",
      "+------+-------------------+------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "T = PrettyTable()\n",
    "T.field_names = [\"Rank\", \"Accuracy over %d \" % iters, \"using features\"]\n",
    "for i, (idx, acc) in enumerate(acc_arr):\n",
    "    acc = '%.3f' % acc\n",
    "    row = [i+1, acc, idx + [feature_names[x].replace(' (cm)','') for x in idx]]\n",
    "    T.add_row(row)\n",
    "print T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "(0, 1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "print '%s' % ([iris.feature_names[x] for x in idxs ])\n",
    "print idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = nn.Conv2d(1, 16, 3, padding=1)\n",
    "print cnn.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_noise(model, val_G, label, iters=100):\n",
    "    x_ax = np.linspace(1, 30, 100)\n",
    "    src_arr = []\n",
    "    noised_arr = []\n",
    "    for std in x_ax:\n",
    "        src_mse_loss = 0\n",
    "        noised_mse_loss = 0\n",
    "        normal = torch.distributions.Normal(0, std)\n",
    "        for i in range(iters):\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "            N = val_x.shape[0]\n",
    "            noise = torch.cat([torch.zeros_like(val_x)[:,:-2], normal.sample([N,2]).cuda()], dim=1)\n",
    "            out1,_ = model(val_x)\n",
    "            out2,_ = model(val_x + noise)\n",
    "            src_mse_loss += F.mse_loss(out1, val_y)\n",
    "            noised_mse_loss += F.mse_loss(out2, val_y)\n",
    "        src_mse_loss /= iters\n",
    "        noised_mse_loss /= iters\n",
    "        src_arr.append(src_mse_loss.item())\n",
    "        noised_arr.append(noised_mse_loss.item())\n",
    "    \n",
    "#     plt.plot(x_ax, src_arr, label=label + ' mse')\n",
    "    plt.plot(x_ax, noised_arr, label=label + ' mse with noise')\n",
    "# eval_noise(att_model, val_G, 'selection', 10)\n",
    "eval_noise(model, val_G, 'src', 10 )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print X.shape, Y.shape\n",
    "print Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float32)\n",
    "Y = iris.target.reshape([-1, 1]).astype(np.float32)\n",
    "# print iris.data.shape\n",
    "N = len(Y)\n",
    "batch_size = 32\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(CustomDataset(X, Y), [N-N//10, N//10])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_G = generator(train_dataloader)\n",
    "val_G = generator(val_dataloader)\n",
    "\n",
    "model = Attention_Autoendecoder(X.shape[-1]).cuda()\n",
    "# opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "opt = optim.Adam(model.parameters())\n",
    "alpha = 100\n",
    "beta = 0\n",
    "epochs = 1000\n",
    "iters = 1\n",
    "noise_std = 5\n",
    "noise_col_idx = [2, 3]\n",
    "writer = SummaryWriter('./AE_logs/Iris-a%f,b%f' % (alpha, beta))\n",
    "reg_l2_coe = 0.1\n",
    "with tqdm(total=epochs*len(train_dataloader)) as pbar:\n",
    "    for epoch in range(epochs):\n",
    "        mask_idx = np.random.randint(0, X.shape[-1])\n",
    "        for _ in range(len(train_dataloader)):\n",
    "            x, y = next(train_G)\n",
    "            noised_x = add_masked_noise(x, noise_std, noise_col_idx)\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            noised_x = noised_x.cuda()\n",
    "            val_x, val_y = next(val_G)\n",
    "            val_noised_x = add_masked_noise(val_x, noise_std, noise_col_idx)\n",
    "            val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "            val_noised_x = val_noised_x.cuda()\n",
    "#             mask\n",
    "#             x = mask_column(x, mask_idx)\n",
    "#             val_x = mask_column(val_x, mask_idx)\n",
    "# \n",
    "            model.train()\n",
    "            out, att_w = model(x)\n",
    "            w_ = torch.softmax(att_w, dim=-1)\n",
    "            mse_loss = F.mse_loss(out, y)\n",
    "            att_loss = alpha*(F.l1_loss(att_w, torch.zeros_like(att_w)) + beta*entropy_loss(w_))\n",
    "            reg_loss = reg_l2_coe * regularizer(model.kernel_weights, F.mse_loss)\n",
    "            loss = att_loss + mse_loss + reg_loss\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                out, _ = model(val_x)\n",
    "                val_mse_loss = F.mse_loss(out, val_y)\n",
    "                val_loss = att_loss + val_mse_loss + reg_loss\n",
    "#                 noised\n",
    "                noised_mse = F.mse_loss(model(noised_x)[0], y)\n",
    "                val_noised_mse = F.mse_loss(model(val_noised_x)[0], val_y)\n",
    "                \n",
    "            \n",
    "            pbar.update(1)\n",
    "            w_arr = model.w.cpu().detach().numpy().flatten()\n",
    "            att_w_arr = att_w.cpu().detach().numpy().flatten()\n",
    "            ratio_w = (att_w / torch.sum(att_w)).cpu().detach().numpy().flatten()\n",
    "#             buf = ','.join(['%d:%.2f' % (i+1,x) for i,x in enumerate(buf)])\n",
    "            buf = ','.join(['%2.3f, ' % (x) for i,x in enumerate(ratio_w)])\n",
    "            buf += 'l1 %.3f, entropy %.3f' % (F.l1_loss(att_w, torch.zeros_like(att_w)).item(), entropy_loss(w_).item())\n",
    "            pbar.set_postfix_str('loss: %.3f, val_loss: %.4f, att_loss : %.3f, regularizer : %.3f                     %s' %\n",
    "                                 (mse_loss.item(), val_mse_loss.item(), \n",
    "                                  att_loss.item(),\n",
    "                                  reg_loss.item(), buf))\n",
    "#             if mse_loss.item() < 100:\n",
    "            if epoch > 0:\n",
    "                writer.add_scalars('data/loss', {'train': loss.item(),\n",
    "                                                     'validation': val_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/mse_loss', {'train': mse_loss.item(),\n",
    "                                                     'validation': val_mse_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/noised_mse_loss', {'train': noised_mse.item(),\n",
    "                                                     'validation': val_noised_mse.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/att_loss', {'train': att_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/reg_loss', {'train': reg_loss.item()},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/w', {'w%d' % (i+1) : v  for i, v in enumerate(w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/att_w', {'w%d' % (i+1) : v  for i, v in enumerate(att_w_arr)},\n",
    "                                                     iters)\n",
    "                writer.add_scalars('data/ratio_att_w', {'w%d' % (i+1) : v  for i, v in enumerate(ratio_w)},\n",
    "                                                     iters)\n",
    "            \n",
    "            iters += 1\n",
    "\n",
    "print 'done 1'\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print 'done'\n",
    "\n",
    "print att_w[0,: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_mse_loss = 0\n",
    "noised_mse_loss = 0\n",
    "normal = torch.distributions.Normal(0, 20)\n",
    "\n",
    "for i in range(100):\n",
    "    val_x, val_y = next(val_G)\n",
    "    val_x, val_y = val_x.cuda(), val_y.cuda()\n",
    "    N = val_x.shape[0]\n",
    "    noise = torch.cat([torch.zeros_like(val_x)[:,:-2], normal.sample([N,2]).cuda()], dim=1)\n",
    "    out1,_ = model(val_x)\n",
    "    out2,_ = model(val_x + noise)\n",
    "    src_mse_loss += F.mse_loss(out1, val_y)\n",
    "    noised_mse_loss += F.mse_loss(out2, val_y)\n",
    "    \n",
    "print src_mse_loss\n",
    "print noised_mse_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.softmax(torch.FloatTensor([1,0,0]), dim=0)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "input_x = np.hstack([h, w, iid, iid2])\n",
    "print input_x.shape\n",
    "m = Sequential()\n",
    "m.add(Dense(32, activation='selu'))\n",
    "m.add(Dense(32, activation='selu'))\n",
    "m.add(Dense(1, activation='linear'))\n",
    "m.compile(loss='mse', optimizer='adam')\n",
    "m.fit(input_x, bmi, epochs=100, batch_size=128, validation_split=0.1)\n",
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print x1.shape\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(x1.flatten(), y1.flatten(), y2.flatten(), label='curve')\n",
    "ax.legend()\n",
    "print X.shape\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rcParams['legend.fontsize'] = 10\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "theta = np.linspace(-4 * np.pi, 4 * np.pi, 100)\n",
    "z = np.linspace(-2, 2, 100)\n",
    "r = z**2 + 1\n",
    "x = r * np.sin(theta)\n",
    "y = r * np.cos(theta)\n",
    "ax.plot(x, y, z, label='parametric curve')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7.14 (conda)",
   "language": "python",
   "name": "python-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
